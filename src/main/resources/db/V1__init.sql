/*
 Navicat Premium Data Transfer

 Source Server         : blog
 Source Server Type    : MySQL
 Source Server Version : 80021
 Source Host           : 120.27.243.204:10001
 Source Schema         : VueBlog

 Target Server Type    : MySQL
 Target Server Version : 80021
 File Encoding         : 65001

 Date: 08/08/2020 12:30:35
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for blog
-- ----------------------------
DROP TABLE IF EXISTS `blog`;
CREATE TABLE `blog`  (
                         `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键',
                         `title` varchar(200) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '标题',
                         `summary` varchar(400) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '概览',
                         `create_date` datetime(0) NOT NULL COMMENT '创建日期',
                         `update_date` datetime(0) NOT NULL COMMENT '更新日期',
                         `click_count` int(0) NOT NULL COMMENT '点击数',
                         `comment_count` int(0) NOT NULL COMMENT '评论数',
                         `like_count` int(0) NOT NULL COMMENT '喜欢数',
                         `tag` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '博客标签(如1,2,3表示具有三种标签)',
                         `blog_image` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '博客图片',
                         `original_url` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '原文地址（如果非原创）',
                         `type` int(0) UNSIGNED NOT NULL COMMENT '0原创/1转载/2翻译',
                         PRIMARY KEY (`id`) USING BTREE,
                         INDEX `type_id`(`tag`) USING BTREE,
                         INDEX `type`(`type`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 63 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of blog
-- ----------------------------
INSERT INTO `blog` VALUES (10, '关于本博客', '简介本博客前后端分离的轻量级个人博客系统。本博客系统由后端服务器系统、后台管理系统、前台系统三个子系统组成。其中，后端服务系统基于SpringBoot，后台管理系统和前台系统均基于Vue。每个子系统的', '2019-07-01 20:13:13', '2019-08-29 21:20:08', 258, 1, 30, '11,13', 'https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/5lQGI7TSaeU97bVgYoTMJasr', '', 1);
INSERT INTO `blog` VALUES (11, '图解排序算法(四)之归并排序', '基本思想　　归并排序（MERGE-SORT）是利用归并的思想实现的排序方法，该算法采用经典的分治（divide-and-conquer）策略（分治法将问题分。分而治之!(http://localhos', '2019-07-16 19:51:27', '2019-08-14 11:09:53', 23, 0, 1, '1,10', 'https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/6FuV57igPa9A0Iwru922IK8l', 'http://www.cnblogs.com/chengxiao/p/6194356.html', 2);
INSERT INTO `blog` VALUES (20, 'vue不使用vuex时创建响应式全局变量的方法', '问题描述Vuex适合于中大型项目，在小型项目中使用往往是杀鸡用牛刀。官方说明如下:如果您不打算开发大型单页应用，使用Vuex可能是繁琐冗余的。确实是如此——如果您的应用够简单，您最好不要使用Vuex。', '2019-07-23 20:13:13', '2019-08-14 11:14:19', 82, 0, 1, '4,6,12', 'https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/nAUpvLNjzkxwks6rvAu9a14i', '', 1);
INSERT INTO `blog` VALUES (33, 'CentOS下docker安装', '前提条件如果是CentOS8,可以参考这篇文章1.Docker运行在CentOS7上，要求系统为64位、系统内核版本为3.10以上。2.Docker运行在CentOS-6.5或更高的版本的CentOS', '2019-08-14 11:02:55', '2019-12-18 16:36:36', 24, 0, 2, '15', NULL, '', 1);
INSERT INTO `blog` VALUES (34, 'SpringCloud学习笔记', '前言本文章内容比较基础，个人学习使用（学到心态爆炸，百度一堆老旧操作，一堆坑），配套完整代码地址Spring是一个轻量级的JAVAEE开源框架，主要是为了解决企业级开发的复杂度问题复杂度-耦合度Spr', '2019-08-14 11:07:58', '2019-09-09 14:05:00', 45, 5, 4, '15', NULL, '', 1);
INSERT INTO `blog` VALUES (35, '项目从打包到部署', '说明本文以本网站作为案例进行说明SpringBoot后端系统的打包以及部署-打包项目成jar包IDEA操作!成功标志![微信图片_2019082', '2019-08-26 16:47:58', '2019-08-26 19:30:06', 16, 2, 1, '11', NULL, '', 1);
INSERT INTO `blog` VALUES (36, 'Java多线程', '一、Java多线程实现的几种方式1.继承Thread类创建线程类publicclassstudy{//1.定义一个继承Thread的子类publicstaticclasstestThreadexten', '2019-08-27 10:30:03', '2019-12-23 10:03:44', 47, 2, 1, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (37, 'Java爬虫以及线程池利用', '概念介绍部分，不想看可以自行跳到后面实战为什么要使用线程池？1.操作的是重用存在的线程，减少对象创建、消亡的开销，性能佳。2.可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免', '2019-08-27 16:56:18', '2019-08-28 10:01:40', 190, 8, 1, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (38, '关于多线程内容的补充，ThreadPoolExecutor与Executors的区别', '简介看了多线程爬虫的文章后，对多线程应该有一定的了解了，那么，我们为什么要使用ThreadPoolExecutor来创建线程池而不使用Executors呢？居然阿里爸爸都说了不要使用Executors', '2019-08-28 16:03:44', '2019-08-28 16:03:44', 31, 5, 2, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (39, 'quartz cron', 'Tips最近打算在项目中加入quartz任务调度，实现定时备份数据库，定时发送邮件提醒的功能，最近时间有限，先把cron的用法了解一下，详细的后面有空再做一、结构SecondsMinutesHours', '2019-08-29 20:05:24', '2019-09-01 19:50:12', 14, 4, 2, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (40, 'MongoDB', '环境安装略实战~~~bash$mongo//进入mongodbhelp//帮助exit//退出$mongoshowdbs;//显示所有数据库usetest;//使用某个数据库showcollectio', '2019-09-04 15:13:00', '2019-09-04 18:29:36', 5, 0, 0, '7', NULL, '', 1);
INSERT INTO `blog` VALUES (41, 'Spring Security OAuth2学习', '什么是oAuthoAuth协议为用户资源的授权提供了一个安全的、开放而又简易的标准。与以往的授权方式不同之处是oAuth的授权不会使第三方触及到用户的帐号信息（如用户名与密码），即第三方无需使用用户的', '2019-09-08 11:35:32', '2019-12-17 19:32:56', 16, 0, 0, '2', NULL, '', 1);
INSERT INTO `blog` VALUES (42, 'frp做内网穿透', '为什么要做内网穿透在做项目的时候，目前主流的方案都是前后端分离的，那么前后端不在一台电脑上，测试的时候前端人员需要一个可以访问的server，这个时候，我们就可以做内网穿透，将本地端口暴露到公网中去，', '2019-09-11 19:56:10', '2019-09-11 20:02:18', 7, 0, 0, '13', NULL, '', 1);
INSERT INTO `blog` VALUES (43, '手写一个FutureTask和线程池', '准备工作1.了解Java是如何创建线程的2.了解Java是如何初始化线程池的本节代码地址为什么要用FutureTaskFutureTask可以获取到线程执行的结果，而直接使用Runable是没办法获取', '2019-09-25 16:45:14', '2019-09-25 17:22:39', 12, 0, 0, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (44, '经典排序算法整合（待更新）', '相关代码地址冒泡排序-比较相邻的元素。如果第一个比第二个大，就交换它们两个；-对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；-针对所有的元素重复以上的步', '2019-10-08 14:40:42', '2019-12-17 09:28:27', 16, 0, 0, '1,10', NULL, '', 1);
INSERT INTO `blog` VALUES (45, 'RocketMQ', '概述消息队列作为高并发系统的核心组件之一，能够帮助业务系统解构提升开发效率和系统稳定性。主要具有以下优势：-削峰填谷：主要解决瞬时写压力大于应用服务能力导致消息丢失、系统奔溃等问题-系统解耦：解决不同', '2019-10-12 09:36:35', '2019-10-12 09:36:35', 3, 0, 0, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (46, 'Java面试整合', '（个人总结，仅供参考）Java基础接口类和抽象类的差别1.接口是绝对抽象的，不可以被实例化成对象。抽象类也不可以被实体化，可是如果抽象类中有main方法的话可以被调用。2.接口中的所有方法都是隐藏抽象', '2019-11-20 20:38:53', '2020-05-11 22:53:44', 85, 0, 0, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (47, 'Java笔试', '2019/5/8下列关于Spring特性中IOC描述错误的是：A.IoC就是指程序之间的关系由程序代码直接操控B.所谓“控制反转”是指控制权由应用代码转到外部容器，即控制权的转移C.IoC将控制创建的', '2019-11-28 17:12:51', '2019-12-05 09:18:56', 17, 0, 0, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (48, 'dockerfile+docker-compose', 'Dockerfile一、简介1.1dockerfile中常用的命令合集!1.2dockerbuild基于dockerfile制作镜像的命令dockerbuildPATH|URL|-参数1.3参', '2019-12-18 19:47:49', '2019-12-18 20:13:50', 4, 0, 0, '11,12', NULL, '', 1);
INSERT INTO `blog` VALUES (49, 'RocketMQ学习笔记', '前言本文章内容参考自，对已有内容进行修改，精简部分内容，并且使用spring-cloud-starter-stream-rocketmq来代替B站视频中的spring-boot集成包。修改后的个人完整', '2019-12-23 20:54:20', '2019-12-24 09:55:07', 15, 0, 0, '16', NULL, '', 1);
INSERT INTO `blog` VALUES (50, 'Nginx代理常用配置', '配置文件内容1）全局块2）events块3）http块反向代理配置例子1）完整案例conf运行用户usersomebody;启动进程,通常设置成和cpu的数量相等worker_processes1;全', '2019-12-25 15:02:45', '2019-12-25 15:09:22', 13, 0, 3, '11', NULL, '', 1);
INSERT INTO `blog` VALUES (52, 'jib-maven-plugin构建镜像', '序言在本次期末设计当中，应为需要做部署脚本，我们采用的是dockerfile+docker-compose的部署方式，这种方式对vue项目是没有问题的，因为vue下载依赖与打包是分离开来的，即使修改了', '2020-01-04 15:10:26', '2020-01-04 15:10:26', 26, 0, 0, '1,12', NULL, '', 1);
INSERT INTO `blog` VALUES (53, 'SpringCloudAlibaba通过jib插件打包发布到docker', '序言在SpringBoot项目部署的时候，我了解到了Jib插件的强大，这个插件可以快速构建镜像发布到我们的镜像仓库当中去。于是我打算在毕设当中加上这个功能，并且整合到githubactions中去。阻', '2020-01-08 16:15:22', '2020-01-08 16:15:22', 6, 0, 0, '1,12', NULL, '', 1);
INSERT INTO `blog` VALUES (54, 'JVM学习笔记', '1、运行时数据区域!-线程私有的：-程序计数器-虚拟机栈-本地方法栈-线程共享的：-堆-方法区-直接内存1.1程序计数器程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字', '2020-02-22 21:53:51', '2020-03-03 15:59:53', 49, 0, 1, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (55, 'Linux常用指令', '-cd：cd命令后面跟一个路径，用于切换当前用户所在的路径，其中路径可以是绝对路径也可以是相对路径-ls：ls是list的缩写。最常用的参数是-l，也就是ls-l命令，作用为用于显示所有文件及文件夹的', '2020-03-05 11:55:56', '2020-04-11 22:19:24', 5, 0, 0, '8', NULL, '', 1);
INSERT INTO `blog` VALUES (56, '设计模式', '一、单例模式1.1饿汉模式Java//饿汉式单例类.在类初始化时，已经自行实例化publicclassSingleton1{privateSingleton1privatestaticfinalSin', '2020-03-08 21:45:42', '2020-04-15 16:01:18', 10, 0, 0, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (57, '文章分享', '计算机网络(https://blog.csdn.net/qq_26896213/article/details/84594060?depth_1-utm_source=distribute.pc_re', '2020-03-12 17:12:15', '2020-03-27 12:35:30', 21, 0, 0, '12', NULL, '', 1);
INSERT INTO `blog` VALUES (58, 'NIO', '本文章对应代码地址：一、了解IO与NIO区别!二、初见Buffer缓冲区!(https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/iWfl', '2020-05-03 20:36:32', '2020-05-04 22:11:33', 8, 0, 0, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (59, 'Netty', '内容参考尚硅谷Netty教程有了NIO，为什么还有Netty1.NIO中epoll空轮询问题2.NIO的类库和API繁杂，使用麻烦：需要掌握Selector、ServerSocketChannel、S', '2020-05-16 11:43:28', '2020-05-26 20:22:08', 6, 0, 0, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (60, 'Netty-TCP', '使用Netty开启TCP服务Netty服务端javapublicclassNettyServer{publicstaticvoidmainthrowsInterruptedExcept', '2020-05-28 10:42:26', '2020-05-28 22:52:21', 3, 0, 0, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (61, 'Netty-TaskQueue', 'Netty任务队列-用户程序自定义的普通任务javactx.channel-{try{Thread.sleep;ctx.writeAndFlush(Unpooled.copiedBuffer(\"处理结', '2020-05-31 14:31:29', '2020-05-31 14:31:29', 0, 0, 0, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (62, 'Netty-WebSocket', 'javapublicclassChatServer{privateintport;ChatServer{this.port=port;}publicvoidstartthrowsInterrupted', '2020-06-17 14:22:57', '2020-06-17 14:22:57', 15, 1, 1, '1', NULL, '', 1);
INSERT INTO `blog` VALUES (63, 'Github Hosts', '项目部署上线后github第三方登录离奇的慢，并且多次出现Connectionrefused的错误，因此找到了一种办法是通过修改hosts解决。Windows下在C:/Windows/system32', '2020-07-23 19:00:55', '2020-07-23 19:00:55', 5, 0, 0, '12', NULL, 'https://www.jianshu.com/p/1a2013b38730', 2);

-- ----------------------------
-- Table structure for blog_content
-- ----------------------------
DROP TABLE IF EXISTS `blog_content`;
CREATE TABLE `blog_content`  (
                                 `id` int(0) UNSIGNED NOT NULL COMMENT '主键，和对应博客一致',
                                 `content` text CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '正文',
                                 PRIMARY KEY (`id`) USING BTREE,
                                 CONSTRAINT `blog_content_ibfk_1` FOREIGN KEY (`id`) REFERENCES `blog` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of blog_content
-- ----------------------------
INSERT INTO `blog_content` VALUES (10, '## 简介\n\n本博客前后端分离的轻量级个人博客系统。\n\n本博客系统由后端服务器系统、后台管理系统、前台系统三个子系统组成。其中，后端服务系统基于SpringBoot，后台管理系统和前台系统均基于Vue。每个子系统的详细内容可参看相应的Github地址。\n\n## 技术栈\n\nSpringBoot + Maven + Mybatis + PageHelper + MySQL + Redis + Quartz(每天定时将当天的评论发送到管理员邮箱)\n\n## 传送门\n\n- [后端服务系统](https://github.com/yhuihu/blog-back)\n- [后台管理系统](https://github.com/yhuihu/yhhu_blog_admin)\n- [前台系统](https://github.com/yhuihu/yhhu_blog_front)\n\n> 注意：项目的图片上传到七牛云上了，所以图片路径为域名形式，可以根据自己的需求改写保存到本地\n## 目前问题\n- 文章中的图片还无法达到放大效果，正在处理中。（已完成，有进一步建议欢迎留言）\n- v-for下如何调用全局变量？评论删除暂时还未完成，遇到瓶颈\n- 用户目前只能通过github第三方登录，没有进行绑定操作，之后有必要会进行补充\n- 由于邮箱是一封封发的，自己测试了一下，简直是被轰炸，下版本合并成一个邮件（已修改）\n## BlahBlah\n\n如果本项目对您学习Vue或SpringBoot等有所帮助的话，请帮忙点颗⭐哦😁！\n\n如果您对本项目有什么意见或建议，也欢迎批评指正。\n\n## 打赏链接\n![微信图片_20190826205030.jpg](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/NPZ9xcBMnrCduvtn4WWMITJi)     ![微信图片_20190826205212.jpg](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/ScPrZMaVtT25quNbLSNtlYXk)');
INSERT INTO `blog_content` VALUES (11, '## 基本思想\n\n　　归并排序（MERGE-SORT）是利用归并的思想实现的排序方法，该算法采用经典的分治（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案\"修补\"在一起，即分而治之)。\n  \n### 分而治之\n\n![](http://localhost/api/upload/2019/07/24/17da2791-65ca-49f1-a26e-f36f28f4a098.png)\n\n可以看到这种结构很像一棵完全二叉树，本文的归并排序我们采用递归去实现（也可采用迭代的方式去实现）。分阶段可以理解为就是递归拆分子序列的过程，递归深度为log2n。\n\n## 合并相邻有序子序列\n\n　　再来看看治阶段，我们需要将两个已经有序的子序列合并成一个有序序列，比如上图中的最后一次合并，要将[4,5,7,8]和[1,2,3,6]两个已经有序的子序列，合并为最终序列[1,2,3,4,5,6,7,8]，来看下实现步骤。\n  \n  ![](http://localhost/api/upload/2019/07/24/26f6b8ff-6d46-4578-b1c4-15df8ccf58df.png)\n  ![](http://localhost/api/upload/2019/07/24/8b75acaa-ef34-4566-a29c-7ac13fc58d98.png)\n  \n## 代码实现\n\n```java\npackage sortdemo;\n\nimport java.util.Arrays;\n\n/**\n * Created by chengxiao on 2016/12/8.\n */\npublic class MergeSort {\n    public static void main(String []args){\n        int []arr = {9,8,7,6,5,4,3,2,1};\n        sort(arr);\n        System.out.println(Arrays.toString(arr));\n    }\n    public static void sort(int []arr){\n        int []temp = new int[arr.length];//在排序前，先建好一个长度等于原数组长度的临时数组，避免递归中频繁开辟空间\n        sort(arr,0,arr.length-1,temp);\n    }\n    private static void sort(int[] arr,int left,int right,int []temp){\n        if(left<right){\n            int mid = (left+right)/2;\n            sort(arr,left,mid,temp);//左边归并排序，使得左子序列有序\n            sort(arr,mid+1,right,temp);//右边归并排序，使得右子序列有序\n            merge(arr,left,mid,right,temp);//将两个有序子数组合并操作\n        }\n    }\n    private static void merge(int[] arr,int left,int mid,int right,int[] temp){\n        int i = left;//左序列指针\n        int j = mid+1;//右序列指针\n        int t = 0;//临时数组指针\n        while (i<=mid && j<=right){\n            if(arr[i]<=arr[j]){\n                temp[t++] = arr[i++];\n            }else {\n                temp[t++] = arr[j++];\n            }\n        }\n        while(i<=mid){//将左边剩余元素填充进temp中\n            temp[t++] = arr[i++];\n        }\n        while(j<=right){//将右序列剩余元素填充进temp中\n            temp[t++] = arr[j++];\n        }\n        t = 0;\n        //将temp中的元素全部拷贝到原数组中\n        while(left <= right){\n            arr[left++] = temp[t++];\n        }\n    }\n}\n```\n执行结果\n>[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n## 最后\n\n　　归并排序是稳定排序，它也是一种十分高效的排序，能利用完全二叉树特性的排序一般性能都不会太差。java中Arrays.sort()采用了一种名为TimSort的排序算法，就是归并排序的优化版本。从上文的图中可看出，每次合并操作的平均时间复杂度为O(n)，而完全二叉树的深度为|log2n|。总的平均时间复杂度为O(nlogn)。而且，归并排序的最好，最坏，平均时间复杂度均为O(nlogn)。');
INSERT INTO `blog_content` VALUES (20, '## 问题描述\n\nVuex适合于中大型项目，在小型项目中使用往往是杀鸡用牛刀。\n\n官方说明如下:\n\n> 如果您不打算开发大型单页应用，使用 Vuex 可能是繁琐冗余的。确实是如此——如果您的应用够简单，您最好不要使用 Vuex。\n\n但最近使用自定义的全局变量时，却遇到了`computed`计算属性不能获取全局变量变更后的状态的问题。\n\n```js\n// src/state/index.js\nexport default {\n	state1: \'\',\n	state2: \'\'\n}\n\n// main.js\nimport state from \'./state\'\nVue.prototype.$state = state\n\n// demo.vue\ncomputed: {\n    state1() {\n        console.log(\'in computed...\')\n        return this.$state.state1\n    }\n},\nwatch: {\n    state1: function(newValue) {\n        console.log(\'newValue: \' + newValue)\n    }\n}    \n```\n\n\n\n当通过其他方式改变`state1`的值时，发现`computed`和`watch`的代码并没有执行，查阅了相关资料才发现这种方式创建的全局变量**是不可交互的**。\n\n## 解决方法\n\n```js\n// src/state/index.js\nexport default {\n	state1: \'\',\n	state2: \'\'\n}\n\n// main.js\nimport state from \'./state\'\nnew Vue({\n  el: \'#app\',\n  router,\n  components: { App },\n  template: \'<App/>\'\n  // 关键在此处，注意此处data不是函数形式\n  data: { // only place where data is not a function\n    state\n  },\n})\n\n// demo.vue\ncomputed: {\n    state1() {\n        console.log(\'in computed...\')\n        return this.$root.state.state1\n    }\n},\nwatch: {\n    state1: function(newValue) {\n        console.log(\'newValue: \' + newValue)\n    }\n}  \n```\n\n按上面写法就能成功创建可交互的全局变量了。\n\n\n\n## 参考\n\n[https://cn.vuejs.org/v2/guide/state-management.html#简单状态管理起步使用](https://cn.vuejs.org/v2/guide/state-management.html#简单状态管理起步使用)\n\n[https://stackoverflow.com/questions/51275301/how-to-react-to-a-global-variable-with-vue](https://stackoverflow.com/questions/51275301/how-to-react-to-a-global-variable-with-vue)');
INSERT INTO `blog_content` VALUES (33, '## 前提条件\n### 如果是CentOS8,可以参考这篇文章[centos8.0安装docker](https://www.cnblogs.com/ding2016/p/11592999.html)\n 1. Docker 运行在 CentOS 7 上，要求系统为64位、系统内核版本为 3.10 以上。\n 2. Docker 运行在 CentOS-6.5 或更高的版本的 CentOS 上，要求系统为64位、系统内核版本为 2.6.32-431 或者更高版本。\n\n## 移除旧版本以及相关内容\n\n```\n	sudo yum remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-selinux \\\n                  docker-engine-selinux \\\n                  docker-engine\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/201908102327229.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTYxMzY4OQ==,size_16,color_FFFFFF,t_70)\n## 安装依赖包\n```\nyum install -y yum-utils \\ device-mapper-persistent-data \\  lvm2\n```\n## 更新并安装Docker CE\n\n```\n//添加软件源\nyum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n//更新并安装docker-ce\nyum update && yum -y install docker-ce\n```\n### 验证安装\n\n - 启动docker\n```\nsystemctl start docker\n```\n - 查看信息\n\n```\ndocker version\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20190810234533945.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTYxMzY4OQ==,size_16,color_FFFFFF,t_70)\n## 设置阿里云镜像加速\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2019081023571344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTYxMzY4OQ==,size_16,color_FFFFFF,t_70)\n根据提示开通服务后执行以下操作（镜像加速器有很多，在此用的是阿里云的）\n![根据操作文档操作](https://img-blog.csdnimg.cn/2019081023593413.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTYxMzY4OQ==,size_16,color_FFFFFF,t_70)\n根据操作文档操作即可\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20190811000152894.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTYxMzY4OQ==,size_16,color_FFFFFF,t_70)\n### 验证配置\n\n```\ndocker info\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20190811000452194.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTYxMzY4OQ==,size_16,color_FFFFFF,t_70)\n## 尝试安装tomcat镜像\n\n```\ndocker pull tomcat\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20190811000711255.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTYxMzY4OQ==,size_16,color_FFFFFF,t_70)\n## 启动tomcat\n\n```\ndocker run -p 8080:8080 tomcat\n```\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20190811000930247.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTYxMzY4OQ==,size_16,color_FFFFFF,t_70)\n\n## 常用命令\n1. 搜索容器镜像\ndocker search xxx\n2. 下载容器镜像\ndocker pull xxx\n3. 启动容器镜像\ndocker run \\<IMAGE ID>\n4. 停止一个容器\ndocker stop xxx\n>先发SIGTERM信号给docker，允许其在一定时间（默认10s）内进行一些操作（例如资源回收），若这段时间内容器未停止，则发送SIGKILL信号强行杀死容器\n5. 停止一个容器2\ndocker kill xxx\n>直接发送SIGKILL信号杀死容器。\n6. 运行已停止的容器\ndocker start <CONTAINER ID>\n7. 删除容器\ndocker rm \\<CONTAINER ID>\n8. 删除镜像\ndocker rmi \\<IMAGE ID>\n9. 显示所有容器id\ndocker ps -aq\n10. 停止所有容器\ndocker stop $(docker ps -aq)\n11. 删除所有容器\ndocker rm $(docker ps -aq)\n12. 删除所有镜像\ndocker rmi $(docker images -q)\n13. 复制容器内内容\ndocker cp mycontainer:/opt/file.txt /opt/local/docker\n\n\n\n\n\n');
INSERT INTO `blog_content` VALUES (34, '## 前言\n本文章内容比较基础，个人学习使用（学到心态爆炸，百度一堆老旧操作，一堆坑），配套完整代码地址[Demo](https://github.com/yhuihu/SpringCloud)\n### Spring\n是一个轻量级的JAVAEE开源框架，主要是为了解决企业级开发的复杂度问题复杂度->耦合度\n\n### SpringBoot\n新一代JAVAEE开发标准，开箱即用的特性（不需要过多配置）\n### 微服务架构\n更好的进行分布式系统开发，拆分单体应用，将一个应用拆分成多个服务，每个服务都是一个可以独立运行的项目\n### 分布式系统开发一定会遇到的问题\n1. 客户端如何访问\n2. 服务间如何通信\n3. 服务如何治理\n4. 服务挂了怎么办\n5. 网络是不可靠的\n\n### 解决方案\nSpring Cloud是一套生态，是为了解决微服务架构遇到的问题。想要用Spring Cloud必须基于Spring Boot\n- Spring Cloud Netflix（18年进入维护，停止更新）\n- Apache Dubbo Zookeeper\n\n```\nDubbo是一个高性能的JAVA RPC通信框架\n服务注册于发现，Zookeeper\nAPI网关，没有，再找第三方或自己实现\n```\n- Spring Cloud Alibaba\n\n```\nSpring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。\n此项目包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。\n依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里分布式应用解决方案，通过阿里中间件来迅速搭建分布式应用系统。\n```\n- 下一代微服务架构标准 Service Mesh服务网格(Istio)\n- 异步非阻塞通信\n\n```\nNetty -> NIO、AIO\nHTTP -> 应用层，跨防火墙，在不同局域网间通信\nRPC -> 远程过程调用，TCP（传输层） \n        优点：速度快\n        缺点：不能跨防火墙，仅支持局域网通信\n```\n\n### 下面为代码环节，首先说明可能遇到的问题\nNacos在进行服务发现与注册的时候扫描的优先顺序不是application.yml，所以在运行的时候可能会出现几次Nacos配置文件存在问题的情况，不需要理会，在最终出现nacos registry, xxxx register finished即可默认注册成功，在Nacos客户端服务列表可以查看到信息。\n\n### 代码不多介绍了，都在github上，使用上都挺简单的，讲一下操作顺序以及注意事项\n1. 创建统一依赖\n2. 安装Nacos（服务注册发现中心，安装看官方文档）[Nacos](https://nacos.io/zh-cn/docs/what-is-nacos.html)\n3. 创建服务提供者\n只需注意一下yml的配置，Controller那些和之前一样\n```Java\nserver:\n  //如果想测试负载均衡只需要将port换一个启动多一个版本就行了\n  port: 8081\nspring:\n  application:\n    name: nacos-provider\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: \"*\"\n```\n\n> 提一下配置文件的加载顺序：bootstrap.properties->bootstrap.yml->application.properties->application.yml\n\n4. 创建服务消费者（本案例提到原始的LoadBalanceClient 和 RestTemplate 结合的方式还有Feign方式）\n\n```Java\n//LoadBalanceClient方式\nspring:\n  application:\n    name: nacos-consumer\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\nserver:\n  port: 9091\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: \"*\"\n\n@Configuration\npublic class NacosConsumerConfiguration {\n\n    @Bean\n    public RestTemplate restTemplate() {\n        return new RestTemplate();\n    }\n}\n\n@RestController\npublic class ConsumerController {\n\n    @Autowired\n    private LoadBalancerClient loadBalancerClient;\n\n    @Autowired\n    private RestTemplate restTemplate;\n\n    @Value(\"${spring.application.name}\")\n    private String appName;\n\n    @GetMapping(value = \"/echo/app/name\")\n    public String echo() {\n        //使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问\n        ServiceInstance serviceInstance = loadBalancerClient.choose(\"nacos-provider\");\n        String url = String.format(\"http://%s:%s/hello/%s\", serviceInstance.getHost(), serviceInstance.getPort(), appName);\n        return restTemplate.getForObject(url, String.class);\n    }\n}\n```\n\n```Java\n//Feign方式\nspring:\n  application:\n    name: nacos-consumer-feign\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\nserver:\n  port: 9092\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: \"*\"\nfeign:\n  sentinel:\n    enabled: true\n\n@FeignClient(value = \"nacos-provider\")\npublic interface EchoService {\n    @GetMapping(value = \"/hello/{message}\")\n    String hello(@PathVariable(\"message\") String message);\n}\n\n\n@RestController\npublic class ConsumerController {\n\n    @Autowired\n    private EchoService echoService;\n    @Value(value =\"${spring.application.name}\")\n    private String name;\n    @GetMapping(value = \"/echo/hi\")\n    public String echo() {\n        return echoService.hello(\"Hi Feign\"+name);\n    }\n}\n```\n\n5. 熔断器配置sentinel(服务挂了怎么办)\n这里以Feign为例子说明\n\n```Java\nspring:\n  application:\n    name: nacos-consumer-feign\n  cloud:\n    //这里为新加内容\n    sentinel:\n      transport:\n        port: 8719\n        dashboard: localhost:8080\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n\nserver:\n  port: 9092\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: \"*\"\nfeign:\n  sentinel:\n    enabled: true\n\n//编写fallback\n@Component\npublic class EchoServiceFallBack implements EchoService {\n    @Override\n    public String hello(String message) {\n        return \"请求失败，请检查网络\";\n    }\n}\n\n//只需要在FeignClient中加一个fallback的配置就可以看到效果，具体测试方法为将服务提供者停掉再访问\n@FeignClient(value = \"nacos-provider\",fallback = EchoServiceFallBack.class)\npublic interface EchoService {\n\n    @GetMapping(value = \"/hello/{message}\")\n    String hello(@PathVariable(\"message\") String message);\n}\n```\n\n6. 安装熔断器仪表盘监控（本来想在CentOS下弄的，可是发现弄了几次都不行？）\n启动命令（可以自行指定端口号）：java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar\n\n7. 创建Spring Cloud Gateway网关并设置过滤器（集成了webflux，不要单独再配置mvc，会发生冲突。由网关控制后所有消费者可以通过同一个端口+服务名的方式访问）\n```Java\n//配置文件太多就不发了，有兴趣可以到github上看\n@Component\npublic class AuthFilter implements GlobalFilter, Ordered {\n    @Override\n    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {\n        //spring5的时候webflux将httpServletRequest改了\n        //查询第一个参数名为token的字段内容\n        String token = exchange.getRequest().getQueryParams().getFirst(\"token\");\n\n        if (token == null || token.isEmpty()) {\n            ServerHttpResponse response = exchange.getResponse();\n\n            // 封装错误信息\n            //google的guava.jar提供的写法，目的是为了简化代码，不需要你手动写泛型。\n            Map<String, Object> responseData = Maps.newHashMap();\n            responseData.put(\"code\", HttpStatus.UNAUTHORIZED);\n            responseData.put(\"message\", \"非法请求\");\n            responseData.put(\"cause\", \"Token is empty\");\n\n            try {\n                // 将信息转换为 JSON\n                ObjectMapper objectMapper = new ObjectMapper();\n                byte[] data = objectMapper.writeValueAsBytes(responseData);\n\n                // 输出错误信息到页面\n                DataBuffer buffer = response.bufferFactory().wrap(data);\n                response.setStatusCode(HttpStatus.UNAUTHORIZED);\n                response.getHeaders().add(\"Content-Type\", \"application/json;charset=UTF-8\");\n                return response.writeWith(Mono.just(buffer));\n            } catch (JsonProcessingException e) {\n                e.printStackTrace();\n            }\n        }\n\n        return chain.filter(exchange);\n    }\n\n    @Override\n    public int getOrder() {\n        return Ordered.LOWEST_PRECEDENCE;\n    }\n}\n```\n\n8. 分布式配置中心管理\n	1. 如何在服务端设置所需要的配置\n	![微信截图_20190905095204.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/ncJq7N0nyACBLYUcG0PErdKR)\n	![微信截图_20190905105429.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/hUkXS8TDeIE90DqmJ7UYSaPt)\n	2. 如何在客户端中使用这些配置（敲黑板，由于配置文件加载顺序的问题，必须将一下内容写到bootstrap.yml中，如果还是没用，那就写到bootstrap.properties中，上面有提到spring配置文件加载顺序）\n	```Java\n	spring.application.name=nacos-provider\n	# 指定查找名为 nacos-provider.properties 的配置文件\n	spring.cloud.nacos.config.file-extension=properties\n	# Nacos Server 的地址\n	spring.cloud.nacos.config.server-addr=localhost:8848\n	```\n	\n	成功标志\n	![微信截图_20190905105609.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/KGqMSjEU3Ds11fCpbIf52iAS)\n	3.如何获取环境里的最新值？\n	传统的方法是@Value(\"${xxx}\")，可是这样获取的是不会再变化的了\n	```Java\n	@Autowired\n    private ConfigurableApplicationContext applicationContext;\n	@GetMapping(\"/environment\")\n    public String test(){\n        return applicationContext.getEnvironment().getProperty(\"user.name\");\n    }\n	//这样就可以实现动态刷新了\n	``` \n	![微信截图_20190905110522.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/vOVXNgVz7oXlV16ExdsxuiSo)\n\n\n\n### spring-cloud-alibaba整合dubbo 达到对内RPC\n1. Dubbo介绍\n	- [Dubbo](http://dubbo.apache.org/zh-cn/docs/user/preface/background.html)\n\n2. 需要新加入的内容\n```Java\n	   <dependency>\n                <groupId>org.apache.dubbo</groupId>\n                <artifactId>dubbo-registry-nacos</artifactId>\n                <version>${dubbo.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>com.alibaba</groupId>\n                <artifactId>dubbo-registry-nacos</artifactId>\n                <version>${dubbo-registry-nacos.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.dubbo</groupId>\n                <artifactId>dubbo-spring-boot-actuator</artifactId>\n                <version>${dubbo.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.dubbo</groupId>\n                <artifactId>dubbo</artifactId>\n                <version>${dubbo.version}</version>\n                <exclusions>\n                    <exclusion>\n                        <groupId>org.springframework</groupId>\n                        <artifactId>spring</artifactId>\n                    </exclusion>\n                    <exclusion>\n                        <groupId>javax.servlet</groupId>\n                        <artifactId>servlet-api</artifactId>\n                    </exclusion>\n                    <exclusion>\n                        <groupId>log4j</groupId>\n                        <artifactId>log4j</artifactId>\n                    </exclusion>\n                </exclusions>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.dubbo</groupId>\n                <artifactId>dubbo-serialization-kryo</artifactId>\n                <version>${dubbo.version}</version>\n                <exclusions>\n                    <exclusion>\n                        <groupId>log4j</groupId>\n                        <artifactId>log4j</artifactId>\n                    </exclusion>\n                    <exclusion>\n                        <groupId>org.apache.dubbo</groupId>\n                        <artifactId>dubbo-common</artifactId>\n                    </exclusion>\n                </exclusions>\n            </dependency>\n```\n\n3. 服务提供者操作，将API与具体实现区分开\n![微信截图_20190909122713.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/NPNZfHEvkK7TSyjKu7znzOJq)\n![微信截图_20190909122731.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/Hgjhba0fqojfXgQklXjbzhvr)\n需要注意，这里的@service注解使用的是dubbo提供的，参数必须加上version\n\n4. 服务消费者操作\n![微信截图_20190909122853.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/6efRT7GYQTVbg1OAeYKgAlJV)\n@Reference注解用于指定版本号，对应提供者的service注解中的version\n\n\n### Dubbo实现高速序列化\nDubbo RPC是Dubbo体系中最核心的一种高性能，高吞吐量的远程调用方式，可以称之为多路复用的TCP长连接调用（碰到了再说下UDP，UDP是广播，无连接，发了大家都会有，可是收不收还是得看自己）：\n- 长连接：避免了每次调用新建TCP连接，提高了调用的响应速度\n- HTTP是单路的，每次访问都是一个连接\n- 多路复用单个TCP连接可交替传输多个请求和响应的消息，降低了连接的等待闲置时间，从而减少了同样并发数下的网络连接数，提高了系统吞吐量\n\nDubbo RPC主要用于两个Dubbo系统之间的远程调用，特别适合高并发，小数据的互联网场景。而序列化对于远程调用的响应速度、吞吐量、网络带宽消耗等同样也起着至关重要的作用，是我们提升分布式系统性能的最关键的因素之一。\n\nDubbo中支持的序列化方式：\n1. dubbo序列化：不建议使用\n2. hessian2序列化：dubbo RPC默认启用的序列化方式（不是原生的，是经过阿里修改过的）\n3. json序列化：fastjson，dubbo自己实现的简单的json库，都不是特别成熟，性能一般，不如上面的两种\n4. java序列化：JDK自带的序列化，性能也一般\n\n#### 专门针对Java语言的序列化方式：Kryo\n整合至需要加入\n```Java\n            <dependency>\n                <groupId>org.apache.dubbo</groupId>\n                <artifactId>dubbo-serialization-kryo</artifactId>\n                <version>${dubbo-kryo.version}</version>\n                <exclusions>\n                    <exclusion>\n                        <groupId>log4j</groupId>\n                        <artifactId>log4j</artifactId>\n                    </exclusion>\n                    <exclusion>\n                        <groupId>org.apache.dubbo</groupId>\n                        <artifactId>dubbo-common</artifactId>\n                    </exclusion>\n                </exclusions>\n            </dependency>\n```\n\n### Dubbo负载均衡\n#### 概述\n集群负载均衡的时候，Dubbo提供了四种策略\n1. 随机\nRandom LoadBalance：按权重设置随机概率，在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀（默认使用这种策略）\n2. 轮询\nRoundRobin LoadBalance：按公约后的权重设置轮询比率，存在慢的提供者累计请求的问题。比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上（nacos默认实现）\n3. 最少活跃调用数\nLeastActive LoadBalance：相同活跃数的随机，活跃数指调用前后计数差，使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。\n4. 一致性 Hash\nConsistentHash LoadBalance：相同参数的请求总是发到统一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟结点，平摊到其他提供者，不会引起剧烈变动。\n\n#### 如何配置负载均衡\n在yml中配置dubbo.provider.loadbalance:\n可以配置的值分别是：random，roundrobin，leastactive，consistenthash\n\n#### 外部化配置\n也就是使用nacos作为配置管理中心，具体代码看demo，和上面的单纯的spring-cloud-alibaba是一样的。\n\n\n### demo地址\n[spring-cloud-alibaba-dubbo](https://github.com/yhuihu/spring-cloud-alibaba-dubbo)\n');
INSERT INTO `blog_content` VALUES (35, '## 说明 \n本文以本网站作为案例进行说明\n### SpringBoot后端系统的打包以及部署\n- 打包项目成jar包(由于项目为个人项目，所有行为直接操作个人服务器，没有配置多个配置文件)\n\n> IDEA操作\n\n![微信图片编辑_20190826162745.jpg](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/TnfgL1LWc3N5F5CsqaWVGkbz)\n> 成功标志\n\n![微信图片_20190826162156.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/GEDZZj389uyvF0p6rZj8ccCw)\n\n> 命令行操作\n\n移动到项目目录\nmvn clean package -Dmaven.test.skip=true\n![微信图片_20190826163135.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/03qeA9C8wDtp6O9Bkuytr1aA)\n在xshell中使用rz命令上传jar包(如果遇到rz无法使用的情况就先执行yum install lrzsz安装依赖)\n![微信图片_20190826163223.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/OljD06SVxfPDoQVv2jJfw8VM)\n后台启动jar包\nnohup java -jar blog-back-0.0.1-SNAPSHOT.jar &\n此时可以在相同目录下看到nohup.out，jar包所有日志都在里面\n\n### VUE项目打包部署\n\n直接使用npm run build进行打包\n> 可能遇到的问题以及注意事项\n\n- build之前请确保能够正常运行，如果在build的时候出现错误，可以尝试将node_modules文件夹删除重新执行npm install，此处建议使用cnpm install，本人在使用npm install出现过包损坏的情况。\n- 在该案例中VUE的部署是使用express和pm2完成的，因此不用修改assetsPublicPath！\n- 如果有人出现问题此处会继续补充\n\n打包完成后相同目录下会出现dist文件夹\n在目录中新建app.js文件，将两内容一起打包成压缩包上传服务器\n```\nconst fs = require(\'fs\'); //文件模块\nconst path = require(\'path\'); //路径模块\nconst express = require(\'express\'); //express框架模块\nconst app = express();\nconst hostName = \'localhost\'; //ip\nconst port = 8002; //端口\napp.use(express.static(path.resolve(__dirname, \'./dist\'))); // 设置静态目录(例：app.js在demo目录下，那么目录则为demo/dist)。\napp.get(\'*\', function (req, res) {\n  const html = fs.readFileSync(path.resolve(__dirname, \'./dist/index.html\'), \'utf-8\'); // 设置所有访问服务请求默认返回index.html文件\n  res.send(html);\n});\napp.listen(port, hostName, function () {\n  console.log(`服务器运行在http://${hostName}:${port}`);\n```\n![微信图片_20190826164451.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/DKUN166zjiloUQHDQCyX3Ij5)\n\n- 此后操作需要先在服务器上安装node(自行百度)\n\n在app.js+dist的目录下执行npm init，一路回车到底\n![微信图片_20190826174658.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/ozOBwAocnqrE675n6d9eysun)\n- 项目安装express框架\ncnpm install express --save\n\n此时项目的目录结构如图\n![微信图片_20190826175009.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/YNnTEZpuKN9MAiY6dZpOYxz4)\n- 启动项目(pm2托管方式)\npm2安装npm install pm2 -g\n\npm2 start app.js --name xxx\n后面的--name xxx用于指定该app的名称，类似于docker，可以不指定，直接用pm2 start app.js\n![微信图片_20190826175145.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/jRrPJgAP0pRWSSzzHapjvLxj)\n\n- 如果想要使用反向代理可以继续往下看，否则已经可以正常运行了\n如果不使用反向代理，访问的方式应该为：www.xxx.xxx:端口号，如果使用方向代理，则可以将某个域名转发到特定端口上面，从而达到省略端口号访问。\n\n在此使用nginx作为方向代理工具，安装直接yum安装就好了，没什么好说的。\n安装完成后可以在/etc/nginx下看到nginx.conf配置文件\n![微信图片_20190826192950.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/IJyETkUVYDlsqfmm4JovM7Er)');
INSERT INTO `blog_content` VALUES (36, '### 一、Java多线程实现的几种方式\n1. 继承Thread类创建线程类\n\n\n```\npublic class study {\n    //1.定义一个继承Thread的子类\n    public static class testThread extends Thread {\n        int i=0;\n        testThread(String name) {\n            super(name);\n        }\n\n        //2.重写Thread的run()方法\n        @Override\n        public void run() {\n            for (; i < 100; i++)\n                System.out.println(\"我是线程:\" + Thread.currentThread().getName() + \"----\" + i);\n        }\n    }\n\n    public static void main(String[] args) {\n        //3.创建Thread子类实例\n        testThread thread1 = new testThread(\"1\");\n        testThread thread2 = new testThread(\"2\");\n        //4.启动线程\n        thread1.start();\n        thread2.start();\n    }\n}\n```\n\n\n>运行一遍后发现线程1和2都将输出0-100，各线程数据时独立的\n\n2. 实现Runnable接口创建线程类  \n\n\n```\n//1.定义Runnable接口实现类\nclass testRunnable implements Runnable {\n    private int i=0;\n    //  2.重写run()方法\n    @Override\n    public void run() {\n        for(;i<100;i++){\n            System.out.println(i);\n        }\n    }\n}\n\npublic class study {\n\n    public static void main(String[] args) {\n        //3.创建实例\n        testRunnable testRunnable=new testRunnable();\n        //4.将该实例作为Thread的target对象\n        Thread thread=new Thread(testRunnable);\n        Thread thread1=new Thread(testRunnable);\n        //5.启动线程\n        thread.start();\n        thread1.start();\n    }\n}\n```\n\n\n>运行后可以发现只输出0-100中的数字一遍，证明Runable是可以实现数据共享的（多个线程共享Thread这个Runable对象代码）\n注意：这是线程不安全的，多运行几次可能会出现某个数字重复输出的情况，可以考虑互斥锁\n\n3. 通过Callable和Future创建线程\n\n\n```\n//1.创建Callable接口的实现类\nclass testCallable implements Callable<Integer> {\n    private int i = 0;\n    //2.实现call方法\n    @Override\n    public Integer call() throws Exception {\n        int sum = 0;\n        for (; i < 100; i++) {\n            System.out.println(Thread.currentThread().getName() + \" \" + i);\n            sum += i;\n        }\n        return sum;\n    }\n}\n\npublic class study {\n\n    public static void main(String[] args) {\n        //3.创建testCallable对象\n        Callable<Integer> testCallable=new testCallable();\n        //4.由Callable创建一个FutureTask对象\n        FutureTask<Integer> ft = new FutureTask<Integer>(testCallable);\n        for (int i = 0; i < 100; i++) {\n            System.out.println(Thread.currentThread().getName() + \" \" + i);\n            if (i == 30) {\n                //5.由FutureTask创建一个Thread对象\n                Thread thread = new Thread(ft);\n                //6.线程进入到就绪状态\n                thread.start();\n            }\n        }\n        System.out.println(\"主线程for循环执行完毕..\");\n        try {\n            int sum = ft.get();            //取得新创建的新线程中的call()方法返回的结果\n            System.out.println(\"sum = \" + sum);\n        } catch (InterruptedException | ExecutionException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n\n### 二、线程的生命周期\n![图解](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/LIHsiIkUz5NMhXqUO2pAJBGA)\n\n1. 新建状态\n用new关键字和Thread类或其子类建立一个线程对象后，该线程对象就处于新建状态。处于新生状态的线程有自己的内存空间，通过调用start方法进入就绪状态（runnable）。\n>注意：不能对已经启动的线程再次调用start()方法，否则会出现IllegalThreadStateException异常。\n2.  就绪状态\n处于就绪状态的线程已经具备了运行条件，但还没有分配到CPU，处于线程就绪队列（尽管是采用队列形式，事实上，把它称为可运行池而不是可运行队列。因为cpu的调度不一定是按照先进先出的顺序来调度的），等待系统为其分配CPU。等待状态并不是执行状态，当系统选定一个等待执行的Thread对象后，它就会从等待执行状态进入执行状态，系统挑选的动作称之为“cpu调度”。一旦获得CPU，线程就进入运行状态并自动调用自己的run方法。\n3. 运行状态\n处于就绪状态的线程，如果获得了cpu的调度，就会从就绪状态变为运行状态，执行run()方法中的任务。如果该线程失去了cpu资源，就会又从运行状态变为就绪状态。重新等待系统分配资源。也可以对在运行状态的线程调用yield()方法，它就会让出cpu资源，再次变为就绪状态。\n\n注： 当发生如下情况是，线程会从运行状态变为阻塞状态：\n\n- CPU执行片已经用完，JVM切换到其他线程执行\n- 线程调用sleep()\n- 线程调用了阻塞IO方法，该方法返回之前，线程会一直阻塞\n- 线程试图获取被其他线程持有的同步监视器\n- 线程在等待某个通知（notify）\n- 程序调用了线程的suspend()将线程挂起。（容易死锁，不推荐）\n\n4. 阻塞状态\n在阻塞状态的线程不能进入就绪队列。只有当引起阻塞的原因消除时，如睡眠时间已到，或等待的I/O设备空闲下来，线程便转入就绪状态，重新到就绪队列中排队等待，被系统选中后从原来停止的位置开始继续运行。\n5. 死亡状态\n当线程的run()方法执行完，或者被强制性地终止，就认为它死去。这个线程对象也许是活的，但是，它已经不是一个单独执行的线程。线程一旦死亡，就不能复生。 如果在一个死去的线程上调用start()方法，会抛出java.lang.IllegalThreadStateException异常。\n\n### 三、线程管理\n1. 线程睡眠---sleep方法\n如果我们需要让当前正在执行的线程暂停一段时间，并进入阻塞状态，则可以通过调用Thread的sleep方法。\n\n>注意：\n（1）sleep是静态方法，最好不要用Thread的实例对象调用它，因为它睡眠的始终是当前正在运行的线程，而不是调用它的线程对象，它只对正在运行状态的线程对象有效。\n（2）Java线程调度是Java多线程的核心，只有良好的调度，才能充分发挥系统的性能，提高程序的执行效率。但是不管程序员怎么编写调度，只能最大限度的影响线程执行的次序，而不能做到精准控制。因为使用sleep方法之后，线程是进入阻塞状态的，只有当睡眠的时间结束，才会重新进入到就绪状态，而就绪状态进入到运行状态，是由系统控制的，我们不可能精准的去干涉它，所以如果调用Thread.sleep(1000)使得线程睡眠1秒，可能结果会大于1秒。\n\n2. 线程让步-yield\nyield()方法和sleep()方法有点相似，它也是Thread类提供的一个静态的方法，它也可以让当前正在执行的线程暂停，让出cpu资源给其他的线程。但是和sleep()方法不同的是，它不会进入到阻塞状态，而是进入到就绪状态。yield()方法只是让当前线程暂停一下，重新进入就绪的线程池中，让系统的线程调度器重新调度器重新调度一次，完全可能出现这样的情况：当某个线程调用yield()方法之后，线程调度器又将其调度出来重新进入到运行状态执行。\n>实际上，当某个线程调用了yield()方法暂停之后，优先级与当前线程相同，或者优先级比当前线程更高的就绪状态的线程更有可能获得执行的机会，当然，只是有可能，因为我们不可能精确的干涉cpu调度线程。用法如下：\n\n```\npublic class Test1 {  \n    public static void main(String[] args) throws InterruptedException {  \n        new MyThread(\"低级\", 1).start();  \n        new MyThread(\"中级\", 5).start();  \n        new MyThread(\"高级\", 10).start();  \n    }  \n}  \n  \nclass MyThread extends Thread {  \n    public MyThread(String name, int pro) {  \n        super(name);// 设置线程的名称  \n        this.setPriority(pro);// 设置优先级  \n    }  \n  \n    @Override  \n    public void run() {  \n        for (int i = 0; i < 30; i++) {  \n            System.out.println(this.getName() + \"线程第\" + i + \"次执行！\");  \n            if (i % 5 == 0)  \n                Thread.yield();  \n        }  \n    }  \n}\n```\n\n>注：关于sleep()方法和yield()方的区别如下：\n①、sleep方法暂停当前线程后，会进入阻塞状态，只有当睡眠时间到了，才会转入就绪状态。而yield方法调用后 ，是直接进入就绪状态，所以有可能刚进入就绪状态，又被调度到运行状态。\n②、sleep方法声明抛出了InterruptedException，所以调用sleep方法的时候要捕获该异常，或者显示声明抛出该异常。而yield方法则没有声明抛出任务异常。\n③、sleep方法比yield方法有更好的可移植性，通常不要依靠yield方法来控制并发线程的执行。\n\n### 总结\n\n实现Runnable接口相比继承Thread类有如下优势：\n\n1. 可以避免由于Java的单继承特性而带来的局限；\n2. 增强程序的健壮性，代码能够被多个线程共享，代码与数据是独立的；\n3. 适合多个相同程序代码的线程区处理同一资源的情况。\n\n实现Runnable接口和实现Callable接口的区别:\n1. Callable规定的方法是call(),Runnable规定的方法是run()\n2. Callable的任务执行后可返回值，而Runnable的任务是不能返回值(是void)\n3. call方法可以抛出异常，run方法不可以\n4. 运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。\n5. 加入线程池运行，Runnable使用ExecutorService的execute方法，Callable使用submit方法。\n\n#### 上述参考多处概念总结而出，如果需要更深层次的使用，可以看参考链接中的Java多线程详解\n## 参考\n[ java多线程—Thread、Runnable和Callable区别](https://blog.csdn.net/u012501054/article/details/80384996)\n\n[Java多线程详解](https://www.cnblogs.com/snow-flower/p/6114765.html)');
INSERT INTO `blog_content` VALUES (37, '## 概念介绍部分，不想看可以自行跳到后面实战\n### 为什么要使用线程池？\n1. 操作的是重用存在的线程，减少对象创建、消亡的开销，性能佳。\n2. 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。\n3. 提供定时执行、定期执行、单线程、并发数控制等功能。\n\n### Java的五种线程池介绍\n1. newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。(用过几次，可能因为电脑台渣，导致线程不够用时不够内存创建新线程报错)\n2. newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。\n3. newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。\n4. newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，此线程池保证所有任务的执行顺序按照任务的提交顺序执行。\n5. newWorkStealingPool创建一个拥有多个任务队列的线程池，可以减少连接数，创建当前可用cpu数量的线程来并行执行，适用于大耗时的操作，可以并行来执行\n\n>Excutors创建线程池貌似不被推荐，推荐实用threadPoolExecutor，后续有时间会补充相关内容。《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 new ThreadPoolExecutor 实例的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。\n\n### 线程池使用demo（代码都跑过，没问题，不贴结果图了）\n- newCachedThreadPool\n```\nclass test implements Runnable {\n    private static int i=0;\n    @Override\n    public void run() {\n        for (;i<100;i++)\n            System.out.println(i);\n    }\n}\npublic class PoolStudy {\n    public static void main(String[] args) {\n        ExecutorService pool = Executors.newCachedThreadPool();\n        long start = System.currentTimeMillis();\n        pool.execute(new test());\n        pool.execute(new test());\n        pool.execute(new test());\n        System.out.println(\"cache: \" + (System.currentTimeMillis() - start));\n    }\n}\n```\n\n>跑一遍会发现执行完成不会马上结束，默认需要等待60秒无操作才会终止或回收\n\n- newFixedThreadPool\n```\npublic class PoolStudy {\n    public static void main(String[] args) {\n        ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3);\n        for (int i = 0; i < 10; i++) {\n            final int index = i;\n            fixedThreadPool.execute(new Runnable() {\n                @Override\n                public void run() {\n                    try {\n                        System.out.println(index);\n                        Thread.sleep(2000);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n            });\n        }\n        fixedThreadPool.shutdown();\n    }\n}\n```\n\n>通过shutdown()方法释放线程，否则会一直存在\n\n- newScheduledThreadPool\n```\npublic class PoolStudy {\n    public static void main(String[] args) {\n        ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5);\n        scheduledThreadPool.schedule(new Runnable() {\n            @Override\n            public void run() {\n                System.out.println(\"delay 3 seconds\");\n            }\n        }, 3, TimeUnit.SECONDS);\n    }\n}\n```\n\n- newSingleThreadExecutor \n```\npublic class PoolStudy {\n    public static void main(String[] args) {\n        ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor();\n        for (int i = 0; i < 10; i++) {\n            final int index = i;\n            singleThreadExecutor.execute(new Runnable() {\n                @Override\n                public void run() {\n                    try {\n                        System.out.println(Thread.currentThread().getName()+index);\n                        Thread.sleep(1000);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n            });\n        }\n        singleThreadExecutor.shutdown();\n    }\n}\n```\n\n- newWorkStealingPool\n```\npublic class PoolStudy {\n    public static void main(String[] args) {\n        // 设置并行级别为2，即默认每时每刻只有2个线程同时执行\n        ExecutorService m = Executors.newWorkStealingPool(2);\n        for (int i = 1; i <= 10; i++) {\n            final int count=i;\n            Future future=m.submit(new Runnable() {\n                @Override\n                public void run() {\n                    Date now=new Date();\n                    System.out.println(\"线程\" + Thread.currentThread() + \"完成任务：\"\n                            + count+\"   时间为：\"+	now.getSeconds());\n                    try {\n                        Thread.sleep(1000);//此任务耗时1s\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n            });\n        }\n        while(true){\n            //主线程陷入死循环，来观察结果，否则是看不到结果的\n        }\n    }\n}\n```\n\n> 说明：线程执行任务有两种方法，一种是excute(new Runable(){...})，一种是submit(new Runable(){...})。不同点在于submit是可以接受到返回信息的，通过上述例子的future.get()可以获取到，如果执行成功返回的是null。\n\n### Java爬虫方法\n\n1. 通过自动化驱动selenium来完成操作，不推荐，速度慢，占用内存高\n2. jsoup，推荐，直接获取html进行解析，以下内容通过jsoup来完成\n\n#### 通过Jsoup+多线程方法爬取HTML内容解析（豆瓣图书的封面图片为例子）\n1. 前往[https://book.douban.com/](https://book.douban.com/)了解html结构\n![微信图片_20190827191502.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/dMAUaqIE5m4fAoHAiNCNwsd8)\n多观察几个，发现图片都是在class属性为cover的div下的img，这就很方便了，直接一步到位进入代码环节\n```\n    public static void main(String[] args) {\n        String url=\"https://book.douban.com/\";\n        // 2 解析 html\n        try {\n            Document doc = Jsoup.connect(url).get();\n            //从 Doc 的树形结构中查找 img 标签\n            //.class 选择器\n            Elements els = doc.select(\".cover img\");\n            System.out.println(els.size());\n            // 创建一个线程池\n            ExecutorService pool = Executors.newFixedThreadPool(9);\n            for(Element e : els) {\n                // <img src=\"\"  width=\"\"  height=\"\" />\n                String src = e.attr(\"src\");\n                System.out.println(src);\n                // 下载每张图片\n                pool.execute(new DownloadTask(src));\n            }\n            //释放资源\n            pool.shutdown();\n        } catch (IOException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n    }\n```\n\n#### 通过Jsoup+多线程方法爬取JSON内容解析（豆瓣电影为例子）\n\n![微信截图_20190827205211.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/RZslPpd3vjvgYAUl74xwD0E8)\n\n在network中，我们观察到请求数据的地址\n我们试一下直接访问该地址看看获得了什么数据\n![微信截图_20190827205310.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/i3IouiYFdfFfZWXVK9cUkRfg)\n\n果不其然，这就是我们需要的电影数据信息了，那么如何使用Jsoup来处理这些数据呢？\n在对JSON数据处理的时候，我的案例中使用的是阿里的fastJson\n```\npublic class Moive {\n    public static void main(String[] args) throws IOException {\n        String savePath = \"D:\" + File.separator + \"资源\" + File.separator + \"豆瓣电影排行榜\" + File.separator;\n        File file = new File(savePath);\n        if (!file.exists()) {\n            if (!file.mkdirs())\n                System.out.println(\"系统操作出现异常。\");\n        }\n        ExecutorService pool = Executors.newFixedThreadPool(10);\n        for (int i = 0; i < 10; i++) {\n            String url = \"https://movie.douban.com/j/search_subjects?type=movie&tag=%E8%B1%86%E7%93%A3%E9%AB%98%E5%88%86&sort=rank&page_limit=20&page_start=\" + String.valueOf(i * 20);\n            //尝试爬10页电影，按自己需求更改\n            Connection.Response res = Jsoup.connect(url).ignoreContentType(true).execute();\n            JSONObject json = JSONObject.parseObject(res.body());\n            JSONArray jsonArray = json.getJSONArray(\"subjects\");\n            for (Object o : jsonArray) {\n                JSONObject object = (JSONObject) o;\n                //电影名称\n                //System.out.println(object.getString(\"title\"));\n                //图片链接\n                //System.out.println(object.getString(\"cover\"));\n                // 下载每张图片\n                pool.execute(new Download(object.getString(\"title\"), object.getString(\"cover\")));\n            }\n        }\n        pool.shutdown();\n    }\n}\n```\n\n\n请求的方法都挺简单的，没有专门防止爬虫的拦截，不需要设置请求头之类的就可以直接捕获到数据，不得不说多线程在爬虫中真是一个利器，在对豆瓣电影进行的10页内容爬虫中，一共200张图片，总消耗时间不到20秒。。。下载文件的代码就不放了，如果有需要可以在留言中留下你的联系方式。\n\n>本案例仅作为参考，没有很深入的操作，例如如何翻页等等，如果需要进一步研究可以自行百度或留言联系我。完整DEMO也可以在留言中留下联系方式获取，如果看到会回复。\n\n## 参考\n[Java 四种线程池newCachedThreadPool,newFixedThreadPool,newScheduledThreadPool,newSingleThreadExecutor](https://www.cnblogs.com/zhujiabin/p/5404771.html)');
INSERT INTO `blog_content` VALUES (38, '### 简介\n看了多线程爬虫的文章后，对多线程应该有一定的了解了，那么，我们为什么要使用ThreadPoolExecutor来创建线程池而不使用Executors呢？居然阿里爸爸都说了不要使用Executors了，那肯定是有缺陷啊\n下面开始分析一下Executors的源代码（这里只放出关键代码，详细的自行查看）\n```\n    public static ExecutorService newFixedThreadPool(int nThreads) {\n        return new ThreadPoolExecutor(nThreads, nThreads,\n                                      0L, TimeUnit.MILLISECONDS,\n                                      new LinkedBlockingQueue<Runnable>());\n    }\n    public static ExecutorService newWorkStealingPool(int parallelism) {\n        return new ForkJoinPool\n            (parallelism,\n             ForkJoinPool.defaultForkJoinWorkerThreadFactory,\n             null, true);\n    }\n    public static ExecutorService newSingleThreadExecutor() {\n        return new FinalizableDelegatedExecutorService\n            (new ThreadPoolExecutor(1, 1,\n                                    0L, TimeUnit.MILLISECONDS,\n                                    new LinkedBlockingQueue<Runnable>()));\n    }\n    public static ExecutorService newCachedThreadPool() {\n        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                      60L, TimeUnit.SECONDS,\n                                      new SynchronousQueue<Runnable>());\n    }\n    public static ScheduledExecutorService newSingleThreadScheduledExecutor() {\n        return new DelegatedScheduledExecutorService\n            (new ScheduledThreadPoolExecutor(1));\n    }\n```\n\n这是Executors.java对线程池的默认实现方法，可以看出来他们其实也是调用ThreadPoolExecutor来完成线程池的创建的，但是也可以看出这很容易造成OOM的情况（out of memory）\n- newFixedThreadPool 和SingleThreadPool\n堆积的请求队列会造成内存增大,甚至OOM\n- newCachedThreadPool 和newScheduledThreadPool\n最大线程量 Integer.MAX_VALUE ,可能引发OOM\n\n下面来详细说明一下ThreadPoolExecutor\n```\n    public ThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue<Runnable> workQueue,\n                              RejectedExecutionHandler handler) {\n        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,\n             Executors.defaultThreadFactory(), handler);\n    }\n```\n\n这是ThreadPoolExecutor的构造函数，每个字段的意思是\n- corePoolSize：核心线程数量，当有新任务在execute()方法提交时，会执行以下判断：\n如果运行的线程少于 corePoolSize，则创建新线程来处理任务，即使线程池中的其他线程是空闲的；\n如果线程池中的线程数量大于等于 corePoolSize 且小于 maximumPoolSize，则只有当workQueue满时才创建新的线程去处理任务；\n如果设置的corePoolSize 和 maximumPoolSize相同，则创建的线程池的大小是固定的，这时如果有新任务提交，若workQueue未满，则将请求放入workQueue中，等待有空闲的线程去从workQueue中取任务并处理；\n如果运行的线程数量大于等于maximumPoolSize，这时如果workQueue已经满了，则通过handler所指定的策略来处理任务；\n所以，任务提交时，判断的顺序为 corePoolSize –> workQueue –> maximumPoolSize。\n- maximumPoolSize：最大线程数量；\n- workQueue：等待队列，当任务提交时，如果线程池中的线程数量大于等于corePoolSize的时候，把该任务封装成一个Worker对象放入等待队列；当提交一个新的任务到线程池以后, 线程池会根据当前线程池中正在运行着的线程的数量来决定对该任务的处理方式，主要有以下几种处理方式:\n	1. 直接切换：这种方式常用的队列是SynchronousQueue，但现在还没有研究过该队列，这里暂时还没法介绍；\n	2. 使用无界队列：一般使用基于链表的阻塞队列LinkedBlockingQueue。如果使用这种方式，那么线程池中能够创建的最大线程数就是corePoolSize，而maximumPoolSize就不会起作用了（后面也会说到）。当线程池中所有的核心线程都是RUNNING状态时，这时一个新的任务提交就会放入等待队列中。\n	3. 使用有界队列：一般使用ArrayBlockingQueue。使用该方式可以将线程池的最大线程数量限制为maximumPoolSize，这样能够降低资源的消耗，但同时这种方式也使得线程池对线程的调度变得更困难，因为线程池和队列的容量都是有限的值，所以要想使线程池处理任务的吞吐率达到一个相对合理的范围，又想使线程调度相对简单，并且还要尽可能的降低线程池对资源的消耗，就需要合理的设置这两个数量。\n		1. 如果要想降低系统资源的消耗（包括CPU的使用率，操作系统资源的消耗，上下文环境切换的开销等）, 可以设置较大的队列容量和较小的线程池容量, 但这样也会降低线程处理任务的吞吐量。\n		2. 如果提交的任务经常发生阻塞，那么可以考虑通过调用 setMaximumPoolSize() 方法来重新设定线程池的容量。\n		3. 如果队列的容量设置的较小，通常需要将线程池的容量设置大一点，这样CPU的使用率会相对的高一些。但如果线程池的容量设置的过大，则在提交的任务数量太多的情况下，并发量会增加，那么线程之间的调度就是一个要考虑的问题，因为这样反而有可能降低处理任务的吞吐量。\n- keepAliveTime：线程池维护线程所允许的空闲时间。当线程池中的线程数量大于corePoolSize的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了keepAliveTime；\n- threadFactory：它是ThreadFactory类型的变量，用来创建新线程。默认使用Executors.defaultThreadFactory() 来创建线程。使用默认的ThreadFactory来创建线程时，会使新创建的线程具有相同的NORM_PRIORITY优先级并且是非守护线程，同时也设置了线程的名称。\n- handler：它是RejectedExecutionHandler类型的变量，表示线程池的饱和策略。如果阻塞队列满了并且没有空闲的线程，这时如果继续提交任务，就需要采取一种策略处理该任务。线程池提供了4种策略：\n	1. AbortPolicy：直接抛出异常，这是默认策略；\n	2. CallerRunsPolicy：用调用者所在的线程来执行任务；\n	3. DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；\n	4. DiscardPolicy：直接丢弃任务；\n\n\n\n\n### 参考\n[ThreadPoolExecutor 使用](https://blog.csdn.net/qq_27712229/article/details/89081396)\n');
INSERT INTO `blog_content` VALUES (39, '### Tips\n#### 最近打算在项目中加入quartz任务调度，实现定时备份数据库，定时发送邮件提醒的功能，最近时间有限，先把cron的用法了解一下，详细的后面有空再做\n### 一、结构\n	\n    Seconds Minutes Hours DayofMonth Month DayofWeek Year(可选)\n    corn从左到右（用空格隔开）：秒 分 小时 月份中的日期 月份 星期几 年份(可选)\n\n### 二、各字段的含义\n![微信图片_20190829165207.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/cbmJbzPmgkUvSvzDXkcrpqGB)\n#### *注意事项\n每个字段可以出现的字符注意观察上表\n#### 特殊字符解释\n1. \\*：表示匹配该域的任意值。假如在Minutes域使用*, 即表示每分钟都会触发事件。\n2. ? ：用在Day-of-Month和Day-of-Week中，指“没有具体的值”。当两个子表达式其中一个被指定了值以后，为了避免冲突，需要将另外一个的值设为“?”。例如：想在每月20日触发调度，不管20号是星期几，只能用如下写法：0 0 0 20 * ?，其中最后以为只能用“?”，而不能用“*”\n3. \\- ：表示指定范围。\n4. , ：表示列出枚举值。例如：在Minutes子表达式中，“5,20”表示在5分钟和20分钟触发。\n5. / ：被用于指定增量。例如：在Minutes子表达式中，“0/15”表示从0分钟开始，每15分钟执行一次。\"3/20\"表示从第三分钟开始，每20分钟执行一次。和\"3,23,43\"（表示第3，23，43分钟触发）的含义一样。\n6. L ：用在day-of-month和day-of-week字串中。它是单词“last”的缩写。它在两个子表达式中的含义是不同的。\n	1. \\- 在day-of-month中，“L”表示一个月的最后一天，一月31号，3月30号。\n	2. 在day-of-week中，“L”表示一个星期的最后一天，也就是“7”或者“SAT”\n7. \\# ：只能用在day-of-week字段。用来指定这个月的第几个周几。例：在day-of-week字段用\"6#3\" or \"FRI#3\"指这个月第3个周五（6指周五，3指第3个）。如果指定的日期不存在，触发器就不会触发。\n8. W ：“Weekday”的缩写。只能用在day-of-month字段。用来描叙最接近指定天的工作日（周一到周五）。例如：在day-of-month字段用“15W”指“最接近这个月第15天的工作日”，即如果这个月第15天是周六，那么触发器将会在这个月第14天即周五触发；如果这个月第15天是周日，那么触发器将会在这个月第 16天即周一触发；如果这个月第15天是周二，那么就在触发器这天触发。注意一点：这个用法只会在当前月计算值，不会越过当前月。“W”字符仅能在 day-of-month指明一天，不能是一个范围或列表。也可以用“LW”来指定这个月的最后一个工作日，即最后一个星期五。\n\n### 三、例子\n以本博客涉及的一小些内容进行说明\n```\n    @Scheduled(cron = \"0 00 08 * * ? \")\n    public void sendEmail() {\n        System.out.println(\"现在是:\" + new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\").format(new Date()) + \",开始发送邮件\");\n        StringBuilder sendText = new StringBuilder();\n        String blogUrl = \"该条博客地址：http://blog.yhhu.xyz/#/blog/\";\n        List<SendComment> list = sendCommentService.findAll();\n        for (SendComment item : list) {\n            sendText.append(item.getReaderName()).append(\"在《\").append(item.getTitle()).append(\"》下回复----\")\n                    .append(item.getContent()).append(\"----\").append(blogUrl)\n                    .append(item.getBlogId()).append(\"\\n\");\n            sendCommentService.deleteById(item.getId());\n        }\n        if(list.size()>0) {\n            emailTool.sendSimpleMail(to,\"Blog每日评论\",String.valueOf(sendText));\n        }\n        System.out.println(\"今天的邮件已经发送完成了\");\n    }\n```\n\n> 这一段代码表明，在每天早上8点发送邮件\n\n```\n    @Scheduled(cron = \"0 00 00 ? * MON \")\n    public void saveDataBase() throws IOException, MessagingException {\n        System.out.println(\"现在是:\" + new SimpleDateFormat(\"yyyy-MM-dd\").format(new Date()) + \",开始备份数据库\");\n        File file = new File(savePath);\n        if (!file.exists())\n            file.mkdirs();\n        String window_cmd = \"cmd /c mysqldump -u\" + dataBaseUserName + \" -p\" + dataBasePassword + \" vueblog >\"\n                + savePath + new SimpleDateFormat(\"yyyy-MM-dd\").format(new Date())\n                + \".sql\";\n        String fileUrl=savePath + new SimpleDateFormat(\"yyyy-MM-dd\").format(new Date()) + \".sql\";\n        String[] centOS_cmd = {\"/bin/sh\",\"-c\",\"mysqldump -u\" + dataBaseUserName + \" -p\"\n                + dataBasePassword + \" \" + dataBaseName + \" > \"\n                + fileUrl};\n        Process process = Runtime.getRuntime().exec(centOS_cmd);\n        System.out.println(\"开始将数据库发送到管理员邮箱。\");\n        emailTool.sendAttachmentsMail(to,\"数据库备份\",\"当前时间为：\"+ new SimpleDateFormat(\"yyyy-MM-dd HH:mm\").format(new Date()),fileUrl);\n        File file1=new File(fileUrl);\n        if(!file1.delete()){\n            logger.error(\"删除备份数据异常\");\n        }\n    }\n```\n\n>每周一备份一次数据库\n\n\n### 网上找的一些例子\n```\n每隔5秒执行一次：*/5 * * * * ?\n\n每隔1分钟执行一次：0 */1 * * * ?\n\n每天23点执行一次：0 0 23 * * ?\n\n每天凌晨1点执行一次：0 0 1 * * ?\n\n每月1号凌晨1点执行一次：0 0 1 1 * ?\n\n每月最后一天23点执行一次：0 0 23 L * ?\n\n每周星期天凌晨1点实行一次：0 0 1 ? * L\n\n在26分、29分、33分执行一次：0 26,29,33 * * * ?\n\n每天的0点、13点、18点、21点都执行一次：0 0 0,13,18,21 * * ?\n```');
INSERT INTO `blog_content` VALUES (40, '## 环境安装\n\n略\n\n## 实战\n\n~~~bash\n$ mongo    //进入mongodb\n> help     //帮助\n> exit     //退出\n$ mongo\n> show dbs;  //显示所有数据库\n> use test;  //使用某个数据库\n> show collections;  //显示集合，相当于mysql的表\n> db.createCollection(\"hello\");  //创建集合\n> db.createCollection(\"blog\");   \n> db.createCollection(\"tag\");\n> show collections;\n> show dbs;\n> db.stats();  //该数据库的状态\n> db.dropDatabase();  //删除本数据库\n> show dbs;\n~~~\n\n~~~bash\n$ mongo\n> show dbs;\n> use test;\n> show collections;\n> db.createCollection(\"users\");\n> show collections;\n> db.users.renameCollection(\"staff\"); // users -> staff\n> show collections;\n> db.staff.drop();  //删除整个集合\n> show collections;\n> db.dropDatabase();\n> show dbs;\n~~~\n\n~~~bash\n$ mongo\n> use test;\n> show collections;\n> db.createCollection(\"hello\");\n> db.hello.insert(\n... {\n...     \"title\": \"测试一下添加\",\n...     \"content\": \"已经开始写博客了，太激动了。\"\n... }\n... );  //添加数据\n> show collections;\n> db.hello.find(); //显示hello集合中所有数据\n> for(var i = 0; i <=10; i++ ) {\n...     db.hello.insert({\n...         title: \"我的第\" + i + \"篇博客\"\n...     });\n... }		//批量插入数据\n> db.hello.find();\n> db.hello.count();   //统计条数\n> db.hello.remove({});   //删除所有\n> db.hello.count();\n> db.hello.find();\n~~~\n\n![微信图片_20190904090406.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/0mHxOVJdtwvpv8ashXPBTmhK)\n可以发现表中的字段是可以不一致的。\n\n条件查询\n* db.[collection_name].find({\"\":\"\"})\n* $gte, $gt, $lte, $lt\n* $eq, $ne\n* 正则表达式:/k/, /^k/\n* db.[collection_name].distinct(\"field_name\");\n* db.[collection_name].find({\"\":\"\", \"\":\"\"})\n* db.[collection_name].find({$or:[{...},{...}]});\n* db.[collection_name].find({\"\": {$in: [...]}});\n* db.[collection_name].find({\"\": {$exists: true}});\n\n~~~bash\n> db.hello.find({\"tag\": \"1\"});        //tag等于1\n> db.hello.find({\"tag\": {$gte: 4}});  //tag大于等于4\n> db.hello.find({\"tag\": {$gt: 4}});   //tag大于4\n> db.hello.find({\"tag\": {$lte: 4}});  //小于等于4\n> db.hello.find({\"tag\": {$lt: 4}});   //小于4\n> db.hello.find({\"title\": /u/});    //title中包含u\n> db.hello.find({\"title\": /^R/});   //以R开头\n> db.hello.find({\"title\": /^U/});   //以U开头\n> db.hello.distinct(\"target\");    //显示target的种类(除重，只输出一遍)\n\n> db.hello.find({\"title\": /3/, \"tag\":{$gte:5} });  //标题带有3并且tag大于等于5\n> db.hello.find({$or: [{\"title\": /u/}, {\"tag\":{$gte:4}}] });  //标题带有3或tag大于等于5\n> db.hello.find({\"tag\": {$in: [3,4]} }); //tag等于3或4\n> db.hello.insert({ \"title\":\"条件测试\", \"istop\": true });\n> db.hello.find({\"istop\": {$exists: true} });  //查找istop字段存在的数据\n~~~\n\n抽出指定的字段\n* db.[collection_name].find({}, {field1: true, field2: 1})\n\n~~~bash\n> db.hello.find();\n//true和1是一样的\n> db.hello.find({}, {title:true, tag:1});\n> db.hello.find({}, {title:true, tag:1, _id:0});\n~~~\n\n排序分页\n* sort()\n* limit()\n* skip()\n\n~~~bash\n> db.hello.find();\n//{_id:0}表示不输出id\n> db.hello.find({}, {_id:0}).sort({tag:1});   //tag升序排序，没有tag的会被排在最前面。。。\n> db.hello.find({}, {_id:0}).sort({tag:-1});  //倒序\n> db.hello.find({}, {_id:0}).limit(3);    //默认排序的前三条        \n> db.hello.find({}, {_id:0}).sort({tag:-1}).limit(3);  //倒序的后三条\n> db.hello.findOne({}, {_id:0});   //只取第一条\n> db.hello.find({}, {_id:0});\n> db.hello.find({}, {_id:0}).limit(3);\n> db.hello.find({}, {_id:0}).skip(3).limit(3);  //跳过前三条，再找三条。也就是分页了\n~~~\n\n文档更新\n* update(\\<filter>, \\<update>, \\<options>)\n\n更新操作很复杂，可以看官方文档\n\n~~~bash\n> db.hello.findOne({\"title\":\"我的第0篇博客\"});\n> db.hello.update({\"title\":\"我的第0篇博客\"}, {$set: {\"tag\": 10} });  //给title为xxxx的数据设置tag\n> db.hello.find();\n> db.hello.update({\"title\":\"我的第0篇博客\"}, {\"tag\": 99});    //***这个语句十分危险，会直接把原来的title为xxx的数据直接抹掉，替换成\"tag\":99。删除旧文档，生成新文档\n> db.hello.find();\n> db.hello.update({\"tag\":5}, {$set: {\"tag\": 50}});   //只更新一条\n> db.hello.find();\n> db.hello.update({\"tag\":5}, {$set: {\"tag\": 50}}, {multi: true}); //全部更新\n> db.hello.find();\n> db.hello.update({\"tag\":50}, {$set: {\"tag\": 60}}, {multi: true});\n> db.hello.find();\n> 批量更新(如果存在同名的，那就把title改成_id来判断唯一，mongodb是支持javascript的)\n> db.hello.find({\"title\":/我的/}).forEach( \n	function(item){\n		 db.hello.update({\"title\":item.title},{$set:{\"tag\":1}}) \n	} \n  )\n~~~\n\n特殊函数\n\n* $inc:递加\n* $mul:相乘\n* $rename:改名\n* $set:新增or修改\n* $unset:字段删除\n\n~~~bash\n> db.hello.find({title:\"我的第0篇博客\"}, {_id:0});\n> db.hello.update({title:\"我的第0篇博客\"}, {$inc: {tag: 1}});  //加法\n> db.hello.find({title:\"我的第0篇博客\"}, {_id:0});\n> db.hello.update({title:\"我的第0篇博客\"}, {$mul: {tag: 2}});  //乘法\n> db.hello.find({title:\"我的第0篇博客\"}, {_id:0});\n> db.hello.update({title:\"我的第0篇博客\"}, {$rename: {\"tag\": \"score\"}}); //字段重命名\n> db.hello.find({title:\"我的第0篇博客\"}, {_id:0});\n> db.hello.update({title:\"我的第0篇博客\"}, {$set: {\"istop\": true}});  //增加字段\n> db.hello.find({title:\"我的第0篇博客\"}, {_id:0});\n> db.hello.update({title:\"我的第0篇博客\"}, {$unset: {\"istop\": true}});  //删除字段\n> db.hello.find({title:\"我的第0篇博客\"}, {_id:0});\n~~~\n\n特殊更新\n\n* upsert:有则更新，无则追加\n* remove:条件删除数据\n\n~~~bash\n> db.hello.find({}, {_id:0});\n> db.hello.update({title:\"我的第n篇博客\"}, {title:\"我的第n篇博客\", \"score\":2,\"tag\":\"game\"}); //此时没有这条数据，find的时候也没有\n> db.hello.find({}, {_id:0});\n> db.hello.update({title:\"我的第n篇博客\"}, {title:\"我的第n篇博客\", \"score\":2,\"tag\":\"test\"}, {upsert:true});  //追加了一条新记录\n> db.hello.find({}, {_id:0});\n> db.hello.update({title:\"我的第n篇博客\"}, {title:\"我的第n篇博客\", \"score\":7,\"tag\":\"test\"}, {upsert:true});  //修改原有数据\n> db.hello.find({}, {_id:0});\n> db.hello.remove({title:\"我的第0篇博客\"});\n> db.hello.find({}, {_id:0});\n~~~\n\n使用索引（相当于主键，便于加快速度，滥用索引反而会影响性能）\n\n* getIndexes()\n* createIndex({...}, {...})\n* dropIndex({...})\n\n~~~bash\n> db.hello.getIndexes();  //默认_id为索引\n> db.hello.createIndex({rank:-1});\n> db.hello.getIndexes();\n> db.hello.dropIndex({rank:-1});\n> db.hello.getIndexes();\n> db.hello.createIndex({title:1}, {unique:true});\n> db.hello.getIndexes();\n> db.hello.find({}, {_id:0});\n> db.hello.insert({title:\"怪物猎人世界评测\"});\n~~~\n\n备份和恢复\n\n* mongodump\n* mongorestore\n\n~~~bash\n> db.hello.find({}, {_id:0});\n> exit\n$ mkdir dbbak\n$ cd dbbak\n$ mongodump -d test\n$ ls\n$ mongo test\n> db.hello.find({}, {_id:0});\n> db.hello.remove({});\n> db.hello.find({}, {_id:0});\n> exit\n$ mongorestore --drop\n$ mongo test\n> db.hello.find({}, {_id:0});\n> exit\n$ mongodump --help\n~~~\n\n\n## SpringBoot中使用MongoDB实现CRUD\n\n#### 引入spring集成的MongoDB依赖\n\n```\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-data-mongodb</artifactId>\n        </dependency>\n```\n\n#### properties配置\n```\nspring.data.mongodb.host=localhost\nspring.data.mongodb.database=test\nspring.data.mongodb.port=27017\n```\n\n#### 创建dao层\n```\n@Repository\npublic interface UserRepository extends MongoRepository<User, ObjectId> {\n\n}\n```\n\n代码有点乱，不贴了，之后补一个完整demo');
INSERT INTO `blog_content` VALUES (41, '## 什么是 oAuth\noAuth 协议为用户资源的授权提供了一个安全的、开放而又简易的标准。与以往的授权方式不同之处是 oAuth 的授权不会使第三方触及到用户的帐号信息（如用户名与密码），即第三方无需使用用户的用户名与密码就可以申请获得该用户资源的授权，因此 oAuth 是安全的。\n\n## 什么是 Spring Security\nSpring Security 是一个安全框架，前身是 Acegi Security，能够为 Spring 企业应用系统提供声明式的安全访问控制。Spring Security 基于 Servlet 过滤器、IOC 和 AOP，为 Web 请求和方法调用提供身份确认和授权处理，避免了代码耦合，减少了大量重复代码工作。\n\n## 客户端授权模式\n客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。oAuth 2.0 定义了四种授权方式。\n- implicit：简化模式，不推荐使用\n- authorization code：授权码模式（本文章采用这种模式）\n- resource owner password credentials：密码模式\n- client credentials：客户端模式\n\n## 个人对oAuth2认证过程的理解\n![微信截图_20190908104104.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/eZJgoJPD6oeOkYGzMBUZdy0t)\n\n## 编码部分\n1. 创建项目工程，本文章采用多module方式\n主要是配置一个pom，文章结束后代码会发到github，这里不复制了\n2. 创建统一依赖\n统一依赖中配置org.springframework.cloud\nspringboot2.1.x需要使用Greenwich版本\n3. 创建认证服务器模块（内存模拟版本）\n```\n@Configuration\n@EnableAuthorizationServer\npublic class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter {\n    // 注入 WebSecurityConfiguration 中配置的 BCryptPasswordEncoder\n    @Autowired\n    private BCryptPasswordEncoder passwordEncoder;\n\n    @Override\n    public void configure(ClientDetailsServiceConfigurer clients) throws Exception {\n        // 配置客户端\n        clients\n                // 使用内存设置\n                .inMemory()\n                // client_id\n                .withClient(\"client\")\n                // client_secret\n                .secret(passwordEncoder.encode(\"secret\"))\n                // 授权类型\n                .authorizedGrantTypes(\"authorization_code\")\n                // 授权范围\n                .scopes(\"app\")\n                // 注册回调地址\n                .redirectUris(\"http://blog.yhhu.xyz\");\n    }\n}\n```\n\n```\n@Configuration\n@EnableWebSecurity\n@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)\npublic class WebSecurityConfiguration extends WebSecurityConfigurerAdapter {\n    @Bean\n    public BCryptPasswordEncoder passwordEncoder() {\n        // 设置默认的加密方式\n        return new BCryptPasswordEncoder();\n    }\n\n    @Override\n    protected void configure(AuthenticationManagerBuilder auth) throws Exception {\n\n        auth.inMemoryAuthentication()\n                // 在内存中创建用户并为密码加密\n                .withUser(\"user\").password(passwordEncoder().encode(\"123456\")).roles(\"USER\")\n                .and()\n                .withUser(\"admin\").password(passwordEncoder().encode(\"123456\")).roles(\"ADMIN\");\n    }\n}\n```\n\n>SpringSecurity提供默认的登录界面，并且提供RestfulAPI\n\n```\nspring:\n  application:\n    name: oauth2-server\nserver:\n  port: 8080\n```\n\n==必须遵循这样的请求url==\n获取code：在浏览器直接访问http://localhost:8080/oauth/authorize?client_id=client&response_type=code\n通过code获取access_token：http://client:secret@localhost:8080/oauth/token\n>这里需要带两个参数,采用x-www-form-urlencoded方式，grant_type为authorization_code，code为上一步获取到的内容\nurl说明：client:secret不是固定的，这取决于你在AuthorizationServerConfiguration中withClient和secret的设置\n\n![微信截图_20190908123558.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/QcPQvmtVsDEy7IbadNNxVA5F)\n\n4. 创建认证服务器模块（JDBC版本）\n    1. 创建一个oauth数据库，官方给的表示H2的，mysql有点改动，百度找了一个\n    ```\n    CREATE TABLE `clientdetails` (\n      `appId` varchar(128) NOT NULL,\n      `resourceIds` varchar(256) DEFAULT NULL,\n      `appSecret` varchar(256) DEFAULT NULL,\n      `scope` varchar(256) DEFAULT NULL,\n      `grantTypes` varchar(256) DEFAULT NULL,\n      `redirectUrl` varchar(256) DEFAULT NULL,\n      `authorities` varchar(256) DEFAULT NULL,\n      `access_token_validity` int(11) DEFAULT NULL,\n      `refresh_token_validity` int(11) DEFAULT NULL,\n      `additionalInformation` varchar(4096) DEFAULT NULL,\n      `autoApproveScopes` varchar(256) DEFAULT NULL,\n      PRIMARY KEY (`appId`)\n    ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\n    CREATE TABLE `oauth_access_token` (\n      `token_id` varchar(256) DEFAULT NULL,\n      `token` blob,\n      `authentication_id` varchar(128) NOT NULL,\n      `user_name` varchar(256) DEFAULT NULL,\n      `client_id` varchar(256) DEFAULT NULL,\n      `authentication` blob,\n      `refresh_token` varchar(256) DEFAULT NULL,\n      PRIMARY KEY (`authentication_id`)\n    ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\n    CREATE TABLE `oauth_approvals` (\n      `userId` varchar(256) DEFAULT NULL,\n      `clientId` varchar(256) DEFAULT NULL,\n      `scope` varchar(256) DEFAULT NULL,\n      `status` varchar(10) DEFAULT NULL,\n      `expiresAt` timestamp NULL DEFAULT NULL,\n      `lastModifiedAt` timestamp NULL DEFAULT NULL\n    ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\n    CREATE TABLE `oauth_client_details` (\n      `client_id` varchar(128) NOT NULL,\n      `resource_ids` varchar(256) DEFAULT NULL,\n      `client_secret` varchar(256) DEFAULT NULL,\n      `scope` varchar(256) DEFAULT NULL,\n      `authorized_grant_types` varchar(256) DEFAULT NULL,\n      `web_server_redirect_uri` varchar(256) DEFAULT NULL,\n      `authorities` varchar(256) DEFAULT NULL,\n      `access_token_validity` int(11) DEFAULT NULL,\n      `refresh_token_validity` int(11) DEFAULT NULL,\n      `additional_information` varchar(4096) DEFAULT NULL,\n      `autoapprove` varchar(256) DEFAULT NULL,\n      PRIMARY KEY (`client_id`)\n    ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\n    CREATE TABLE `oauth_client_token` (\n      `token_id` varchar(256) DEFAULT NULL,\n      `token` blob,\n      `authentication_id` varchar(128) NOT NULL,\n      `user_name` varchar(256) DEFAULT NULL,\n      `client_id` varchar(256) DEFAULT NULL,\n      PRIMARY KEY (`authentication_id`)\n    ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\n    CREATE TABLE `oauth_code` (\n      `code` varchar(256) DEFAULT NULL,\n      `authentication` blob\n    ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\n    CREATE TABLE `oauth_refresh_token` (\n      `token_id` varchar(256) DEFAULT NULL,\n      `token` blob,\n      `authentication` blob\n    ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n    ```\n    2. 操作一下oauth_client_details表\n    需要设置的内容为client_id，client_secret，scope，authorized_grant_types，web_server_redirect_uri，注意client_secret是经过加密的\n    ![微信截图_20190908131112.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/AfzUmYxR1ZqNVt1ccpa5oRl3)\n\n至此完成验证功能，其他操作和内存版都是一样的，完成后可以在数据库中看到看到token相关信息\n\n## RBAC（Role-Based Access Control，基于角色的访问控制）\n增加了几个表，模型如下\n\n![微信图片_20190908141858.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/zR33HRXmlfxJbiPGGInoOXft)\n\n可以做的简单一点，可是这样做功能更加完备，单单在user表中插入role列的话不便于管理\n\n下面开始具体实现\n\n1. 在认证服务器端排除token检查的权限判断\n```Java\n    @Override\n    public void configure(WebSecurity web) throws Exception {\n        web.ignoring().antMatchers(\"/oauth/check_token\");\n    }\n```\n\n2. 创建一个service，查询用户使用（代码略）\n3. 将授权模式由内存模式改为userDetailService方式\n```Java\n    @Autowired\n    private DataSource dataSource;\n\n    @Bean\n    public TokenStore tokenStore() {\n        // 基于 JDBC 实现，令牌保存到数据\n        return new JdbcTokenStore(dataSource);\n    }\n\n    @Bean\n    public ClientDetailsService jdbcClientDetails() {\n        // 基于 JDBC 实现，需要事先在数据库配置客户端信息\n        return new JdbcClientDetailsService(dataSource);\n    }\n\n    @Override\n    public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception \n    {\n        // 设置令牌\n        endpoints.tokenStore(tokenStore());\n    }\n\n    @Override\n    protected void configure(AuthenticationManagerBuilder auth) throws Exception {\n        auth.userDetailsService(userDetailsService());\n    }\n```\n\n4. 认证中心UserDetail权限判断逻辑\n```Java\npublic class UserDetailServiceImpl implements UserDetailsService {\n    @Autowired\n    private TbUserService tbUserService;\n    @Autowired\n    private TbPermissionService tbPermissionService;\n    @Override\n    public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException {\n        TbUser tbUser = tbUserService.getByUsername(s);\n        List<GrantedAuthority> grantedAuthorities= Lists.newArrayList();\n        if (tbUser != null) {\n            List<TbPermission> tbPermissions = tbPermissionService.selectByUserId(tbUser.getId());\n            tbPermissions.forEach(item -> {\n                GrantedAuthority grantedAuthority = new SimpleGrantedAuthority(item.getEnname());\n                grantedAuthorities.add(grantedAuthority);\n            });\n            return new User(tbUser.getUsername(),tbUser.getPassword(),grantedAuthorities);\n        }\n        return null;\n    }\n}\n```\n\n5. 如何自定义一个权限控制方法？（通过permission中url对应的方式来判断权限）\n> 定义权限判断类\n\n```java\n@Component(\"permission\")\npublic class PermissionCheck {\n    private AntPathMatcher antPathMatcher = new AntPathMatcher();\n\n    public boolean hasPermission(HttpServletRequest request, Authentication authentication) {\n        boolean hasPermission = false;\n	//取出当前token对应用户所拥有的权限\n        Collection<? extends GrantedAuthority> authorities = authentication.getAuthorities();\n        for (GrantedAuthority authority : authorities) {\n            if (antPathMatcher.match(authority.getAuthority(), request.getRequestURI())) {\n                hasPermission = true;\n                break;\n            }\n        }\n        return hasPermission;\n    }\n}\n```\n\n> 在资源服务器中配置access(\"\")方法来调用hasPermission方法\n\n```java\npublic class ResourceServerConfiguration extends ResourceServerConfigurerAdapter {\n    @Override\n    public void configure(HttpSecurity http) throws Exception {\n        http.exceptionHandling()\n                .and()\n                //管理session的创建策略永远不会创建HttpSession，它不会使用HttpSession来获取SecurityContext\n                .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS)\n                //ALWAYS总是创建HttpSession\n                //IF_REQUIREDSpring Security只会在需要时创建一个HttpSession\n                //NEVERSpring Security不会创建HttpSession，但如果它已经存在，将可以使用HttpSession\n                .and()\n                .authorizeRequests()\n                .anyRequest().access(\"@permission.hasPermission(request,authentication)\");\n        // 以下为配置所需保护的资源路径及权限，需要与认证服务器配置的授权部分对应\n//                .antMatchers(\"/**\").hasAuthority(\"SystemContent\");\n    }\n}\n```\n\n## 完整代码地址\n[oauth2](https://github.com/yhuihu/oauth2)');
INSERT INTO `blog_content` VALUES (42, '## 为什么要做内网穿透\n在做项目的时候，目前主流的方案都是前后端分离的，那么前后端不在一台电脑上，测试的时候前端人员需要一个可以访问的server，这个时候，我们就可以做内网穿透，将本地端口暴露到公网中去，使得前端人员可以直接调用接口。\n\n## frp\n[frp](https://github.com/fatedier/frp)是一个开源的内网穿透软件，详细内容可以到github上去看。\n\n## 正题\n要做内网穿透，还是需要一个服务器的，这里假设你已经有一个服务器了\n1. 下载并解压frp\n\n![微信截图_20190911194636.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/yb10bicxcl1EfXqmTddDRKpf)\n\n这是解压后的目录结构，frps对应server端，frpc对应client端\n\n2. 修改frps.ini\n\n![Inked微信截图_20190911194745_LI.jpg](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/qeldUn2txVbWGofM5X3fDyJu)\n   - bind_port提供client端绑定的端口。\n   - vhost_http_port内网穿透后访问所使用的端口\n   - dashboard开头的为控制台的一些配置\n   - privilege_token是为了安全考虑，client端也要拥有同样的token才能连接上\n\n3. 启动服务器端\n\n```bash\n//后台运行方法\nnohup ./frps -c ./frps.ini &\n\ncat nohup.out\n```\n\n![微信截图_20190911195146.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/eA8ZPv5IkmhvyzG2WK3Dh1xQ)\n\n服务器端配置完成\n\n4. 客户端配置\n\n```\n[common]\n\nserver_addr = xxxxx //服务器地址\n\nserver_port = 7088  //对应bind_port\n\nprivilege_token = 8d262f2b-6dba-xxxxxxxxxx   //token\n\n[http]\ntype=http\nlocal_ip = 127.0.0.1    //本地地址，一般都是localhost\nlocal_port = 9001       //要做内网穿透的端口\ncustom_domains = test.yhhu.xyz  //对应域名，不用也可以，用了可以通过nginx去掉端口号（xxxx:6081）\n```\n \n\n5. 启动客户端\n\n\n![微信截图_20190911195426.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/phzP6yEnH2TmKAmYAKkBu4E6)\n\n6. 测试\n\n\n![微信截图_20190911195535.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/kA07yQnLgiXxzkVPd8mHZZoQ)\n\n![微信截图_20190911195556.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/wGHsgvpI1J4ODNwWMr84bVOQ)\n\n## 总结\n\n没什么难的，关键要注意一点，如果你配置了domain，也就是域名方式，那么应该会用到nginx，那么nginx的配置如下\n\n```bash\n  server {\n        listen       80;\n        #listen       [::]:80 default_server;\n        server_name  test.yhhu.xyz;\n        root         /usr/share/nginx/html;\n        include /etc/nginx/default.d/*.conf;\n        location / {\n            proxy_pass http://127.0.0.1:6081;\n            #下面这4个不可上，过来人的经验-，-\n            proxy_set_header Host $host:$server_port;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Real-PORT $remote_port;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        }\n        error_page 404 /404.html;\n            location = /40x.html {\n        }\n        error_page 500 502 503 504 /50x.html;\n            location = /50x.html {\n        }\n    }\n```');
INSERT INTO `blog_content` VALUES (43, '### 准备工作\n1. 了解Java是如何创建线程的\n2. 了解Java是如何初始化线程池的\n本节代码地址[手写线程](https://github.com/yhuihu/Java-Study/tree/master/Thread)\n\n### 为什么要用FutureTask\nFutureTask可以获取到线程执行的结果，而直接使用Runable是没办法获取到线程执行的结果的\n\n### 编码\n1. 先来看看目前我们是如何使用FutureTask的\n```Java\npublic class Test {\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n        Callable<String> work1=new Callable<String>() {\n            @Override\n            public String call() throws Exception {\n                System.out.println(\"测试方法1\");\n                return \"方法1执行完毕\";\n            }\n        };\n        Callable<String> work2=new Callable<String>() {\n            @Override\n            public String call() throws Exception {\n                System.out.println(\"测试方法2\");\n                return \"方法2执行完毕\";\n            }\n        };\n        FutureTask<String> task1=new FutureTask<>(work1);\n        FutureTask<String> task2=new FutureTask<>(work2);\n        new Thread(task1).start();\n        new Thread(task2).start();\n        String result1=task1.get();\n        String result2=task2.get();\n        System.out.println(result1);\n        System.out.println(result2);\n\n    }\n}\n```\n\n> 执行结果\n\n![微信截图_20190925162834.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/HCDlBO0QcMKvOCFrGTWjVM1C)\n\n2. 创建一个名为MyFutureTask的类，并做一个最简单的实现\n```Java\npublic class MyFutureTask<T> implements Runnable {\n    private Callable<T> callable;\n    private T result;\n\n    public MyFutureTask(Callable<T> callable) {\n        this.callable = callable;\n    }\n\n    @Override\n    public void run() {\n        //业务逻辑执行\n        try {\n            result = callable.call();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n这一部分最关键的是要明白将Callable作为参数构造实例，因为在run方法中我们是要通过callable的call方法来执行业务逻辑并获取结果的\n\n3. 完善\n先提出问题：在用FutureTask的时候，我们可能有一个疑问，我们是如何保证get()方法一定能获取到值得，那么这个问题就要涉及到我们如何让get方法进入阻塞状态，等待线程执行完成之后再返回值了。\n```Java\npublic class MyFutureTask<T> implements Runnable {\n    private static final String ERROR = \"EXP\";\n    private static final String FINISH = \"END\";\n    private static final String NEW = \"NEW\";\n    private Callable<T> callable;\n    private volatile String state = NEW;\n    private T result;\n    private LinkedBlockingQueue<Thread> waiters = new LinkedBlockingQueue<>();\n\n    public MyFutureTask(Callable<T> callable) {\n        this.callable = callable;\n    }\n\n    @Override\n    public void run() {\n        //业务逻辑执行\n        try {\n            result = callable.call();\n        } catch (Exception e) {\n            state = ERROR;\n            e.printStackTrace();\n        } finally {\n            if (!state.equals(ERROR)) {\n                state = FINISH;\n            }\n        }\n\n        Thread waiter = waiters.poll();\n        while (waiter != null) {\n            LockSupport.unpark(waiter);\n            waiter = waiters.poll();\n        }\n    }\n\n    public T get() throws Exception {\n        //没有执行完毕，需要等待\n        if (ERROR.equals(state)) {\n            throw new Exception(\"错误\");\n        }\n        while (!FINISH.equals(state)) {\n            waiters.add(Thread.currentThread());\n            LockSupport.park(); //进入阻塞状态\n        }\n        return result;\n    }\n}\n```\n\n- 我们定义了三个状态ERROR,FINISH,NEW分别对应当前线程的各种状态\n- LinkedBlockingQueue是一个基于链表的队列，这里用来存放所有线程\n\n>思路\n\n- 先看get方法\n当我们调用get方法的时候，我们会判断一下当前线程的执行情况，如果没有达到FINISH，那么我们会进入死循环，并将当前线程加入到队列当中去。\n\n- 再看run方法\nrun方法执行完成的时候，将结果保存到result，如果出现了异常，那么定义状态为ERROR，最终，我们要将队列中所有的线程都激活，激活过后会在此进入get方法里的while循环。\n\n4. 测试，用我们自己的MyFutureTask替换FutureTask\n```Java\npublic class Test {\n    public static void main(String[] args) throws Exception {\n        Callable<String> work1=new Callable<String>() {\n            @Override\n            public String call() throws Exception {\n                System.out.println(\"测试方法1\");\n                return \"方法1执行完毕\";\n            }\n        };\n        Callable<String> work2=new Callable<String>() {\n            @Override\n            public String call() throws Exception {\n                System.out.println(\"测试方法2\");\n                return \"方法2执行完毕\";\n            }\n        };\n        MyFutureTask<String> task1=new MyFutureTask<>(work1);\n        MyFutureTask<String> task2=new MyFutureTask<>(work2);\n        new Thread(task1).start();\n        new Thread(task2).start();\n        String result1=task1.get();\n        String result2=task2.get();\n        System.out.println(result1);\n        System.out.println(result2);\n\n    }\n}\n```\n\n![微信截图_20190925164446.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/P6xT6EVD3eHPkU8OTBCAYWKV)\n结果正确\n\n\n5. 手写线程池\n```Java\npublic class FixedSizeThreadPool {\n    private BlockingQueue<Runnable> blockingQueue;\n    private LinkedBlockingQueue<Thread> workers;\n\n    /**\n     * @param pollSize 线程池数量\n     * @param taskSize 任务数量\n     * @return\n     **/\n    public FixedSizeThreadPool(int pollSize, int taskSize) {\n        if (pollSize <= 0 || taskSize <= 0) {\n            throw new IllegalArgumentException(\"非法参数\");\n        }\n        this.blockingQueue = new LinkedBlockingQueue<>(taskSize);\n        this.workers = new LinkedBlockingQueue<>(pollSize);\n\n        for (int i = 0; i < pollSize; i++) {\n            Worker worker = new Worker(this);\n            worker.start();\n            ;\n            workers.add(worker);\n        }\n    }\n\n    public Boolean submit(Runnable task) {\n        if (isWorking) {\n            return this.blockingQueue.offer(task);\n        } else {\n            return false;\n        }\n    }\n\n    private volatile boolean isWorking = true;\n\n    public void shutdown() {\n        this.isWorking = false;\n        for (Thread thread : workers) {\n            if(thread.getState().equals(Thread.State.BLOCKED)){\n                thread.interrupt();\n            }\n        }\n    }\n\n    public static class Worker extends Thread {\n        private FixedSizeThreadPool pool;\n\n        public Worker(FixedSizeThreadPool pool) {\n            this.pool = pool;\n        }\n\n        @Override\n        public void run() {\n            while (this.pool.isWorking || this.pool.blockingQueue.size() > 0) {\n                Runnable task = null;\n                try {\n                    //阻塞方法获取任务\n                    if (this.pool.isWorking) {\n                        task = this.pool.blockingQueue.take();\n                    } else {\n                        task = this.pool.blockingQueue.poll();\n                    }\n\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                if (task != null) {\n                    task.run();\n                    System.out.println(\"线程\" + Thread.currentThread().getName() + \"执行完毕\");\n                }\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        FixedSizeThreadPool fixedSizeThreadPool = new FixedSizeThreadPool(3, 6);\n        for (int i = 0; i < 6; i++) {\n            fixedSizeThreadPool.submit(new Runnable() {\n                @Override\n                public void run() {\n                    System.out.println(\"放入一个线程\");\n                    try {\n                        Thread.sleep(2000L);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n            });\n        }\n        fixedSizeThreadPool.shutdown();\n    }\n}\n```\n\n好像没啥难度，认真看一下应该就能懂了。');
INSERT INTO `blog_content` VALUES (44, '### 相关代码地址\n[排序](https://github.com/yhuihu/Java-Study/tree/master/sort)\n### 冒泡排序\n- 比较相邻的元素。如果第一个比第二个大，就交换它们两个；\n- 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；\n- 针对所有的元素重复以上的步骤，除了最后一个；\n- 重复步骤1~3，直到排序完成。\n\n![640.gif](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/BbuMRqNNeUqSGIT8Ope1vToz)\n```java\n    /**\n     * 冒泡排序\n     *\n     * @param array\n     */\n    public static void bubbleSort(int[] array) {\n        int flag;\n        if (array.length == 0) {\n            return;\n        }\n        for (int i = 0; i < array.length; i++) {\n            flag = 0;\n            for (int j = 0; j < array.length - 1 - i; j++) {\n                if (array[j + 1] < array[j]) {\n                    int temp = array[j + 1];\n                    array[j + 1] = array[j];\n                    array[j] = temp;\n                    flag = 1;\n                }\n            }\n            if (flag == 0) {\n                break;\n            }\n        }\n    }\n```\n\n### 选择排序\nn个记录的直接选择排序可经过n-1趟直接选择排序得到有序结果。具体算法描述如下：\n- 初始状态：无序区为R[1..n]，有序区为空；\n- 第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区；\n- n-1趟结束，数组有序化了。\n\n\n![640 1.gif](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/7eCfHzQiNzTK94nahFGt6G2Y)\n```java\n    /**\n     * 选择排序\n     *\n     * @param array\n     */\n    public static void selectionSort(int[] array) {\n        if (array.length == 0) {\n            return;\n        }\n        for (int i = 0; i < array.length; i++) {\n            int minIndex = i;\n            for (int j = i; j < array.length; j++) {\n                //找到最小的数\n                if (array[j] < array[minIndex]) {\n                    //将最小数的索引保存\n                    minIndex = j;\n                }\n            }\n            if (minIndex != i) {\n                int temp = array[minIndex];\n                array[minIndex] = array[i];\n                array[i] = temp;\n            }\n        }\n    }\n```\n\n### 插入排序\n一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下：\n- 从第一个元素开始，该元素可以认为已经被排序；\n- 取出下一个元素，在已经排序的元素序列中从后向前扫描；\n- 如果该元素（已排序）大于新元素，将该元素移到下一位置；\n- 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；\n- 将新元素插入到该位置后；\n- 重复步骤2~5。\n\n![640 2.gif](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/wJ6facTkKijKw9CKSvoQIsgK)\n```java\n    /**\n     * 插入排序\n     *\n     * @param array\n     */\n    public static void insertionSort(int[] array) {\n        int i, j, k;\n        for (i = 1; i < array.length; i++) {\n            int temp = array[i];\n            for (j = i - 1; j >= 0; j--) {\n                if (array[j] > temp) {\n                    array[j + 1] = array[j];\n                } else {\n                    break;\n                }\n            }\n            array[j + 1] = temp;\n        }\n    }\n```\n\n### 希尔排序\n先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：\n- 选择一个增量序列t1，t2，…，tk，其中ti>tj，tk=1；\n- 按增量序列个数k，对序列进行k 趟排序；\n- 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。\n\n![微信截图_20191008114253.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/uUnNkJHtKpafEBTTFD6i4TI8)\n```java\n    /**\n     * 希尔排序\n     *\n     * @param array\n     */\n    public static void shellSort(int[] array) {\n        int len = array.length;\n        int temp, gap = len / 2;\n        while (gap > 0) {\n            for (int i = gap; i < len; i++) {\n                temp = array[i];\n                int preIndex = i - gap;\n                while (preIndex >= 0 && array[preIndex] > temp) {\n                    array[preIndex + gap] = array[preIndex];\n                    preIndex -= gap;\n                }\n                array[preIndex + gap] = temp;\n            }\n            gap /= 2;\n        }\n    }\n```\n\n### 归并排序\n归并排序（MERGE-SORT）是利用归并的思想实现的排序方法，该算法采用经典的分治（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案\"修补\"在一起，即分而治之)。\n\n![微信截图_20191008114737.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/7fW78Ne6jGGYwXA03idQQhh9)\n再来看看治阶段，我们需要将两个已经有序的子序列合并成一个有序序列，比如上图中的最后一次合并，要将[4,5,7,8]和[1,2,3,6]两个已经有序的子序列，合并为最终序列[1,2,3,4,5,6,7,8]，来看下实现步骤。\n![微信截图_20191008114948.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/rlwWDFKIYuhjWdYovoYuXlTp)\n![微信截图_20191008115001.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/0VEYPdhhxiWJzeT50Eh900ps)\n算法思路：\n- 把长度为n的输入序列分成两个长度为n/2的子序列；\n- 对这两个子序列分别采用归并排序；\n- 将两个排序好的子序列合并成一个最终的排序序列。\n\n![640 3.gif](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/Q1Fcq2bJZf2U21DmeLKXmwgR)\n\n```java\n    public static void sort(int[] arr) {\n        int[] temp = new int[arr.length];\n        //在排序前，先建好一个长度等于原数组长度的临时数组，\n        //避免递归中频繁开辟空间\n        sort(arr, 0, arr.length - 1, temp);\n    }\n\n    private static void sort(int[] arr, int left, int right, int[] temp) {\n        int mid = (left + right) / 2;\n        // 子数组长度大于1时，进行拆分\n        if (left < right) {\n            //左边归并排序，使得左子序列有序\n            sort(arr, left, mid, temp);\n            //右边归并排序，使得右子序列有序\n            sort(arr, mid + 1, right, temp);\n        }\n        //将两个有序子数组合并操作\n        merge(arr, left, mid, right, temp);\n    }\n\n    private static void merge(int[] arr, int left, int mid, int right, int[] temp) {\n        //左序列指针\n        int i = left;\n        //右序列指针\n        int j = mid + 1;\n        //临时数组指针\n        int t = 0;\n        while (i <= mid && j <= right) {\n            if (arr[i] <= arr[j]) {\n                temp[t++] = arr[i++];\n            } else {\n                temp[t++] = arr[j++];\n            }\n        }\n        //将左边剩余元素填充进temp中\n        while (i <= mid) {\n            temp[t++] = arr[i++];\n        }\n        //将右序列剩余元素填充进temp中\n        while (j <= right) {\n            temp[t++] = arr[j++];\n        }\n        t = 0;\n        //将temp中的元素全部拷贝到原数组中\n        while (left <= right) {\n            arr[left++] = temp[t++];\n        }\n    }\n```\n\n### 快速排序\n![19403173bf6002ba2c0b90b.gif](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/Jx5PuV9EdnbrkW7YUEsJr4YZ)\n```java\npublic class QuickSort {\n    private static int count;\n\n    /**\n     * 测试\n     *\n     * @param args\n     */\n    public static void main(String[] args) {\n        int[] num = {3, 45, 78, 64, 52, 11, 64, 55, 99, 11, 18};\n        System.out.println(arrayToString(num, \"未排序\"));\n        quickSort(num, 0, num.length - 1);\n        System.out.println(arrayToString(num, \"排序\"));\n        System.out.println(\"数组个数：\" + num.length);\n        System.out.println(\"循环次数：\" + count);\n\n    }\n\n    /**\n     * 快速排序\n     *\n     * @param num   排序的数组\n     * @param left  数组的前针\n     * @param right 数组后针\n     */\n    private static void quickSort(int[] num, int left, int right) {\n        //如果left等于right，即数组只有一个元素，直接返回\n        if (left >= right) {\n            return;\n        }\n        //设置最左边的元素为基准值\n        int key = num[left];\n        //数组中比key小的放在左边，比key大的放在右边，key值下标为i\n        int i = left;\n        int j = right;\n        while (i < j) {\n            //j向左移，直到遇到比key小的值\n            while (num[j] >= key && i < j) {\n                j--;\n            }\n            //i向右移，直到遇到比key大的值\n            while (num[i] <= key && i < j) {\n                i++;\n            }\n            //i和j指向的元素交换\n            if (i < j) {\n                int temp = num[i];\n                num[i] = num[j];\n                num[j] = temp;\n            }\n        }\n        num[left] = num[i];\n        num[i] = key;\n        count++;\n        quickSort(num, left, i - 1);\n        quickSort(num, i + 1, right);\n    }\n\n    /**\n     * 将一个int类型数组转化为字符串\n     *\n     * @param arr\n     * @param flag\n     * @return\n     */\n    private static String arrayToString(int[] arr, String flag) {\n        String str = \"数组为(\" + flag + \")：\";\n        for (int a : arr) {\n            str += a + \"\\t\";\n        }\n        return str;\n    }\n}\n```\n\n\n### 参考\n[十大经典排序算法最强总结](https://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&mid=2247487252&idx=1&sn=c54b06312dc4f450464b01b92734f7fb&chksm=fc7a62bacb0debac6dab940a5a8c46a85d111bdb79745398e094136079c99cd79dee59c0b883&mpshare=1&scene=1&srcid=1007i2NeSIuuOnBwiqhPqQfm&sharer_sharetime=1570497271031&sharer_shareid=b628fd8f6c15b9b5095c1e3c662fc26a&key=28a0f481c5d883ac3fe109b2f02f43b65163c5730df8a6e7101af690a3e423683aeed1114415c6086860ea9fdffede5b19f5422ec597711495e06ea7fbc399211b0f3357a644cb6d17695b7df3779f49&ascene=1&uin=NTcwMTgyNzQw&devicetype=Windows+10&version=62060833&lang=zh_CN&pass_ticket=xbz3%2BsSp4SBrm9W6XLQh74M3wUv8VWcjKqExvbxtK5O3gGM5z9R1gSYQimvbEYYx)');
INSERT INTO `blog_content` VALUES (45, '### 概述\n\n\n消息队列作为高并发系统的核心组件之一，能够帮助业务系统解构提升开发效率和系统稳定性。主要具有以下优势：\n\n\n- 削峰填谷： 主要解决瞬时写压力大于应用服务能力导致消息丢失、系统奔溃等问题\n- 系统解耦： 解决不同重要程度、不同能力级别系统之间依赖导致一死全死\n- 提升性能： 当存在一对多调用时，可以发一条消息给消息系统，让消息系统通知相关系统\n- 蓄流压测： 线上有些链路不好压测，可以通过堆积一定量消息再放开来压测\n\n### RocketMQ\nApache Alibaba RocketMQ 是一个消息中间件。消息中间件中有两个角色：消息生产者和消息消费者。RocketMQ 里同样有这两个概念，消息生产者负责创建消息并发送到 RocketMQ 服务器，RocketMQ 服务器会将消息持久化到磁盘，消息消费者从 RocketMQ 服务器拉取消息并提交给应用消费。\n\n### RocketMQ 特点\nRocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点：\n- 支持严格的消息顺序\n- 支持 Topic 与 Queue 两种模式\n- 亿级消息堆积能力\n- 比较友好的分布式特性\n- 同时支持 Push 与 Pull 方式消费消息\n\n### RocketMQ 优势\n目前主流的 MQ 主要是 RocketMQ、kafka、RabbitMQ，其主要优势有：\n- 支持事务型消息（消息发送和 DB 操作保持两方的最终一致性，RabbitMQ 和 Kafka 不支持）\n- 支持结合 RocketMQ 的多个系统之间数据最终一致性（多方事务，二方事务是前提）\n- 支持 18 个级别的延迟消息（RabbitMQ 和 Kafka 不支持）\n- 支持指定次数和时间间隔的失败消息重发（Kafka 不支持，RabbitMQ 需要手动确认）\n- 支持 Consumer 端 Tag 过滤，减少不必要的网络传输（RabbitMQ 和 Kafka 不支持）\n- 支持重复消费（RabbitMQ 不支持，Kafka 支持）\n\n### 安装\n等待更新\n\n### JAVA生产者配置\n等待更新\n\n### JAVA消费者配置\n等待更新\n\n### 完成可靠事务demo\n等待更新');
INSERT INTO `blog_content` VALUES (46, '（个人总结，仅供参考）\n\n# Java基础\n\n### 接口类和抽象类的差别\n\n1. 接口是绝对抽象的，不可以被实例化成对象。抽象类也不可以被实体化，可是如果抽象类中有main方法的话可以被调用。\n2. 接口中的所有方法都是隐藏抽象的。抽象类中可以包含抽象方法也可以包含非抽象方法。\n3. 一个类可以实现多个接口，可是只可以继承一个抽象类。\n4. 接口中声明的变量都是被final关键字修饰的。抽象类中的变量可以是非final的。\n5. 抽象类可以在不提供接口实现类的基础上提供接口的默认方法。\n6. 接口中的方法默认是public的。抽象类的方法可以是private，protected，public的。\n\n### Java类加载过程\n[深入浅出Java类加载过程](https://www.cnblogs.com/luohanguo/p/9469851.html)\n[JVM（三）：类加载机制（类加载过程和类加载器）](https://blog.csdn.net/boyupeng/article/details/47951037?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)\n\n\n### Map的分类和常见情况\n\n![7010483_1496974867310_D5D2D67073C3D04D7B608AD94C2886F0.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/ZM3KBAQzylT4wezkEQ1sbti4)\n\n1. Map的四个实现类为`HashMap`，`HashTable`，`LinkHashMap`和`TreeMap`。Map是以键值对的形式存储的，因此不允许键重复，可是值可以重，如果键相同会直接覆盖。\n2. 平时我们用的最多的Map是`HashMap`，它根据键值的`HashCode`来存储数据，可以通过键直接获取到对应的值，所以访问速度很快。遍历时取得数据的顺序是随机的。\n3. `HashMap`最多只允许一条记录的键为null，允许多条记录的值为null。\n4. `HashMap`不支持线程的同步，即任一时刻可以有多个线程同时写`HashMap`，这会导致数据的不一致。如果需要线程同步，可以使用`Collections`的`synchronizedMap`方法来使`HashMap`具有同步能力，或者用`ConcurrentHashMap`。\n5. `Hashtable`与`HashMap`类似。不同的是它不允许键或者值为空，支持线程同步，因此也导致了在写入的时候比较慢。\n6. `LinkedHashMap`是`HashMap`的子类，保存了记录的插入顺序。\n7. `TreeMap`可以按照键值来排序，也可以自定义排序的规则。\n\n### ==比较的是什么\n\n&emsp;&emsp;\"==\"对比两个对象的时候比较的是两个对象的内存引用是否完全相同。如果两边是基本类型，比较的是数值是否相等。\n\n\n### equals()方法默认是比较什么的？\n\n&emsp;&emsp;如果不重写equals()方法，默认比较的是对象的地址。\n\n### Java支持的数据类型有哪些？什么是自动拆装箱\n\n&emsp;&emsp;八种数据类型：`byte`，`short`，`int`，`long`，`float`，`double`，`char`，`boolean`。\n&emsp;&emsp;自动装箱是指在基本数据类型和对应的对象包装类型之间做的一个转化，反之就是自动拆箱。\n\n### Array和ArrayList的区别\n\n&emsp;&emsp;`Array`可以包含基本数据类型和对象，`ArrayList`只可以包含对象。\n&emsp;&emsp;`Array`大小是固定的，`ArrayList`的大小是动态变化的。\n\n### StringBuffer和StringBuilder的区别\n\n&emsp;&emsp;`StringBuffer`是线程安全的，`StringBuilder`是线程不安全的。`StringBuffer`其实就是比`StringBuilder`多了`Synchronized`修饰符\n\n### Synchronization和Lock\n\n&emsp;&emsp;`Lock`比`Synchronization`的方法多，可以在多种场景中使用到Lock的不同方法; synchronization可以在执行完自动释放锁，而Lock需要`lock.unlock()`;来释放锁，一般写在`try{}catch{}finally{ lock.unlock();}`的finally中\n\n### 访问权限\n\n![3807435_1531360217902_D706FD89218075198372990150A023A8.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/bMw9FC8B3eF2XAot3IWaqEyG)\n\n\n### 静态同步synchronized方法与synchronized（class）代码块\n- 关键字synchronized还可以应用在static静态方法上，如果这样写，那是对当前的*.java文件对应的Class类进行持锁。\n- synchronized关键字加到static静态方法上是给Class类上锁，而synchronized关键字加到非static静态方法上是给对象上锁。\n- 异步的原因是持有不同的锁，一个是对象锁，另外一个是Class锁，而Class锁可以对类的所有对象实例起作用。\n- 同步synchronized（class）代码块的作用其实和synchronized static方法的作用一样。\n\n### JVM分区（没有深入了解）\n\n![281726404166686.jpg](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/ZRfuu9vpMbpypowGaSYgku6H)\n\n### 重载和重写的区别，重载的要求是什么\n\n重载：\n\n1. 方法重载是让类以统一的方式处理不同类型数据的一种手段。多个同名函数同时存在，具有不同的参数个数/类型。（重载是一个类中多态性的一种表现）\n2. 重载的时候要求方法名一样，但是参数的类型和个数不一样，返回类型可以相同也可以不同。但是不能以返回类型作为重载函数的区分标准。\n\n重写：\n\n1. 父类与子类多态性的表现，对父类的函数进行重新定义。如果在子类中定义某方法与其父类有相同的名称和参数，这种方法叫重写。继承父类不需要重新编写相同的方法，但是可以重写。（方法重写又叫覆盖）\n2. 子函数的访问权限不能少于父类的。\n\n### \"static\"是什么意思？Java中可以覆盖一个private或者static的方法吗\n\n1. \"static\"关键字表明一个成员变量或者成员方法可以在没有所属类的实例的情况下被调用。\n2. \"static\"方法是不可以被覆盖的，因为方法覆盖是基于运行时动态绑定的，而static方法是在编译时静态绑定的。static方法跟类的任何实例都不挂钩，所以概念上不通用。\n\n### StringBuffer和StringBuilder有什么区别\n\n1. `StringBuffer`线程安全，`StringBuilder`线程不安全。\n2. 底层实现上`StringBuffer`比`StringBuilder`多了Synchronized修饰符。\n\n### 深拷贝与浅拷贝\n浅拷贝指的是：一个对象内如果存在另一个对象` father.children`，在拷贝的对象中，这个`children`对象和原对象的`children`对象不是同一个。\n深拷贝则相反。\n\n\n### 上界与下界\n\n> 上界不存，下界不取\n\n1. 上界<? extend Fruit>，表示所有继承Fruit的子类，但是具体是哪个子类，无法确定，所以调用add的时候，要add什么类型，谁也不知道。但是get的时候，不管是什么子类，肯定有个父类是Fruit，所以，我都可以用最大的父类Fruit接着，也就是把所有的子类向上转型为Fruit。\n2. 下界<? super Apple>，表示Apple的所有父类，包括Fruit，一直可以追溯到Object。那么当add的时候，我不能add Apple的父类，因为不能确定List里面存放的到底是哪个父类。但是我可以add Apple及其子类。因为不管我的子类是什么类型，它都可以向上转型为Apple及其所有父类甚至转型为Object。但是当我get的时候，Apple的父类这么多，我用什么接着呢，除了Object，其他的都接不住。\n\n### 面向对象的特征有哪些方面\n\n1. 抽象\n   抽象就是忽略一个主体中与当前目标无关的那些方面，以便更充分的注意与当前目标有关的方面。抽象并不打算了解全部问题，而只是选择其中的一部分，暂时不用部分细节。抽象包括两个方面，一是过程抽象，二是数据抽象\n2. 继承\n   继承是一种联结类的层次模型，并允许和鼓励类的重用，它提供了一种明确表述共性的方法，对象的一个新类可以从现有的类中派生，这个过程称为继承。新类继承了原始类的特性，新类称为原始类的派生类（子类），二原始类称为新类的基类（父类）。派生类可以从它的基类那里继承方法和实例变量，并且类可以修改或新增新的方法使之更适合特殊的需要。\n3. 封装\n   封装是把过程和数据包围起来，对数据的访问只能通过已定义的界面。\n4. 多态性\n   多态性指的是允许不同类的对象对同一消息作出响应。多态性包括参数化多态性和包含多态性。\n\n### final,finally,finalize的区别\n\n1. final用于声明属性，方法和类，分别表示属性不可变，方法不可覆盖，类不可继承。\n2. finally是异常处理语句的一部分，表示总是执行。\n3. finalize是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等。\n\n### 六原则一法则\n\n1. 单一职责原则（高内聚，低耦合）\n   一个类只做他该做的事情，不涉及与它无关的领域就是实践了高内聚的原则，这个类就只有单一职责。另一个是模块化，一个好的软件系统，他里面的每个功能模块也应该是可以轻易的拿到其他系统中使用的，这样才能实现软件复用的目标。\n2. 开闭原则\n   软件实体应当对外扩展开放，对修改关闭（在理想状态下，当我们需要为一个软件系统增加新功能的时候，只需要从原来的系统中派生出一些新类的就可以，不需要修改原来的任何代码）。要做到开闭有两个要点：\n   1. 抽象是关键，一个系统中如果没有抽象类或接口系统就没有扩展点。\n   2. 封装可变性，将系统中各种可变因素封装到一个继承结构中。\n3. 依赖倒置原则\n   面向接口编程。\n4. 里氏替换原则\n   任何时候都可以用子类替换掉父类\n5. 接口隔离原则\n   接口也应该是高内聚的\n6. 合成聚合复用原则\n7. 迪米特法则\n   最少知识原则\n\n### ArrayList和LinkedList的区别，如果一直在list的尾部添加元素，用哪个效率高\n\n1. `ArrayList`是基于数组实现的，查找效率比`LinkedList`效率高。\n2. `LinkedList`采用双向链表实现的，插入和删除的效率比`ArrayList`要高。\n3. `LinkedList`比`ArrayList`占内存，因为每个节点存储了两个引用，一个指向上一个元素，一个指向下一个元素。\n\n### HashMap解析\n[基于JDK8的HashMap源码解析](https://blog.csdn.net/zjxxyz123/article/details/81111627)\n\n### 进程与线程的区别\n1. 进程是资源分配的最小单位，线程是程序执行的最小单位（资源调度的最小单位）\n2. 进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作非常昂贵。而线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多。\n3. 线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式（IPC)进行。不过如何处理好同步与互斥是编写多线程程序的难点。\n4. 但是多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。\n\n### 并发与并行\n1. 并发：同一时刻只能有一个处于执行状态，但是它们交换着进行，因此在同一段时间内可看做是同时进行的。(先吃饭，电话来了接电话(不一定吃完饭)，电话结束再去吃饭。)\n2. 并行：同一时刻多个同时进行，多路线进行。(一边吃饭，一边打电话；)\n\n### 算法时间复杂度\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/kvmetYXJzxo1Bu3IXJoYvnWq)\n\n### 插入排序示例\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/zD5hi80SIR5pesrwtNfQIck4)\n\n### 死锁产生的原因\n- 系统资源的竞争\n- 进程运行推进顺序不合适\n\n### 死锁的四个必要条件\n- 互斥条件：一个资源每次只能被一个进程所使用。即在一段时间内某资源仅为一个进程所占用。此时若有其他进程请求资源，则请求进程只能等待。\n- 请求与保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程所占用，此时请求进程被阻塞，但对自己已获得的资源保持不放。\n- 循环等待条件：若干进程间形成首尾相接循环等待资源的关系。\n- 不可剥夺条件：进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放。\n\n### 如何判断线程已完成工作\n- 使用线程池的原生函数isTerminated()\n- 使用CountDownLatch\n- 维持一个公共计数（类似CountDownLatch）\n- submit向线程池提交任务，Future判断任务执行状态\n\n### 过滤器和拦截器的区别\n- Filter需要在web.xml中配置，依赖于Servlet；\n- Interceptor需要在SpringMVC中配置，依赖于框架；\n- Filter的执行顺序在Interceptor之前，具体的流程见下图；\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/oR0b4abD0VA9q8FTyevwUjW1)\n\n[拦截器（Interceptor）和过滤器（Filter）的执行顺序和区别](https://blog.csdn.net/zxd1435513775/article/details/80556034)\n\n# Spring\n\n### 介绍一下IOC，AOP\n一、\n1. 依赖注入存在三种方式，\n	1. 接口注入：接口注入有点复杂，被注入对象如果想要IOC容器为其注入依赖对象，就必须实现某个接口，这个接口提供一个方法，用来为被注入对象注入依赖对象，IOC容器通过接口方法将依赖对象注入到被注入对象中去。相对于前两种注入方式，接口注入比繁琐和死板，被注入对象就必须专声明和实现另外的接口\n	```\n	@Autowired\n	private DependencyA dependencyA;\n	@Autowired\n	private DependencyB dependencyB;\n	@Autowired\n	private DependencyC dependencyC;\n	```\n\n	2. Construct注入：即被注入对象可以通过在其构造方法中声明依赖对象的参数列表，让外部(通常是IOC容器)知道它需要哪些依赖对象，然后IOC容器会检查被注入对象的构造方法\n	```\n	private DependencyA dependencyA;\n	private DependencyB dependencyB;\n	private DependencyC dependencyC;\n \n	@Autowired\n	public DI(DependencyA dependencyA, DependencyB dependencyB, DependencyC dependencyC) {\n    	this.dependencyA = dependencyA;\n    	this.dependencyB = dependencyB;\n    	this.dependencyC = dependencyC;\n	}\n	```\n	3. setter注入：即当前对象只需要为其依赖对象所对应的属性添加setter方法，IOC容器通过此setter方法将相应的依赖对象设置到被注入对象的方式即setter方法注入\n	```\n	private DependencyA dependencyA;\n	private DependencyB dependencyB;\n	private DependencyC dependencyC;\n \n	@Autowired\n	public void setDependencyA(DependencyA dependencyA) {\n    	this.dependencyA = dependencyA;\n	}\n \n	@Autowired\n	public void setDependencyB(DependencyB dependencyB) {\n    	this.dependencyB = dependencyB;\n	}\n \n	@Autowired\n	public void setDependencyC(DependencyC dependencyC) {\n    	this.dependencyC = dependencyC;\n	}\n	```\n\n2. 为什么要使用IOC？\n	1. 脱开、降低类之间的耦合\n	2. 倡导面向接口编程、实施依赖倒置原则\n	3. 提高系统可插入、可测试、可修改特性\n\n[什么是控制反转(IoC)？什么是依赖注入（DI）？以及实现原理](https://blog.csdn.net/weixin_40834464/article/details/82831157)\n\n二、\n1. AOP指面向切面编程，可以说是OOP（Object Oriented Programmming，面向对象编程）的补充和完善。\n\n\n### Spring bean生命周期\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/SRp1uJhNSno11FQYDcQpUFh5)\n1. 实例化一个Bean－－也就是我们常说的new\n2. 按照Spring上下文对实例化的Bean进行配置－－也就是IOC注入\n3. 如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String)方法，此处传递的就是Spring配置文件中Bean的id值\n4. 如果这个Bean已经实现了BeanFactoryAware接口，会调用它实现的setBeanFactory(setBeanFactory(BeanFactory)传递的是Spring工厂自身（可以用这个方式来获取其它Bean，只需在Spring配置文件中配置一个普通的Bean就可以）\n5. 如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessBeforeInitialization(Object obj, String s)方法，BeanPostProcessor经常被用作是Bean内容的更改，并且由于这个是在Bean初始化结束时调用那个的方法，也可以被应用于内存或缓存技术\n6. 如果Bean在Spring配置文件中配置了init-method属性会自动调用其配置的初始化方法\n7. 如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessAfterInitialization(Object obj, String s)方法\n8. 当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用那个其实现的destroy()方法\n9. 最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法\n\n>执行顺序测试（来源：[Spring InitializingBean init-method @PostConstruct 执行顺序](https://www.cnblogs.com/april-chen/p/8182631.html)）\n```java\npackage com.example;\n/**\n通过实现 InitializingBean/DisposableBean 接口来定制初始化之后/销毁之前的操作方法；\n通过 元素的 init-method/destroy-method属性指定初始化之后 /销毁之前调用的操作方法；\n在指定方法上加上@PostConstruct 或@PreDestroy注解来制定该方法是在初始化之后还是销毁之前调用。 \n**/\npublic class InitSequenceBean implements InitializingBean {   \n    \n    public InitSequenceBean() {   \n       System.out.println(\"InitSequenceBean: constructor\");   \n    }   \n      \n    @PostConstruct  \n    public void postConstruct() {   \n       System.out.println(\"InitSequenceBean: postConstruct\");   \n    }   \n      \n    public void initMethod() {   \n       System.out.println(\"InitSequenceBean: init-method\");   \n    }   \n      \n    @Override  \n    public void afterPropertiesSet() throws Exception {   \n       System.out.println(\"InitSequenceBean: afterPropertiesSet\");   \n    }   \n}\n```\n\nxml文件配置\n\n```java\n<bean id=\"initSequenceBean \" class=\"com.example.InitSequenceBean\" init-method=\"initMethod\"/>\n```\n\n执行结果\n\n```java\nInitSequenceBean: constructor\n\nInitSequenceBean: postConstruct\n\nInitSequenceBean: afterPropertiesSet\n\nInitSequenceBean: init-method\n```\n\n### Autowired和Resource的区别\n1. 共同点：两者都可以写在字段和setter方法上。两者如果都写在字段上，那么就不用再写setter方法。\n2. 不同点：\n	1. @Autowired为Spring提供的注解，只按照byType注入。默认情况下它要求注入的对象一定要存在，如果允许Null，可以设置他的required属性为false。如果我们想使用按照名称来装配，可以结合@Qualifier注解一起使用\n	2. @Resource默认按照ByName自动注入，由J2EE提供，有两个重要属性，name和type，而Spring将@Resource注解的name属性解析为bean的名称，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。\n\n### Spring Bean 作用域\n- singleton\n- property\n- request\n- session\n- global-session\n\n\n# 计算机网络\n\n### 计算机网络五层协议，TCP协议在哪一层？IP协议在哪一层？HTTP协议在哪一层\n1. 物理层、数据链路层、网络层、传输层、应用层\n	1. 物理层：主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流（就是由1、0转化为电流强弱来进行传输,到达目的地后在转化为1、0，也就是我们常说的数模转换与模数转换）。这一层的数据叫做比特。\n	2. 数据链路层：定义了如何让格式化数据以进行传输，以及如何让控制对物理介质的访问。这一层通常还提供错误检测和纠正，以确保数据的可靠传输。 \n	3. 网络层：在位于不同地理位置的网络中的两个主机系统之间提供连接和路径选择。Internet的发展使得从世界各站点访问信息的用户数大大增加，而网络层正是管理这种连接的层。\n	4. 传输层：定义了一些传输数据的协议和端口号（WWW端口80等），如：\n		1. TCP（传输控制协议，传输效率低，可靠性强，用于传输可靠性要求高，数据量大的数据） \n		2. UDP（用户数据报协议，与TCP特性恰恰相反，用于传输可靠性要求不高，数据量小的数据，如QQ聊天数据就是通过这种方式传输的）。 主要是将从下层接收的数据进行分段和传输，到达目的地址后再进行重组。常常把这一层数据叫做段。\n	5. 应用层：是体系结构中的最高。直接为用户的应用进程（例如电子邮件、文件传输和终端仿真）提供服务。\n2. TCP协议属于运输层，IP协议属于网络层、HTTP协议属于应用层（引入一下https，https就是比http多了一层TLS/SSL来保证数据传输安全，TLS/SSL也属于协议，它的主要作用是保证数据传输安全。）\n\n### TCP的连接与释放\n1. 三次握手\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/s2BIi18pd1nUttDlRN1SgV4i)\n- 第一次握手：主机A发送位码为syn＝1，随机产生seq number=x的数据包到服务器，客户端进入SYN_SEND状态，等待服务器的确认；主机B由SYN=1知道A要求建立连接。\n\n- 第二次握手：主机B收到请求后要确认连接信息，向A发送ack number(主机A的seq+1)、syn=1、ack=1，随机产生seq=y的包，此时服务器进入SYN_RECV状态。\n\n- 第三次握手：主机A收到后检查ack number是否正确，即第一次发送的seq number+1，以及位码ack是否为1，若正确，主机A会再发送ack number(主机B的seq+1)、ack=1，主机B收到后确认seq值与ack=1则连接建立成功。客户端和服务器端都进入ESTABLISHED状态。\n\n> 三次握手的必要性\n- 第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。\n- 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。\n- 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收能力，服务器自己的发送能力也正常。\n\n\n2. 四次挥手\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/WSvm0itUhGUjZ7GtQY8EuMCE)\n\n# 数据库\n\n### 索引类型\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/P7ITzfAryvUuSjghM4RtFxrS)\n\n### 唯一索引与主键索引的比较\n1. 唯一索引不允许两行具有相同的索引值。如果现有数据中存在重复的键值，则大多数数据库都不允许将新创建的唯一索引与表一起保存。当新数据将使表中的键值重复时，数据库也拒绝接受此数据。例如，如果在 employee 表中的职员姓氏(lname) 列上创建了唯一索引，则所有职员不能同姓。\n2. 主键索引是唯一索引的特殊类型。数据库表通常有一列或列组合，其值用来唯一标识表中的每一行。该列称为表的主键。\n	1. 对于主健/unique constraint ， oracle/sql server/mysql等都会自动建立唯一索引；\n	2. 主键不一定只包含一个字段，所以如果你在主键的其中一个字段建唯一索引还是必要的；\n	3. 主健可作外健，唯一索引不可；\n	4. 主健不可为空，唯一索引可；\n	5. 主健也可是多个字段的组合；\n	6. 主键与唯一索引不同的是：\n		1. 有not null属性；\n		2. 每个表只能有一个。\n\n### 什么是事务\n事务是逻辑上的一组操作，要么都执行，要么都不执行。\n事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。\n\n### 事务的四大特性（ACID）\n1. 原子性（Atomicity）： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；\n2. 一致性（Consistency）： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；\n3. 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；\n4. 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。\n\n\n### 脏读，不可重复读，幻读\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/k5sZEWPTZhrGXT3OefvUrHLt)\n[快速理解脏读，不可重复读，幻读](https://blog.csdn.net/Vincent2014Linux/article/details/89669762)\n脏读（隔离级别为未提交读时）：事务A读取了事务B中尚未提交的数据。如果事务B回滚，则A读取了错误的数据。\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/b3dDjTCOWfaItcabwV0P9zSp)\n\n> 比如我给你转了100万，但是我还没有提交，此时你查询自己账户，多了100万，很开心。然后我发现转错人了，回滚了事物。然后你100万就没了。  在过程中你查到了没有提交事物的数据（多出的100万），这就是脏读。\n\n不可重复度（隔离级别为提交读）：不可重复读是指在事务1内，读取了一个数据，事务1还没有结束时，事务2也访问了这个数据，修改了这个数据，并提交。紧接着，事务1又读这个数据。由于事务2的修改，那么事务1两次读到的的数据可能是不一样的，因此称为是不可重复读。\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/HUgNKAM5MQAxBwwYK3FdINds)\n\n幻读（隔离级别为可重复度）：所谓幻读，指的是当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行。InnoDB存储引擎通过多版本并发控制（MVCC）解决了幻读的问题。\n\n> 当隔离级别设置为可串行化，强制事务串行执行，避免了前面说的幻读的问题。\n\n注意：不可重复读和幻读的区别是：前者是指读到了已经提交的事务的更改数据（修改或删除），后者是指读到了其他已经提交事务的新增数据。\n对于这两种问题解决采用不同的办法，防止读到更改数据，只需对操作的数据添加行级锁，防止操作中的数据发生变化；而防止读到新增数据，往往需要添加表级锁，将整张表锁定，防止新增数据（oracle采用多版本数据的方式实现）。\n\n### MySQL索引引擎\n[MySQL存储引擎－－MyISAM与InnoDB区别](https://www.cnblogs.com/peijz/p/12355772.html)\n\n### 索引建立越多越好吗\n- 数据量小的表不需要建立索引，因为建立索引会增加额外的开销。\n- 数据变更需要维护索引，因此更多的索引意味着更多的维护成本。\n- 更多的索引意味着更多的存储空间。\n\n### 视图与表的区别\n- 视图是一个逻辑概念的存在，没有物理记录，表是占有物理空间的数据\n- 视图是一个预编译好的sql，而表不是\n- 视图的增加和删除只影响视图本身，不影响基本表\n- 视图是查看数据表的一种方法，可以查询数据表中某些字段构成的数据，只是一些SQL语句的集合。从安全的角度说，视图可以不给用户接触数据表，从而不知道表结构\n');
INSERT INTO `blog_content` VALUES (47, '## 2019/5/8\n#### 下列关于Spring特性中IOC描述错误的是：\n\n```\nA.IoC就是指程序之间的关系由程序代码直接操控\nB.所谓“控制反转”是指控制权由应用代码转到外部容器，即控制权的转移\nC.IoC将控制创建的职责搬进了框架中，从应用代码脱离开来\nD.使用Spring的IoC容器时只需指出组件需要的对象，在运行时Spring的IoC容器会根据XML配置数据提供给它\n```\n> 解析\n\n```\nA\n控制反转即IoC (Inversion of Control)，是面向对象编程中的一种设计原则，可以用来减低计算机代码之间的耦合度。\n它把传统上由程序代码直接操控的对象的调用权交给容器，通过容器来实现对象组件的装配和管理。\n所谓的“控制反转”概念就是对组件对象控制权的转移，从程序代码本身转移到了外部容器。\n```\n\n---\n#### 转发和重定向的区别\n\n```\n String username=request.getParameter(\"username\");\n //转发与重定向\n if(username.equals(\"admin\")){\n  //提示用户已存在，不能注册\n  request.setAttribute(\"message\",\"该用户已存在，不能注册\");//添加提示信息，需要在userCreate.jsp页面中进行提示信息展示\n  request.getRequestDispatcher(\"userCreate.jsp\").forward(request, response);//转发\n }else{\n  //提示注册成功\n  request.setAttribute(\"message\",\"注册成功\");\n  response.sendRedirect(\"indext.jsp\");//重定向\n }\n```\n> 区别\n\n\n1. 重定向的执行过程：Web服务器向浏览器发送一个http响应--》浏览器接受此响应后再发送一个新的http请求到服务器--》服务器根据此请求寻找资源并发送给浏览器。它可以重定向到任意URL，不能共享request范围内的数据。\n\n2. 重定向是在客户端发挥作用，通过新的地址实现页面转向。\n\n3. 重定向是通过浏览器重新请求地址，在地址栏中可以显示转向后的地址。\n\n4. 转发过程：Web服务器调用内部方法在容器内部完成请求和转发动作--》将目标资源发送给浏览器，它只能在同一个Web应用中使用，可以共享request范围内的数据。\n\n5. 转发是在服务器端发挥作用，通过forward()方法将提交信息在多个页面间进行传递。\n\n6. 转发是在服务器内部控制权的转移，客户端浏览器的地址栏不会显示出转向后的地址。\n\n\n---\n#### 下面哪一项对Servlet描述错误？\n\n```\nServlet是一个特殊的Java 类 ，它必须直接或间接实现Servlet接口\nServlet接口定义了Servelt的生命周期方法\n当多个客户请求一个Servlet时，服务器为每一个客户启动一个进程\nServlet客户线程调用service方法响应客户的请求\n```\n> 解析\n\n```\n1.import javax.servlet.http.httpservletrequest，你看这个包说明servlet是一个特殊的Java类， java和javax都是Java的API包，java是核心包，javax的x是extension的意思，也就是扩展包。\n2.servlet接口定义了servlet的生命周期方法：init（）、service（）、destory（）三个方法\n3.当多个浏览器终端请求web服务器的时候，服务器为每个客户启动一个线程，不是进程。(选择中喜欢偷换概念，在这个上面做文章。)\n4.service（）中的方法就是用来写相应客户请求的方法的。前后两个是申请资源初始化，和释放资源关闭。\n```\n#### 下面有关SPRING的事务传播特性，说法错误的是？\n\n```\nPROPAGATION_SUPPORTS：支持当前事务，如果当前没有事务，就以非事务方式执行\nPROPAGATION_REQUIRED：支持当前事务，如果当前没有事务，就抛出异常\nPROPAGATION_REQUIRES_NEW：新建事务，如果当前存在事务，把当前事务挂起\nPROPAGATION_NESTED：支持当前事务，新增Savepoint点，与当前事务同步提交或回滚\n```\n> 解析\n\nSpring 支持 7 种事务传播行为：\n1. PROPAGATION_REQUIRED 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。\n2. PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。\n3. PROPAGATION_MANDATORY 使用当前的事务，如果当前没有事务，就抛出异常。\n4. PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。\n5. PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。\n6. PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。\n7. PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED 类似的操作。\n\n---\n#### SpringMVC的原理\n![image](https://uploadfiles.nowcoder.com/images/20171010/163192_1507646670364_7216367DD4FDC0CC274F999B0D00CFE5)\n\n## 2019/5/16\n#### HashMap和HashSet的区别\nHashMap是实现Map<K,V>接口的一个实体类，它对键值做了一对一的映射关系，当然里面键值不能重复。Map 接口提供三种collection 视图，允许以键集、值集或键-值映射关系集的形式查看某个映射的内容。映射顺序 定义为迭代器在映射的 collection 视图上返回其元素的顺序。某些映射实现可明确保证其顺序，如 TreeMap 类；另一些映射实现则不保证顺序，如 HashMap 类。\n![image](https://s2.ax1x.com/2019/05/18/EOFLb8.md.png)\n\nHashSet是实现Set<E>接口的一个实体类，数据是以哈希表的形式存放的，里面的不能包含重复数据。Set接口是一种一个不包含重复元素的 collection。\n\n![image](https://s2.ax1x.com/2019/05/18/EOFXVS.md.png)\n\n#### 汇总：\n\n![image](https://s2.ax1x.com/2019/05/18/EOFjUg.png)\n\n## 2019/5/18\n#### 有以下代码:\n\n```\nclass A{\n    public A(String str){\n         \n    }\n}\npublic class Test{\n    public static void main(String[] args) {\n        A classa=new A(\"he\");\n        A classb=new A(\"he\");\n        System.out.println(classa==classb);\n    }\n}\n```\n\n#### 请问输出的结果是: false\n\n因为== 表示的是否指向的是同一个内存。\nSystem.out.println(classa.equals(classb));   如果这这样输出答案也是错误的,因为子类没有覆盖Object\n的equals()方法,而默认调用==的这个方法判断两个对象是否相等需要覆盖equals()方法和hashcaode()方法\n\n---\n\n## 2019/5/20\n#### 基本数据类型均可任意互相转换。\n#### 错\n原生类是指Java中，数据类型分为基本数据类型（或叫做原生类、内置类型）和引用数据类型。\n那么原生类为基本数据类型，有八种，这样转换的时候就有表达范围问题。\n1、所占位数少的可以转换为所占位数多的类型，比如byte转char,char转int等；\n2、而所占位数多的转为所占位数少的默认情况下不能实现转换，需要强制类型转换，这样可能会丢失一部分原始数据；\n3、此外，boolean类型数据和其他七种不能互相转换。\n\n#### 八种数据类型\n\n![image](https://s2.ax1x.com/2019/05/20/EvGAqf.md.png)\n\n#### 关于java线程\n创建线程的方法有三种：\n（1）继承Thread类,重写run方法；\n（2）实现Runnable接口，并将对象实例作为参数传递给Thread类的构造方法；\n（3）实现callable接口，并实现call方法，并且线程执行完毕后会有返回值。 \n> 注意：（1）和（2）都是调用start()方法启动线程的，然后JVM虚拟机将此线程放到就绪队列中，有处理机可用时，则执行run方法。这两种方法都重写了run方法，但是没有返回值。\n\n![EvGuGj.jpg](https://s2.ax1x.com/2019/05/20/EvGuGj.jpg)\n\n\n---\n\n#### 假设有以下代码\n\n```\nString s=”hello”;\nString t=”hello”;\nchar c[] ={‘h’,’e’,’l’,’l’,’o’};\n```\n下列选项中返回false的语句是：t.equals(c);\n\n```\ns.equals(t);\nt.equals(c);\ns==t;\nt.equals(new String(“hello”));\n```\n\n```\nString s=”hello”;//首先会在字符串缓冲区找找有没有hello，结果没有找到，就创建了一个hello，然后引用是s\nString t=”hello”;//会在字符串缓冲区找hello，结果找到了，就返回了引用，也就是s；所以这句话等同于t=s；所以两个引用一样；所以t==s是true\nChar c[] ={‘h’,’e’,’l’,’l’,o’’};//这就是一个数组,而且数组在堆上\nequlse函数可以看源码！比较值相等之前会先比较类型是不是一样；如果类型一样才会比较值；如果类型不一致就直接return false；\n所以综上所述：ACD返回true Bfalse\n```\n\n---\n\n#### transient变量和下面哪一项有关（A）？\n```\nSerializable\nCloneable\nRunnable\nThrowable\nComparable\n```\n> 我们都知道一个对象只要实现了Serilizable接口，这个对象就可以被序列化，java的这种序列化模式为开发者提供了很多便利，我们可以不必关系具体序列化的过程，只要这个类实现了Serilizable接口，这个类的所有属性和方法都会自动序列化。\n这个类的有些属性需要序列化，而其他属性不需要被序列化；\njava 的transient关键字为我们提供了便利，你只需要实现Serilizable接口，将不需要序列化的属性前添加关键字transient，序列化对象的时候，这个属性就不会序列化到指定的目的地中。\n\n---\n\n\n<html>\n<a href=\"https://imgchr.com/i/EvGqYQ\"><img src=\"https://s2.ax1x.com/2019/05/20/EvGqYQ.png\" alt=\"EvGqYQ.png\" border=\"0\" /></a>\n</html>\n\n\n---\n<html>\n<a href=\"https://s2.ax1x.com/2019/05/20/EvJG6I.png\"><img src=\"https://s2.ax1x.com/2019/05/20/EvJG6I.png\" alt=\"EvGqYQ.png\" border=\"0\" /></a>\n</html>\n\n![EvJwtg.png](https://s2.ax1x.com/2019/05/20/EvJwtg.png)\n\n\n---\n![EvJfNF.png](https://s2.ax1x.com/2019/05/20/EvJfNF.png)\n\n\n---\n## 2019/5/20\n\n![VpBEnO.png](https://s2.ax1x.com/2019/05/22/VpBEnO.png)\n\n\nArrayList和LinkedList在性能上各有优缺点，都有各自所适用的地方，总的说来可以描述如下：\n\n1．对ArrayList和LinkedList而言，在列表末尾增加一个元素所花的开销都是固定的。对ArrayList而言，主要是在内部数组中增加一项，指向所添加的元素，偶尔可能会导致对数组重新进行分配；而对LinkedList而言，这个开销是统一的，分配一个内部Entry对象。\n\n2．在ArrayList的中间插入或删除一个元素意味着这个列表中剩余的元素都会被移动；而在LinkedList的中间插入或删除一个元素的开销是固定的。\n\n3．LinkedList不支持高效的随机元素访问。\n\n4．ArrayList的空间浪费主要体现在在list列表的结尾预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗相当的空间\n\n可以这样说：当操作是在一列数据的后面添加数据而不是在前面或中间,并且需要随机地访问其中的元素时,使用ArrayList会提供比较好的性能；当你的操作是在一列数据的前面或中间添加或删除数据,并且按照顺序访问其中的元素时,就应该使用LinkedList了。\n\n---\n![image](https://s2.ax1x.com/2019/05/22/Vprjnf.png)\n\n\n---\n\n![VpsFcq.png](https://s2.ax1x.com/2019/05/22/VpsFcq.png)\n\n![VpsZHU.png](https://s2.ax1x.com/2019/05/22/VpsZHU.png)\n\n---\n\n![VAemMd.png](https://s2.ax1x.com/2019/05/25/VAemMd.png)\n\n![VAeZxH.png](https://s2.ax1x.com/2019/05/25/VAeZxH.png)\n\n---\n![VVsUne.png](https://s2.ax1x.com/2019/05/27/VVsUne.png)\n\n![image](https://s2.ax1x.com/2019/05/27/VVsd7d.png)\n\n---\n\n![image](https://s2.ax1x.com/2019/05/31/VQ6PeI.jpg)\n\n![image](https://s2.ax1x.com/2019/05/31/VQ6EY8.jpg)\n\n\n---\n\nprivate方法只可以在类的内部使用，在类外根本访问不到， 而final方法可以在类外访问，但是不可以重写该方法，就是说可以使用该方法的功能但是不可以改变其功能，这就是private方法和final方法的最大区别\n\n---\n![image](https://s2.ax1x.com/2019/06/03/VJk9js.png)\n![VJk7PU.png](https://s2.ax1x.com/2019/06/03/VJk7PU.png)\n\n---\n![VJkPun.png](https://s2.ax1x.com/2019/06/03/VJkPun.png)\n\n![VJkiBq.png](https://s2.ax1x.com/2019/06/03/VJkiBq.png)\n\n---\n![VJkAEV.png](https://s2.ax1x.com/2019/06/03/VJkAEV.png)\n![VJkENT.png](https://s2.ax1x.com/2019/06/03/VJkENT.png)\n==system是属于java.lang.sysytem==\n\n---\n![VJkV4U.png](https://s2.ax1x.com/2019/06/03/VJkV4U.png)\n==run和start区分==\n\n![VJk5V0.png](https://s2.ax1x.com/2019/06/03/VJk5V0.png)\n![VJkIaV.png](https://s2.ax1x.com/2019/06/03/VJkIaV.png)\n\n---\n\n![image](https://s2.ax1x.com/2019/06/20/VvCXxf.png)](https://imgchr.com/i/VvCXxf)\n> DriverManager.getConnection方法返回一个Connection对象，这是加载驱动之后才能进行的\n\n---\n![image](https://s2.ax1x.com/2019/06/20/VvPiin.png)\n![VvP7OU.png](https://s2.ax1x.com/2019/06/20/VvP7OU.png)\n\n---\n![VvZ5E8.png](https://s2.ax1x.com/2019/06/20/VvZ5E8.png)\n![VvZH3j.png](https://s2.ax1x.com/2019/06/20/VvZH3j.png)\n\n---\n![VveTZ6.png](https://s2.ax1x.com/2019/06/20/VveTZ6.png)\n![VveLJe.png](https://s2.ax1x.com/2019/06/20/VveLJe.png)\n![VveXzd.png](https://s2.ax1x.com/2019/06/20/VveXzd.png)\n\n---\n![VzWf5d.png](https://s2.ax1x.com/2019/06/21/VzWf5d.png)\n![image](https://s2.ax1x.com/2019/06/21/VzWcDO.png)\n\n\n---\n![image](https://s2.ax1x.com/2019/06/30/ZlTCAs.png)\n![ZlTPNn.png](https://s2.ax1x.com/2019/06/30/ZlTPNn.png)\n\n---\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/0HW8VlMLXKFwytO9wXmUAK6m)\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/rdVWz3gh0ZjiQyHtYwUqlq16)\n\n---\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/COJD9sL3krd3vJp3Ja8fTKrn)\n\n---\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/ZhMfEjtPC3s2VJzL41BiRvAD)\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/w4vKZ0BoZWc3YxOutmvpcyDM)\n\n---\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/F1woihIvqIPaeZyXUpgn0ntO)\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/wxY5IjQ7D0DgNAvicRW5e9Ef)\n\n---\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/PvNpSO2v7zy9k7UJjOHPr0wj)\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/O3seoqiOeiU3Nzya3GKvserz)\n\n---\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/5pYhsqV7rWDDX9yGQy3sScqE)\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/Aq2iliB81V88glNAVgPxGqmy)\n\n---\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/iXB0NrLNUG8M8XxvXvCW2Mis)\n\n---\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/sKkuzNLL3hsdSjBxb8c1CFMr)\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/tymrewqqJnQwg6i1uZxl2f5c)\n\n---\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/cK4JahKZ1U9nKvYzpPDnZeGA)\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/VRxDTMI4TFZ8x4P5gokeZ5Qd)\n>注意二分法区域的选择\n\n---\n');
INSERT INTO `blog_content` VALUES (48, '## Dockerfile\n### 一、简介\n#### 1.1 dockerfile中常用的命令合集\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/8rx9JEBshSGuBu6terzm0OKI)\n#### 1.2 docker build 基于dockerfile制作镜像的命令\n`docker build [OPTIONS] PATH | URL | -参数`\n#### 1.3 参数选项\n- --build-arg=[] :设置镜像创建时的变量；\n\n- --cpu-shares :设置 cpu 使用权重；\n\n- --cpu-period :限制 CPU CFS周期；\n\n- --cpu-quota :限制 CPU CFS配额；\n\n- --cpuset-cpus :指定使用的CPU id；\n\n- --cpuset-mems :指定使用的内存 id；\n\n- --disable-content-trust :忽略校验，默认开启；\n\n- -f :指定要使用的Dockerfile路径；\n\n- --force-rm :设置镜像过程中删除中间容器；\n\n- --isolation :使用容器隔离技术；\n\n- --label=[] :设置镜像使用的元数据；\n\n- -m :设置内存最大值；\n\n- --memory-swap :设置Swap的最大值为内存+swap，\"-1\"表示不限swap；\n\n- --no-cache :创建镜像的过程不使用缓存；\n\n- --pull :尝试去更新镜像的新版本；\n\n- --quiet, -q :安静模式，成功后只输出镜像 ID；\n\n- --rm :设置镜像成功后删除中间容器；\n\n- --shm-size :设置/dev/shm的大小，默认值是64M；\n\n- --ulimit :Ulimit配置。\n\n- --tag, -t: 镜像的名字及标签，通常 name:tag 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。\n\n- --network: 默认 default。在构建期间设置RUN指令的网络模式\n```yml\n#例如\nFROM centos:7\nARG user # ARG user=root\nUSER $user\n```\n\n```shell\ndocker build --build-arg user=yhhu .\n```\n\n1.4 这里讲一下`CMD`、`ENTRYPOINT`和`RUN`的区别，其他相关内容可以查看下方参考链接\n- 一个Dockerfile中只能有一个CMD命令。( docker run时运行，dockerfile 中如果存在多个CMD指令，仅最后一个生效。CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。)\n- 一个Dockerfile中可以有许多个RUN命令。(docker buld时运行)\n- ENTRYPOINT 指令：类似于 CMD 指令，但其不会被 docker run 的命令行参数指定的指令所覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序；但是, 如果运行 docker run 时使用了 --entrypoint 选项，此选项的参数可当作要运行的程序覆盖 ENTRYPOINT 指令指定的程序；\n\n### 参考\n[Docker系列07—Dockerfile 详解](https://www.cnblogs.com/along21/p/10243761.html)\n\n## Docker-compose\n### 安装方法\n#### [官方文档](https://docs.docker.com/compose/install/)\n\n## 简单介绍docker-compose文件的编写方法\n> 这里以一个mysql+redis的配置方法举例\n\n### 一. 先判断docker-compose是否安装完成\n```shell\n$ docker-compose --version\n```\n### 二. docker-compose常见参数\n```yml\n#版本号\nversion: \"3.1\"\n#服务列表\nservices:\n  #服务名\n  mysql:\n    #容器名称\n    container_name: mysql-docker\n    #使用的镜像\n    image: mysql\n    #没启动时是否自动重启\n    restart: always\n    #映射端口    :前的为本地端口，:后的为容器的端口\n    ports:\n      - \"3306:3306\"\n    #添加环境变量\n    environment:\n      MYSQL_ROOT_PASSWORD: 123456\n      TZ: \"Asia/Shanghai\"\n    #挂载文件目录\n    volumes:\n      - \"./storages/data/mysql:/var/lib/mysql\"\n      - \"./storages/config/my.cnf:/etc/my.cnf\"\n  redis:\n    image: redis\n    restart: always\n    command: --appendonly yes\n    ports:\n      - 6379:6379\n    volumes:\n      - \"./storages/data/redis:/data\"\n```\n');
INSERT INTO `blog_content` VALUES (49, '## 前言\n本文章内容参考自[RocketMQ系统精讲，经受历年双十一狂欢节考验的分布式消息中间件](https://www.bilibili.com/video/av66702383/?p=97)，对已有内容进行修改，精简部分内容，并且使用`spring-cloud-starter-stream-rocketmq`来代替B站视频中的spring-boot集成包。修改后的个人完整demo地址：[github](https://github.com/yhuihu/Java-Study/tree/master/RocketMQ)\n\n# 1. MQ介绍\n\n## 1.1 为什么要用MQ\n\n消息队列是一种“先进先出”的数据结构\n\n![queue1.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/e5xlNj3f9VTPgxDLVmfGzko3)\n\n其应用场景主要包含以下3个方面\n\n* 应用解耦\n\n系统的耦合性越高，容错性就越低。以电商应用为例，用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障或者因为升级等原因暂时不可用，都会造成下单操作异常，影响用户使用体验。\n\n::: hljs-center\n![解耦1.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/3fPewYEq749gjfSvEc5mGw5I)\n:::\n\n使用消息队列解耦合，系统的耦合性就会提高了。比如物流系统发生故障，需要几分钟才能来修复，在这段时间内，物流系统要处理的数据被缓存到消息队列中，用户的下单操作正常完成。当物流系统回复后，补充处理存在消息队列中的订单消息即可，终端系统感知不到物流系统发生过几分钟故障。\n\n::: hljs-center\n![解耦2.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/pY3unaQT4DrvJjEznAmyun7q)\n:::\n\n* 流量削峰\n::: hljs-center\n![mq5.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/NgpxkBRSMR9vtxcEi1ZRV6sz)\n:::\n\n应用系统如果遇到系统请求流量的瞬间猛增，有可能会将系统压垮。有了消息队列可以将大量请求缓存起来，分散到很长一段时间处理，这样可以大大提到系统的稳定性和用户体验。\n::: hljs-center\n![mq6.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/KLiEDUJJpmIeT54o8gvsghPk)\n:::\n![](img/mq-6.png)\n\n一般情况，为了保证系统的稳定性，如果系统负载超过阈值，就会阻止用户请求，这会影响用户体验，而如果使用消息队列将请求缓存起来，等待系统处理完毕后通知用户下单完毕，这样总不能下单体验要好。\n\n<u>处于经济考量目的：</u>\n\n业务系统正常时段的QPS如果是1000，流量最高峰是10000，为了应对流量高峰配置高性能的服务器显然不划算，这时可以使用消息队列对峰值流量削峰\n\n* 数据分发\n::: hljs-center\n![mq1.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/I9zCrARSQNIdUsiA6v5XCitl)\n:::\n\n通过消息队列可以让数据在多个系统更加之间进行流通。数据的产生方不需要关心谁来使用数据，只需要将数据发送到消息队列，数据使用方直接在消息队列中直接获取数据即可\n![mq2.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/MRoO3xrjW7F97Au7hQr8OASQ)\n\n## 1.2 MQ的优点和缺点\n\n优点：解耦、削峰、数据分发\n\n缺点包含以下几点：\n\n* 系统可用性降低\n\n  系统引入的外部依赖越多，系统稳定性越差。一旦MQ宕机，就会对业务造成影响。\n\n  如何保证MQ的高可用？\n\n* 系统复杂度提高\n\n  MQ的加入大大增加了系统的复杂度，以前系统间是同步的远程调用，现在是通过MQ进行异步调用。\n\n  如何保证消息没有被重复消费？怎么处理消息丢失情况？那么保证消息传递的顺序性？\n\n* 一致性问题\n\n  A系统处理完业务，通过MQ给B、C、D三个系统发消息数据，如果B系统、C系统处理成功，D系统处理失败。\n\n  如何保证消息数据处理的一致性？\n\n# 2. RocketMQ快速入门\n\nRocketMQ是阿里巴巴2016年MQ中间件，使用Java语言开发，在阿里内部，RocketMQ承接了例如“双11”等高并发场景的消息流转，能够处理万亿级别的消息。\n\n## 2.1 安装RocketMQ\n\n### 2.1.1 在虚拟机上安装docker\n\n参考我的博客中docker安装的文章[CentOS下docker安装](http://blog.yhhu.xyz/#/blog/33)\n\n### 2.1.2 创建目录结构以及编写docker-compose文件\n\n完整文件目录结构如下(自行忽略无用部分。。。)：\n::: hljs-center\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/iOtUG41sYLHMlOMcFjkg9zlj)\n:::\n\n\n```yml\nversion: \"3.5\"\nservices:  \n  #RocketMQ\n  rmqnamesrv:\n    image: foxiswho/rocketmq:server-4.5.2\n    container_name: rmqnamesrv\n    ports:\n      - 9876:9876\n    volumes:\n      - ./data/rocketmq/namesrv/logs:/opt/logs\n      - ./data/rocketmq/namesrv/store:/opt/store\n    environment:\n      JAVA_OPT_EXT: \"-Duser.home=/opt -Xms128m -Xmx128m -Xmn128m\"\n    restart: always\n    networks:\n        rmq:\n          aliases:\n            - rmqnamesrv\n  rmqbroker:\n    image: foxiswho/rocketmq:broker-4.5.2\n    container_name: rmqbroker\n    ports:\n      - 10909:10909\n      - 10911:10911\n    volumes:\n      - ./data/rocketmq/broker/logs:/opt/logs\n      - ./data/rocketmq/broker/store:/opt/store\n      - ./rocketmq/broker.conf:/etc/rocketmq/broker.conf\n    environment:\n      JAVA_OPT_EXT: \"-Duser.home=/opt -server -Xms128m -Xmx128m -Xmn128m\"\n    command: [\"/bin/bash\",\"mqbroker\",\"-c\",\"/etc/rocketmq/broker.conf\",\"-n\",\"rmqnamesrv:9876\",\"autoCreateTopicEnable=true\"]\n    restart: always\n    depends_on:\n      - rmqnamesrv\n    networks:\n      rmq:\n        aliases:\n          - rmqbroker\n\n  rmqconsole:\n    image: styletang/rocketmq-console-ng\n    container_name: rmqconsole\n    ports:\n      - 8180:8080\n    environment:\n        JAVA_OPTS: \"-Drocketmq.namesrv.addr=rmqnamesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false\"\n    depends_on:\n      - rmqnamesrv\n    networks:\n      rmq:\n        aliases:\n          - rmqconsole\n\nnetworks:\n  rmq:\n    name: rmq\n    driver: bridge\n```\n\nbroker.conf配置文件内容\n```yml\n# 所属集群名字\nbrokerClusterName=DefaultCluster\n\n# broker 名字，注意此处不同的配置文件填写的不一样，如果在 broker-a.properties 使用: broker-a,\n# 在 broker-b.properties 使用: broker-b\nbrokerName=broker-a\n\n# 0 表示 Master，> 0 表示 Slave\nbrokerId=0\n\n# nameServer地址，分号分割\n# namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876\n\n# 启动IP,如果 docker 报 com.alibaba.rocketmq.remoting.exception.RemotingConnectException: connect to <192.168.0.120:10909> failed\n# 解决方式1 加上一句 producer.setVipChannelEnabled(false);，解决方式2 brokerIP1 设置宿主机IP，不要使用docker 内部IP\nbrokerIP1=my.service.com\n\n# 在发送消息时，自动创建服务器不存在的topic，默认创建的队列数\ndefaultTopicQueueNums=4\n\n# 是否允许 Broker 自动创建 Topic，建议线下开启，线上关闭 ！！！这里仔细看是 false，false，false\nautoCreateTopicEnable=true\n\n# 是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭\nautoCreateSubscriptionGroup=true\n\n# sql过滤支持\nenablePropertyFilter = true\n\n# Broker 对外服务的监听端口\nlistenPort=10911\n\n# 删除文件时间点，默认凌晨4点\ndeleteWhen=04\n\n# 文件保留时间，默认48小时\nfileReservedTime=120\n\n# commitLog 每个文件的大小默认1G\nmapedFileSizeCommitLog=1073741824\n\n# ConsumeQueue 每个文件默认存 30W 条，根据业务情况调整\nmapedFileSizeConsumeQueue=300000\n\n# destroyMapedFileIntervalForcibly=120000\n# redeleteHangedFileInterval=120000\n# 检测物理文件磁盘空间\ndiskMaxUsedSpaceRatio=88\n# 存储路径\n# storePathRootDir=/home/ztztdata/rocketmq-all-4.1.0-incubating/store\n# commitLog 存储路径\n# storePathCommitLog=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/commitlog\n# 消费队列存储\n# storePathConsumeQueue=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/consumequeue\n# 消息索引存储路径\n# storePathIndex=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/index\n# checkpoint 文件存储路径\n# storeCheckpoint=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/checkpoint\n# abort 文件存储路径\n# abortFile=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/abort\n# 限制的消息大小\nmaxMessageSize=65536\n\n# flushCommitLogLeastPages=4\n# flushConsumeQueueLeastPages=2\n# flushCommitLogThoroughInterval=10000\n# flushConsumeQueueThoroughInterval=60000\n\n# Broker 的角色\n# - ASYNC_MASTER 异步复制Master\n# - SYNC_MASTER 同步双写Master\n# - SLAVE\nbrokerRole=ASYNC_MASTER\n\n# 刷盘方式\n# - ASYNC_FLUSH 异步刷盘\n# - SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n\n# 发消息线程池数量\n# sendMessageThreadPoolNums=128\n# 拉消息线程池数量\n# pullMessageThreadPoolNums=128\n```\n\n### 2.1.3 执行`docker-compose up -d`等待执行完成\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/B1UmUR3ZQbG4pUCye2PP04mW)\n\n# 3. RocketMQ集群搭建\n\n## 3.1 各角色介绍\n\n* Producer：消息的发送者；举例：发信者\n* Consumer：消息接收者；举例：收信者\n* Broker：暂存和传输消息；举例：邮局\n* NameServer：管理Broker；举例：各个邮局的管理机构\n* Topic：区分消息的种类；一个发送者可以发送消息给一个或者多个Topic；一个消息的接收者可以订阅一个或者多个Topic消息\n* Message Queue：相当于是Topic的分区；用于并行发送和接收消息\n\n![RocketMQ角色.jpg](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/L76dH74XmT8CBSH15i2ppebf)\n\n## 3.2 集群搭建方式\n\n### 3.2.1 集群特点\n\n- NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。\n\n- Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。\n- Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。\n- Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。\n\n### 3.2.3 集群模式\n\n#### 1）单Master模式\n\n这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用。不建议线上环境使用,可以用于本地测试。\n\n#### 2）多Master模式\n\n一个集群无Slave，全是Master，例如2个Master或者3个Master，这种模式的优缺点如下：\n\n- 优点：配置简单，单个Master宕机或重启维护对应用无影响，在磁盘配置为RAID10时，即使机器宕机不可恢复情况下，由于RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢），性能最高；\n- 缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。\n\n#### 3）多Master多Slave模式（异步）\n\n每个Master配置一个Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下：\n\n- 优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样；\n- 缺点：Master宕机，磁盘损坏情况下会丢失少量消息。\n\n#### 4）多Master多Slave模式（同步）\n\n每个Master配置一个Slave，有多对Master-Slave，HA采用同步双写方式，即只有主备都写成功，才向应用返回成功，这种模式的优缺点如下：\n\n- 优点：数据与服务都无单点故障，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高；\n- 缺点：性能比异步复制模式略低（大约低10%左右），发送单个消息的RT会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。\n\n## 3.3 双主双从集群搭建\n\n### 3.3.1 总体架构\n\n消息高可用采用2m-2s（同步双写）方式\n\n![RocketMQ集群.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/YZ7lNk0quyaBeAQHZ2yzkzvz)\n\n### 3.3.2 集群工作流程\n\n1. 启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。\n2. Broker启动，跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。\n3. 收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。\n4. Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic存在哪些Broker上，轮询从队列列表中选择一个队列，然后与队列所在的Broker建立长连接从而向Broker发消息。\n5. Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。\n\n### 3.3.3 搭建过程\n这里简单描述一下，RocketMQ的集群搭建其实很简单，因为本人电脑配置原因，伪集群意义也不大，所以不进行过多的介绍。\n\n1. 修改配置文件，这里需要注意的是\n\n主：\n```yml\n#所属集群名字\nbrokerClusterName=rocketmq-cluster\n#broker名字，注意此处不同的配置文件填写的不一样\nbrokerName=broker-a\n#0 表示 Master，>0 表示 Slave\nbrokerId=0\n#nameServer地址，分号分割\n#需要指定多个name-server，相当于注册到多个注册中心上去\nnamesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876\n```\n\n从：\n```yml\n#所属集群名字\nbrokerClusterName=rocketmq-cluster\n#broker名字，注意此处不同的配置文件填写的不一样\nbrokerName=broker-b\n#0 表示 Master，>0 表示 Slave\nbrokerId=1\n#nameServer地址，分号分割\nnamesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876\n```\n其他配置文件也类似处理\n\n2. 在启动的时候修改docker-compose文件，注意修改配置文件所处的路径！\n\n# 4. 消息发送样例\n* 创建父级依赖管理\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>2.1.8.RELEASE</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>study</groupId>\n    <version>1.0.0-SNAPSHOT</version>\n    <name>dependencies</name>\n    <packaging>pom</packaging>\n    <modules>\n        <module>simple</module>\n    </modules>\n    <artifactId>RocketMQ</artifactId>\n    <dependencyManagement>\n        <dependencies>\n            <dependency>\n                <groupId>org.springframework.cloud</groupId>\n                <artifactId>spring-cloud-dependencies</artifactId>\n                <version>Greenwich.SR1</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n            <dependency>\n                <groupId>com.alibaba.cloud</groupId>\n                <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n                <version>2.1.0.RELEASE</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n        </dependencies>\n    </dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-stream-rocketmq</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n    </dependencies>\n</project>\n\n```\n\n* 创建simple包开始测试\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <groupId>study</groupId>\n        <artifactId>RocketMQ</artifactId>\n        <version>1.0.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>simple</artifactId>\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n            <scope>provided</scope>\n        </dependency>\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-stream-rocketmq</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <scope>provided</scope>\n        </dependency>\n    </dependencies>\n</project>\n\n```\n\n* 消息发送者步骤分析r\n\n```tex\n1.创建消息生产者producer，并制定生产者组名\n2.指定Nameserver地址\n3.启动producer\n4.创建消息对象，指定主题Topic、Tag和消息体\n5.发送消息\n6.关闭生产者producer\n```\n\n* 消息消费者步骤分析\n\n```tex\n1.创建消费者Consumer，制定消费者组名\n2.指定Nameserver地址\n3.订阅主题Topic和Tag\n4.设置回调函数，处理消息\n5.启动消费者consumer\n```\n\n## 4.1 基本样例\n\n### 4.1.1 消息发送\n\n#### 1）发送同步消息\n\n这种可靠性同步地发送方式使用的比较广泛，比如：重要的消息通知，短信通知。\n\n```java\n/**\n * @author Tiger\n * @date 2019-12-23\n * @see com.study.demo.sendMessage\n **/\npublic class SyncProducer {\n    /**\n     * 发送同步消息：这种方式在发送消息之后需要等待broker返回发送的结果，因此会比较慢，但是可以保证可靠性\n     * @param args args\n     * @throws Exception e\n     */\n    public static void main(String[] args) throws Exception {\n        // 实例化消息生产者Producer\n        DefaultMQProducer producer = new DefaultMQProducer(\"syncProducer\");\n        // 设置NameServer的地址\n        producer.setNamesrvAddr(\"my.service.com:9876\");\n        // 启动Producer实例\n        producer.start();\n        for (int i = 0; i < 100; i++) {\n            // 创建消息，并指定Topic，Tag和消息体\n            Message msg = new Message(\"SyncProducer\" ,\"TagA\" ,(\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n            // 发送消息到一个Broker\n            SendResult sendResult = producer.send(msg);\n            // 通过sendResult返回消息是否成功送达\n            System.out.printf(\"%s%n\", sendResult);\n        }\n        // 如果不再发送消息，关闭Producer实例。\n        producer.shutdown();\n    }\n}\n```\n\n#### 2）发送异步消息\n\n异步消息通常用在对响应时间敏感的业务场景，即发送端不能容忍长时间地等待Broker的响应。\n\n```java\n/**\n * @author Tiger\n * @date 2019-12-23\n * @see com.study.demo.sendMessage\n **/\npublic class AsyncProducer {\n    public static void main(String[] args) throws Exception {\n        // 实例化消息生产者Producer\n        DefaultMQProducer producer = new DefaultMQProducer(\"syncProducer\");\n        // 设置NameServer的地址\n        producer.setNamesrvAddr(\"my.service.com:9876\");\n        // 启动Producer实例\n        producer.start();\n//        producer.setRetryTimesWhenSendAsyncFailed(0);\n        for (int i = 0; i < 10; i++) {\n            final int index = i;\n            // 创建消息，并指定Topic，Tag和消息体\n            Message msg = new Message(\"AsyncProducer\", \"TagA\", \"OrderID188\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET));\n            // SendCallback接收异步返回结果的回调\n            producer.send(msg, new SendCallback() {\n                @Override\n                public void onSuccess(SendResult sendResult) {\n                    System.out.printf(\"%-10d OK %s %n\", index,\n                            sendResult.getMsgId());\n                }\n                @Override\n                public void onException(Throwable e) {\n                    System.out.printf(\"%-10d Exception %s %n\", index, e);\n                    e.printStackTrace();\n                }\n            });\n        }\n        // 这里需要注意，由于使用了异步，这么有可能会导致连接已经shutdown了才返回异步结果，这样会报错，因此只能手动关闭\n//        producer.shutdown();\n    }\n}\n```\n\n#### 3）单向发送消息\n\n这种方式主要用在不特别关心发送结果的场景，例如日志发送。\n\n```java\n/**\n * @author Tiger\n * @date 2019-12-23\n * @see com.study.demo.sendMessage\n **/\npublic class OnewayProducer {\n    public static void main(String[] args) throws Exception {\n        // 实例化消息生产者Producer\n        DefaultMQProducer producer = new DefaultMQProducer(\"onewayProducer\");\n        // 设置NameServer的地址\n        producer.setNamesrvAddr(\"my.service.com:9876\");\n        // 启动Producer实例\n        producer.start();\n        for (int i = 0; i < 100; i++) {\n            // 创建消息，并指定Topic，Tag和消息体\n            Message msg = new Message(\"OnewayProducer\",\n                    \"TagA\",\n                    (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET)\n            );\n            // 发送单向消息，没有任何返回结果\n            producer.sendOneway(msg);\n\n        }\n        // 如果不再发送消息，关闭Producer实例。\n        producer.shutdown();\n    }\n}\n```\n\n### 4.1.2 消费消息\n#### 1）负载均衡模式\n\n消费者采用负载均衡方式消费消息，多个消费者共同消费队列消息，每个消费者处理的消息不同\n\n```java\n/**\n * @author Tiger\n * @date 2019-12-23\n * @see com.study.demo.getMessage\n **/\npublic class Balance {\n    public static void main(String[] args) throws Exception {\n        // 实例化消息生产者,指定组名\n        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"syncProducer\");\n        // 指定Namesrv地址信息.\n        consumer.setNamesrvAddr(\"my.service.com:9876\");\n        // 订阅Topic\n        consumer.subscribe(\"AsyncProducer\", \"*\");\n        //负载均衡模式消费\n        consumer.setMessageModel(MessageModel.CLUSTERING);\n        // 注册回调函数，处理消息\n        consumer.registerMessageListener(new MessageListenerConcurrently() {\n            @Override\n            public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,\n                                                            ConsumeConcurrentlyContext context) {\n                System.out.printf(\"%s Receive New Messages: %s %n\",\n                        Thread.currentThread().getName(), msgs);\n                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n            }\n        });\n        //启动消息者\n        consumer.start();\n        System.out.printf(\"Consumer Started.%n\");\n    }\n}\n```\n\n#### 2）广播模式\n\n消费者采用广播的方式消费消息，每个消费者消费的消息都是相同的\n\n```java\n/**\n * @author Tiger\n * @date 2019-12-23\n * @see com.study.demo.getMessage\n **/\npublic class Broadcasting {\n    public static void main(String[] args) throws Exception {\n        // 实例化消息生产者,指定组名\n        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"syncProducer\");\n        // 指定Namesrv地址信息.\n        consumer.setNamesrvAddr(\"my.service.com:9876\");\n        // 订阅Topic\n        consumer.subscribe(\"AsyncProducer\", \"*\");\n        //广播模式消费\n        consumer.setMessageModel(MessageModel.BROADCASTING);\n        // 注册回调函数，处理消息\n        consumer.registerMessageListener(new MessageListenerConcurrently() {\n            @Override\n            public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,\n                                                            ConsumeConcurrentlyContext context) {\n                System.out.printf(\"%s Receive New Messages: %s %n\",\n                        Thread.currentThread().getName(), msgs);\n                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n            }\n        });\n        //启动消息者\n        consumer.start();\n        System.out.printf(\"Consumer Started.%n\");\n    }\n}\n```\n\n## 4.2 顺序消息\n\n消息有序指的是可以按照消息的发送顺序来消费(FIFO)。RocketMQ可以严格的保证消息有序，可以分为分区有序或者全局有序。\n\n顺序消费的原理解析，在默认的情况下消息发送会采取Round Robin轮询方式把消息发送到不同的queue(分区队列)；而消费消息的时候从多个queue上拉取消息，这种情况发送和消费是不能保证顺序。但是如果控制发送的顺序消息只依次发送到同一个queue中，消费的时候只从这个queue上依次拉取，则就保证了顺序。当发送和消费参与的queue只有一个，则是全局有序；如果多个queue参与，则为分区有序，即相对每个queue，消息都是有序的。\n\n下面用订单进行分区有序的示例。一个订单的顺序流程是：创建、付款、推送、完成。订单号相同的消息会被先后发送到同一个队列中，消费时，同一个OrderId获取到的肯定是同一个队列。\n\n### 4.2.1 顺序消息生产\n\n```java\n/**\n* Producer，发送顺序消息\n*/\npublic class OrderProducer {\n\n    public static void main(String[] args) throws Exception {\n        DefaultMQProducer producer = new DefaultMQProducer(\"orderProducer\");\n\n        producer.setNamesrvAddr(\"my.service.com:9876\");\n\n        producer.start();\n\n        String[] tags = new String[]{\"TagA\", \"TagC\", \"TagD\"};\n\n        // 订单列表\n        List<OrderStep> orderList = new OrderProducer().buildOrders();\n\n        Date date = new Date();\n        SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n        String dateStr = sdf.format(date);\n        for (int i = 0; i < 10; i++) {\n            // 加个时间前缀\n            String body = dateStr + \" Hello RocketMQ \" + orderList.get(i);\n            Message msg = new Message(\"TopicTest\", tags[i % tags.length], \"KEY\" + i, body.getBytes());\n\n            SendResult sendResult = producer.send(msg, (mqs, msg1, arg) -> {\n                Long id = (Long) arg;  //根据订单id选择发送queue\n                long index = id % mqs.size();\n                return mqs.get((int) index);\n            }, orderList.get(i).getOrderId());//订单id\n\n//            SendResult sendResult = producer.send(msg, new MessageQueueSelector() {\n//                @Override\n//                public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {\n//                    Long id = (Long) arg;  //根据订单id选择发送queue\n//                    long index = id % mqs.size();\n//                    return mqs.get((int) index);\n//                }\n//            }, orderList.get(i).getOrderId());//订单id\n\n            System.out.println(String.format(\"SendResult status:%s, queueId:%d, body:%s\",\n                    sendResult.getSendStatus(),\n                    sendResult.getMessageQueue().getQueueId(),\n                    body));\n        }\n\n        producer.shutdown();\n    }\n\n    /**\n     * 生成模拟订单数据\n     */\n    private List<OrderStep> buildOrders() {\n        List<OrderStep> orderList = new ArrayList<OrderStep>();\n\n        OrderStep orderDemo = new OrderStep();\n        orderDemo.setOrderId(15103111039L);\n        orderDemo.setDesc(\"创建\");\n        orderList.add(orderDemo);\n\n        orderDemo = new OrderStep();\n        orderDemo.setOrderId(15103111065L);\n        orderDemo.setDesc(\"创建\");\n        orderList.add(orderDemo);\n\n        orderDemo = new OrderStep();\n        orderDemo.setOrderId(15103111039L);\n        orderDemo.setDesc(\"付款\");\n        orderList.add(orderDemo);\n\n        orderDemo = new OrderStep();\n        orderDemo.setOrderId(15103117235L);\n        orderDemo.setDesc(\"创建\");\n        orderList.add(orderDemo);\n\n        orderDemo = new OrderStep();\n        orderDemo.setOrderId(15103111065L);\n        orderDemo.setDesc(\"付款\");\n        orderList.add(orderDemo);\n\n        orderDemo = new OrderStep();\n        orderDemo.setOrderId(15103117235L);\n        orderDemo.setDesc(\"付款\");\n        orderList.add(orderDemo);\n\n        orderDemo = new OrderStep();\n        orderDemo.setOrderId(15103111065L);\n        orderDemo.setDesc(\"完成\");\n        orderList.add(orderDemo);\n\n        orderDemo = new OrderStep();\n        orderDemo.setOrderId(15103111039L);\n        orderDemo.setDesc(\"推送\");\n        orderList.add(orderDemo);\n\n        orderDemo = new OrderStep();\n        orderDemo.setOrderId(15103117235L);\n        orderDemo.setDesc(\"完成\");\n        orderList.add(orderDemo);\n\n        orderDemo = new OrderStep();\n        orderDemo.setOrderId(15103111039L);\n        orderDemo.setDesc(\"完成\");\n        orderList.add(orderDemo);\n\n        return orderList;\n    }\n\n}\n\n@Data\npublic class OrderStep {\n    private long orderId;\n    private String desc;\n\n    @Override\n    public String toString() {\n        return \"OrderStep{\" +\n                \"orderId=\" + orderId +\n                \", desc=\'\" + desc + \'\\\'\' +\n                \'}\';\n    }\n}\n```\n\n### 4.2.2 顺序消费消息\n\n```java\n/**\n* 顺序消息消费，带事务方式（应用可控制Offset什么时候提交）\n*/\npublic class ConsumerInOrder {\n\n   public static void main(String[] args) throws Exception {\n       DefaultMQPushConsumer consumer = new \n           DefaultMQPushConsumer(\"please_rename_unique_group_name_3\");\n       consumer.setNamesrvAddr(\"127.0.0.1:9876\");\n       /**\n        * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费<br>\n        * 如果非第一次启动，那么按照上次消费的位置继续消费\n        */\n       consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);\n\n       consumer.subscribe(\"TopicTest\", \"TagA || TagC || TagD\");\n\n       consumer.registerMessageListener(new MessageListenerOrderly() {\n\n           Random random = new Random();\n\n           @Override\n           public ConsumeOrderlyStatus consumeMessage(List<MessageExt> msgs, ConsumeOrderlyContext context) {\n               context.setAutoCommit(true);\n               for (MessageExt msg : msgs) {\n                   // 可以看到每个queue有唯一的consume线程来消费, 订单对每个queue(分区)有序\n                   System.out.println(\"consumeThread=\" + Thread.currentThread().getName() + \"queueId=\" + msg.getQueueId() + \", content:\" + new String(msg.getBody()));\n               }\n\n               try {\n                   //模拟业务逻辑处理中...\n                   TimeUnit.SECONDS.sleep(random.nextInt(10));\n               } catch (Exception e) {\n                   e.printStackTrace();\n               }\n               return ConsumeOrderlyStatus.SUCCESS;\n           }\n       });\n\n       consumer.start();\n\n       System.out.println(\"Consumer Started.\");\n   }\n}\n```\n\n## 4.3 延时消息\n\n比如电商里，提交了一个订单就可以发送一个延时消息，1h后去检查这个订单的状态，如果还是未付款就取消订单释放库存。\n\n### 4.3.1 启动消息消费者\n\n```java\npublic class ScheduledMessageConsumer {\n   public static void main(String[] args) throws Exception {\n      // 实例化消费者\n      DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"ExampleConsumer\");\n      // 订阅Topics\n      consumer.subscribe(\"TestTopic\", \"*\");\n      // 注册消息监听者\n      consumer.registerMessageListener(new MessageListenerConcurrently() {\n          @Override\n          public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> messages, ConsumeConcurrentlyContext context) {\n              for (MessageExt message : messages) {\n                  // Print approximate delay time period\n                  System.out.println(\"Receive message[msgId=\" + message.getMsgId() + \"] \" + (System.currentTimeMillis() - message.getStoreTimestamp()) + \"ms later\");\n              }\n              return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n          }\n      });\n      // 启动消费者\n      consumer.start();\n  }\n}\n```\n\n### 4.3.2 发送延时消息\n\n```java\n/**\n * @author Tiger\n * @date 2019-12-24\n * @see com.study.demo.sendMessage\n **/\npublic class ScheduledMessageProducer {\n    /**\n     * 发送延时消息\n     * @param args a\n     * @throws Exception e\n     */\n    public static void main(String[] args) throws Exception {\n        // 实例化一个生产者来产生延时消息\n        DefaultMQProducer producer = new DefaultMQProducer(\"ExampleProducerGroup\");\n        producer.setNamesrvAddr(\"my.service.com:9876\");\n        // 启动生产者\n        producer.start();\n        int totalMessagesToSend = 100;\n        for (int i = 0; i < totalMessagesToSend; i++) {\n            Message message = new Message(\"TestTopic\", (\"Hello scheduled message \" + i).getBytes());\n            // 设置延时等级2,这个消息将在5s之后发送(现在只支持固定的几个时间,详看delayTimeLevel)\n            message.setDelayTimeLevel(2);\n            // 发送消息\n            producer.send(message);\n        }\n        // 关闭生产者\n        producer.shutdown();\n    }\n}\n```\n\n### 4.3.3 验证\n\n您将会看到消息的消费比存储时间晚10秒\n\n### 4.3.4 使用限制\n\n```java\n// org/apache/rocketmq/store/config/MessageStoreConfig.java\nprivate String messageDelayLevel = \"1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h\";\n```\n\n现在RocketMq并不支持任意时间的延时，需要设置几个固定的延时等级，从1s到2h分别对应着等级1到18\n\n## 4.4 批量消息\n\n批量发送消息能显著提高传递小消息的性能。限制是这些批量消息应该有相同的topic，相同的waitStoreMsgOK，而且不能是延时消息。此外，这一批消息的总大小不应超过4MB。\n\n### 4.4.1 发送批量消息\n\n如果您每次只发送不超过4MB的消息，则很容易使用批处理，样例如下：\n\n```java\nString topic = \"BatchTest\";\nList<Message> messages = new ArrayList<>();\nmessages.add(new Message(topic, \"TagA\", \"OrderID001\", \"Hello world 0\".getBytes()));\nmessages.add(new Message(topic, \"TagA\", \"OrderID002\", \"Hello world 1\".getBytes()));\nmessages.add(new Message(topic, \"TagA\", \"OrderID003\", \"Hello world 2\".getBytes()));\ntry {\n   producer.send(messages);\n} catch (Exception e) {\n   e.printStackTrace();\n   //处理error\n}\n```\n\n如果消息的总长度可能大于4MB时，这时候最好把消息进行分割\n\n```java\npublic class ListSplitter implements Iterator<List<Message>> {\n   private final int SIZE_LIMIT = 1024 * 1024 * 4;\n   private final List<Message> messages;\n   private int currIndex;\n   public ListSplitter(List<Message> messages) {\n           this.messages = messages;\n   }\n    @Override \n    public boolean hasNext() {\n       return currIndex < messages.size();\n   }\n   	@Override \n    public List<Message> next() {\n       int nextIndex = currIndex;\n       int totalSize = 0;\n       for (; nextIndex < messages.size(); nextIndex++) {\n           Message message = messages.get(nextIndex);\n           int tmpSize = message.getTopic().length() + message.getBody().length;\n           Map<String, String> properties = message.getProperties();\n           for (Map.Entry<String, String> entry : properties.entrySet()) {\n               tmpSize += entry.getKey().length() + entry.getValue().length();\n           }\n           tmpSize = tmpSize + 20; // 增加日志的开销20字节\n           if (tmpSize > SIZE_LIMIT) {\n               //单个消息超过了最大的限制\n               //忽略,否则会阻塞分裂的进程\n               if (nextIndex - currIndex == 0) {\n                  //假如下一个子列表没有元素,则添加这个子列表然后退出循环,否则只是退出循环\n                  nextIndex++;\n               }\n               break;\n           }\n           if (tmpSize + totalSize > SIZE_LIMIT) {\n               break;\n           } else {\n               totalSize += tmpSize;\n           }\n\n       }\n       List<Message> subList = messages.subList(currIndex, nextIndex);\n       currIndex = nextIndex;\n       return subList;\n   }\n}\n//把大的消息分裂成若干个小的消息\nListSplitter splitter = new ListSplitter(messages);\nwhile (splitter.hasNext()) {\n  try {\n      List<Message>  listItem = splitter.next();\n      producer.send(listItem);\n  } catch (Exception e) {\n      e.printStackTrace();\n      //处理error\n  }\n}\n```\n\n## 4.5 过滤消息\n\n在大多数情况下，TAG是一个简单而有用的设计，其可以来选择您想要的消息。例如：\n\n```java\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"CID_EXAMPLE\");\nconsumer.subscribe(\"TOPIC\", \"TAGA || TAGB || TAGC\");\n```\n\n消费者将接收包含TAGA或TAGB或TAGC的消息。但是限制是一个消息只能有一个标签，这对于复杂的场景可能不起作用。在这种情况下，可以使用SQL表达式筛选消息。SQL特性可以通过发送消息时的属性来进行计算。在RocketMQ定义的语法下，可以实现一些简单的逻辑。下面是一个例子：\n\n```te\n------------\n| message  |\n|----------|  a > 5 AND b = \'abc\'\n| a = 10   |  --------------------> Gotten\n| b = \'abc\'|\n| c = true |\n------------\n------------\n| message  |\n|----------|   a > 5 AND b = \'abc\'\n| a = 1    |  --------------------> Missed\n| b = \'abc\'|\n| c = true |\n------------\n```\n\n### 4.5.1 SQL基本语法\n\nRocketMQ只定义了一些基本语法来支持这个特性。你也可以很容易地扩展它。\n\n* 数值比较，比如：**>，>=，<，<=，BETWEEN，=；**\n* 字符比较，比如：**=，<>，IN；**\n* **IS NULL** 或者 **IS NOT NULL；**\n* 逻辑符号 **AND，OR，NOT；**\n\n常量支持类型为：\n\n* 数值，比如：**123，3.1415；**\n* 字符，比如：**\'abc\'，必须用单引号包裹起来；**\n* **NULL**，特殊的常量\n* 布尔值，**TRUE** 或 **FALSE**\n\n只有使用push模式的消费者才能用使用SQL92标准的sql语句，接口如下：\n\n```java\npublic void subscribe(finalString topic, final MessageSelector messageSelector)\n```\n\n### 4.5.2 消息生产者\n\n发送消息时，你能通过`putUserProperty`来设置消息的属性\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");\nproducer.start();\nMessage msg = new Message(\"TopicTest\",\n   tag,\n   (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET)\n);\n// 设置一些属性\nmsg.putUserProperty(\"a\", String.valueOf(i));\nSendResult sendResult = producer.send(msg);\n\nproducer.shutdown();\n```\n\n### 4.5.3 消息消费者\n\n用MessageSelector.bySql来使用sql筛选消息\n\n```java\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_4\");\n// 只有订阅的消息有这个属性a, a >=0 and a <= 3\nconsumer.subscribe(\"TopicTest\", MessageSelector.bySql(\"a between 0 and 3\");\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\n   @Override\n   public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) {\n       return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n   }\n});\nconsumer.start();\n```\n\n# 5. `spring-cloud-starter-stream-rocketmq`的使用\n## 5.1 基本样例\n* 创建SpringCloud统一依赖管理\n\n```xml\n    <dependencyManagement>\n        <dependencies>\n            <dependency>\n                <groupId>org.springframework.cloud</groupId>\n                <artifactId>spring-cloud-dependencies</artifactId>\n                <version>Greenwich.SR1</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n            <dependency>\n                <groupId>com.alibaba.cloud</groupId>\n                <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n                <version>2.1.0.RELEASE</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n        </dependencies>\n    </dependencyManagement>\n```\n\n* 子模块中加入rocketmq依赖\n\n```xml\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-stream-rocketmq</artifactId>\n        </dependency>\n```\n\n* org.springframework.cloud.stream.config.BindingProperties查看可配置的属性\n```java\n@JsonInclude(Include.NON_DEFAULT)\n@Validated\npublic class BindingProperties {\n    public static final MimeType DEFAULT_CONTENT_TYPE;\n    private static final String COMMA = \",\";\n    private String destination;\n    private String group;\n    private String contentType;\n    private String binder;\n    private ConsumerProperties consumer;\n    private ProducerProperties producer;\n    ...\n}\n```\n\n## 5.2 配置生产者\n* 编写生产者配置文件\n```yml\nserver:\n  port: 9094\nspring:\n  application:\n    name: rocketmq-provider\n  cloud:\n    stream:\n      bindings:\n        output1:\n          content-type: text/plain\n          destination: TransactionTopic\n      rocketmq:\n        binder:\n          name-server: my.service.com:9876\n	#自定义的名称 对应spring.cloud.stream.bindings.output1\n        bindings:\n          output1:\n            producer:\n              group: demo-group\n              transactional: true\n  datasource:\n    password: 123456\n    url: jdbc:mysql://my.service.com:3306/test?useUnicode=true&characterEncoding=UTF-8&useSSL=false&allowPublicKeyRetrieval=true&serverTimezone=GMT%2B8\n    username: root\n```\n\n* 指定当前MQ使用的配置\n```java\npublic interface MySource {\n    @Output(\"output1\")\n    MessageChannel output1();\n}\n``` \n\n* 在`Application`中进行绑定\n```\n@SpringBootApplication\n@EnableBinding(MySource.class)\npublic class ServerApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(ServerApplication.class, args);\n    }\n}\n```\n\n* 进入使用\n```java\n    @Resource\n    MySource source;\n    public void send(String message) {\n        //tags过滤方法\n	source.output1().send(MessageBuilder.withPayload(message).setHeader(RocketMQHeaders.TAGS,\"test\").build());\n        Random r = new Random();\n        //sql过滤方法\n	source.output1().send(MessageBuilder.withPayload(message).setHeader(\"index\",r.nextInt(1000)+500).build());\n	//默认方法\n	source.output1().send(MessageBuilder.withPayload(message).build());\n    }\n```\n\n* 如何使用事务方法\n上面内容不需要进行变更，只需要加入以下监听类\n```java\n@RocketMQTransactionListener(txProducerGroup = \"demo-group\")\npublic class ProducerListener implements RocketMQLocalTransactionListener {\n\n    @Autowired\n    JdbcTemplate jdbcTemplate;\n\n    @Override\n    @Transactional\n    public RocketMQLocalTransactionState executeLocalTransaction(Message message, Object arg) {\n        //消息发送成功回调此方法，此方法执行本地事务\n        try {\n            //解析消息内容\n            String jsonString = new String((byte[]) message.getPayload());\n            JSONObject jsonObject = JSONObject.parseObject(jsonString);\n            ...\n            return RocketMQLocalTransactionState.COMMIT;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return RocketMQLocalTransactionState.ROLLBACK;\n        }\n    }\n\n    //此方法检查事务执行状态\n    @Override\n    public RocketMQLocalTransactionState checkLocalTransaction(Message message) {\n        RocketMQLocalTransactionState state;\n        final JSONObject jsonObject = JSON.parseObject(new String((byte[]) message.getPayload()));\n        ...\n        System.out.println(\"check\");\n        System.out.println(jsonObject);\n	//自行定义规则，如要需要完整demo可以参考我github代码\n        if (...) {\n	    //提交事务\n            state = RocketMQLocalTransactionState.COMMIT;\n        } else {\n	    //稍后重试\n            state = RocketMQLocalTransactionState.UNKNOWN;\n        }\n        return state;\n    }\n}\n```\n\n## 5.3 配置消费者\n* 编写消费者配置文件\n```yml\nserver:\n  port: 9093\nspring:\n  application:\n    name: rocketmq-consumer\n  cloud:\n    stream:\n      bindings:\n        input:\n          consumer:\n#            消费者线程数设置\n            concurrency: 20\n          content-type: application/json\n          destination: TransactionTopic\n          group: demo-group\n      rocketmq:\n        binder:\n          name-server: my.service.com:9876\n        bindings:\n          input:\n            consumer:\n              broadcasting: false\n              sql: \'index >= 600\'\n              tags: tag0||tag1\n  datasource:\n    password: 123456\n    url: jdbc:mysql://my.service.com:3306/test?useUnicode=true&characterEncoding=UTF-8&useSSL=false&allowPublicKeyRetrieval=true&serverTimezone=GMT%2B8\n    username: root\n```\n\n* 这里没有使用自定义名称，只需要在`Application`中绑定默认规则即可\n```java\n@SpringBootApplication\n@EnableBinding({Sink.class})\npublic class ConsumerApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(ConsumerApplication.class, args);\n    }\n}\n```\n\n* 注册消息消费者监听器`@StreamListener(Sink.INPUT)`\n```\n    @StreamListener(Sink.INPUT)\n    //默认有ack机制，不抛出异常就是确认消费成功\n    public void receive(String receiveMsg) {\n        try {\n            JSONObject jsonObject = JSONObject.parseObject(receiveMsg);\n            ...\n        } catch (Exception e) {\n            throw new RuntimeException();\n        }\n    }\n```');
INSERT INTO `blog_content` VALUES (50, '## 配置文件内容\n### 1）全局块\n### 2）events块\n### 3）http块\n\n## 反向代理配置例子\n### 1）完整案例\n```conf\n\n#运行用户\n#user somebody;\n \n#启动进程,通常设置成和cpu的数量相等\nworker_processes  1;\n \n#全局错误日志\nerror_log  D:/Tools/nginx-1.10.1/logs/error.log;\nerror_log  D:/Tools/nginx-1.10.1/logs/notice.log  notice;\nerror_log  D:/Tools/nginx-1.10.1/logs/info.log  info;\n \n#PID文件，记录当前启动的nginx的进程ID\npid        D:/Tools/nginx-1.10.1/logs/nginx.pid;\n \n#工作模式及连接数上限\nevents {\n    worker_connections 1024;    #单个后台worker process进程的最大并发链接数\n}\n \n#设定http服务器，利用它的反向代理功能提供负载均衡支持\nhttp {\n    #设定mime类型(邮件支持类型),类型由mime.types文件定义\n    include       D:/Tools/nginx-1.10.1/conf/mime.types;\n    default_type  application/octet-stream;\n    \n    #设定日志\n    log_format  main  \'[$remote_addr] - [$remote_user] [$time_local] \"$request\" \'\n                      \'$status $body_bytes_sent \"$http_referer\" \'\n                      \'\"$http_user_agent\" \"$http_x_forwarded_for\"\';\n                      \n    access_log    D:/Tools/nginx-1.10.1/logs/access.log main;\n    rewrite_log     on;\n    \n    #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，\n    #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime.\n    sendfile        on;\n    #tcp_nopush     on;\n \n    #连接超时时间\n    keepalive_timeout  120;\n    tcp_nodelay        on;\n    \n    #gzip压缩开关\n    #gzip  on;\n \n    #设定实际的服务器列表 \n    upstream zp_server1{\n        server 127.0.0.1:8089;\n    }\n \n    #HTTP服务器\n    server {\n        #监听80端口，80端口是知名端口号，用于HTTP协议\n        listen       80;\n        \n        #定义使用www.xx.com访问\n        server_name  www.helloworld.com;\n        \n        #首页\n        index index.html\n        \n        #指向webapp的目录\n        root D:\\01_Workspace\\Project\\github\\zp\\SpringNotes\\spring-security\\spring-shiro\\src\\main\\webapp;\n        \n        #编码格式\n        charset utf-8;\n        \n        #代理配置参数\n        proxy_connect_timeout 180;\n        proxy_send_timeout 180;\n        proxy_read_timeout 180;\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarder-For $remote_addr;\n \n        #反向代理的路径（和upstream绑定），location 后面设置映射的路径\n        location / {\n            proxy_pass http://zp_server1;\n        } \n \n        #静态文件，nginx自己处理\n        location ~ ^/(images|javascript|js|css|flash|media|static)/ {\n            root D:\\01_Workspace\\Project\\github\\zp\\SpringNotes\\spring-security\\spring-shiro\\src\\main\\webapp\\views;\n            #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。\n            expires 30d;\n        }\n    \n        #设定查看Nginx状态的地址\n        location /NginxStatus {\n            stub_status           on;\n            access_log            on;\n            auth_basic            \"NginxStatus\";\n            auth_basic_user_file  conf/htpasswd;\n        }\n    \n        #禁止访问 .htxxx 文件\n        location ~ /\\.ht {\n            deny all;\n        }\n        \n        #错误处理页面（可选择性配置）\n        #error_page   404              /404.html;\n        #error_page   500 502 503 504  /50x.html;\n        #location = /50x.html {\n        #    root   html;\n        #}\n    }\n}\n```\n\n[nginx 中location和root，你确定真的明白他们关系？](https://blog.csdn.net/u011510825/article/details/50531864)\n\n### 2）负载均衡的方式\n* 轮询（默认）\n* weight\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/4nEwZfiav75zUEbOrvApBRum)\n* ip_hash\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/zTtri1gyhfo8dmqQ2mN9gIUF)\n* fair\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/dbFlxsvGYlEo9gWqe33VKlmO)\n\n## location匹配规则\n[nginx配置中location匹配规则详解](http://www.findme.wang/blog/detail/id/495.html)');
INSERT INTO `blog_content` VALUES (52, '## 序言\n在本次期末设计当中，应为需要做部署脚本，我们采用的是dockerfile+docker-compose的部署方式，这种方式对vue项目是没有问题的，因为vue下载依赖与打包是分离开来的，即使修改了代码，只要没有安装新的包都不会重新去下载包。而在SpringBoot项目中，也许是个人技术原因，没有找到下载依赖与打包分离开的方法，导致每次修改代码打包的时候都需要下载一堆的东西，导致运行时长过长。在咨询一些大佬后得知jib插件。\n\n## 准备工作\n在阿里云的容器镜像服务中创建两个镜像仓库，一个用于部署，一个用于创建自己的jdk镜像（不用应该也是可以的）。\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/fQbyPegsHqJ5LyJRG4tGtlce)\n\n### 一、设置jdk镜像\n在管理镜像中参考官方给的demo进行设置即可\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/1TaEIjeIGMUzqUdPnZErytYY)\n\n### 二、设置pom.xml\n```xml\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n            <plugin>\n                <groupId>com.google.cloud.tools</groupId>\n                <artifactId>jib-maven-plugin</artifactId>\n                <version>1.8.0</version>\n                <configuration>\n                    <from>\n                        <image>registry.cn-hangzhou.aliyuncs.com/yhhu/jdk8</image>\n                    </from>\n                    <to>\n                        <image>registry.cn-hangzhou.aliyuncs.com/yhhu/ejile</image>\n                        <tags>\n                            <tag>0.01</tag>\n                        </tags>\n                    </to>\n                    <container>\n                        <ports>\n                            <port>8080</port>\n                        </ports>\n                        <useCurrentTimestamp>true</useCurrentTimestamp>\n                        <args>\n                            <arg>--spring.profiles.active=prod</arg>\n                        </args>\n                    </container>\n                    <allowInsecureRegistries>true</allowInsecureRegistries>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n```\n\n方法一：配置`maven settings.xml`文件（推荐）\n```xml\n    <pluginGroups>\n        <!-- pluginGroup | Specifies a further group identifier to use for plugin\n            lookup. <pluginGroup>com.your.plugins</pluginGroup> -->\n        <pluginGroup>com.google.cloud.tools</pluginGroup>\n    </pluginGroups>\n    <!--对应容器仓库权限的账号密码-->\n    <servers>\n        <server>\n            <id>registry.cn-hangzhou.aliyuncs.com</id>\n            <username>xxx</username>\n            <password>xxx</password>\n        </server>\n    </servers>\n```\n\n方法二：在pom.xml中添加认证信息（不推荐）\n\n```xml\n                    <from>\n                        <image>registry.cn-hangzhou.aliyuncs.com/yhhu/jdk8</image>\n                        <auth>\n                            <username>my_username</username>\n                            <password>my_password</password>\n                        </auth>\n                    </from>\n                    <to>\n                        <image>registry.cn-hangzhou.aliyuncs.com/yhhu/ejile</image>\n                        <tags>\n                            <tag>0.01</tag>\n                        </tags>\n                        <auth>\n                            <username>my_username</username>\n                            <password>my_password</password>\n                        </auth>\n                    </to>\n```\n\n### 三、构建并提交镜像\n```sh\nmvn compile jib:build\n```\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/6e2Txd4Uf0KR4k4Qz6ZwAgW2)\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/Ub2Yyc94AfDONAP70J86dpYa)');
INSERT INTO `blog_content` VALUES (53, '## 序言\n在SpringBoot项目部署的时候，我了解到了Jib插件的强大，这个插件可以快速构建镜像发布到我们的镜像仓库当中去。于是我打算在毕设当中加上这个功能，并且整合到github actions中去。\n\n## 阻碍\n在单体地狱的项目中，我们使用jib插件十分的方便，只需要在项目文件夹下运行命令：`mvn complie jib:build`就可以完成镜像的构建并且推送到仓库。详情见：[jib-maven-plugin构建镜像](http://blog.yhhu.xyz/#/blog/52)\n可是这种方法在SpringCloud这种多模块化项目当中肯定是无法实现的。假设当前maven工程是父子结构的，有两个子工程A和B，其中A是二方库，提供一个jar包，里面是接口类和Bean类，B是springboot应用，并且B的源码中用到了A提供的接口和Bean；上述父子结构的maven工程是常见的工程结构，此时如果要将B构建成Docker镜像，在B的目录下执行`mvn compile jib:build`显然是不行的，因为没有编译构建A，会导致B的编译失败；\n\n## 解决办法\n此时最好的做法就是将`jib`与`mvn`构建的生命周期绑定，修改B的`pom.xml`文件，加入`executions`节点；\n父工程目录下执行`mvn package`，此时`maven`会先编译构建整个工程，然后再将B工程的构建结果制作成镜像；\n\n## 实例\n### 一、目录结构\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/vU6KQ5RfpTjEZ96gdKsTydJ6)\n这是我的`SpringCloud`项目的目录结构，我们需要修改的内容为需要发布到仓库的服务的`pom`文件，例如：\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/xfYHcyDaImboNQTyInBvEmit)\n\n### 二、通过`<executions>`节点绑定生命周期\n```xml\n    <plugin>\n        <groupId>com.google.cloud.tools</groupId>\n        <artifactId>jib-maven-plugin</artifactId>\n        <version>1.8.0</version>\n	<!-- executions   start-->\n        <executions>\n            <execution>\n                <id>build-image</id>\n                <phase>package</phase>\n                <goals>\n                    <goal>build</goal>\n                </goals>\n            </execution>\n        </executions>\n	<!-- executions   end-->\n        <configuration>\n            <from>\n                <image>registry.cn-hangzhou.aliyuncs.com/yhhu/jdk8</image>\n            </from>\n            <to>\n                <image>registry.cn-hangzhou.aliyuncs.com/2shop/user_provider</image>\n            </to>\n            <container>\n                <useCurrentTimestamp>true</useCurrentTimestamp>\n                <args>\n                    <arg>--spring.profiles.active=prod</arg>\n                </args>\n            </container>\n            <allowInsecureRegistries>true</allowInsecureRegistries>\n        </configuration>\n    </plugin>\n```\n\n### 三、与`github actions`整合，实现`push`后自动构建镜像\ngithub action文件如下：\n```xml\nname: Cloud CI\non:\n  push:\n    branches:\n      - master\n  pull_request:\njobs:\n  push_docker:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v1\n      - name: Set up JDK 1.8\n        uses: actions/setup-java@v1\n        with:\n          java-version: 1.8\n          server-id: registry.cn-hangzhou.aliyuncs.com\n          server-username: MAVEN_USERNAME\n          server-password: MAVEN_PASSWORD\n      - name: Build\n        run: mvn package -q -B -V\n        env:\n          MAVEN_USERNAME: ${{secrets.DOCKER_USERNAME}}\n          MAVEN_PASSWORD: ${{secrets.DOCKER_PASSWORD}}\n```\n\n## 完全整合demo\n[yhuihu/shop_api](https://github.com/yhuihu/shop_api)');
INSERT INTO `blog_content` VALUES (54, '## 1、运行时数据区域\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/zxa2x58vG8HM2Ogm2uJ6F3G1)\n\n- 线程私有的：\n	- 程序计数器\n	- 虚拟机栈\n	- 本地方法栈\n\n- 线程共享的：\n	- 堆\n	- 方法区\n	- 直接内存\n\n### 1.1 程序计数器\n程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令、分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。\n\n> 为了保证线程切换后能恢复到正确的执行位置，所以每个线程都需要一个独立的程序计数器，使得各线程间互不影响。所以程序计数器的线程私有的。\n\n### 1.2 `Java`虚拟机栈\n与程序计数器一样，`Java`虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是`Java`方法执行的内存模型。\n`Java`内存可以粗糙的区分为堆内存`Heap`和栈内存`Stack`，其中栈内存就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。\n局部变量表主要存放了编译器可知的各种基本数据类型、对象引用（reference类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。\n\n### 1.3 本地方法栈\n和虚拟机栈所发挥的作用非常相似，区别是：虚拟机栈为虚拟机执行`Java`方法（也就是字节码）服务，二本地方法栈则为虚拟机使用到的`Native`方法服务。在`HotSpot`虚拟机中和`Java`虚拟机栈合二为一。\n\n### 1.4 堆\n`Java`虚拟机所管理的内存中最大的一块，`Java`堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。\n`Java`堆是垃圾收集器管理的主要区域，因此也被称作`GC堆（Garbage Collected Heap）`。\n从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以Java堆还可以细分为：新生代，老年代。再细致一点可以分为：`Eden空间`、`From Survivor`、`To Survivor空间`等。\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/ckGXMhquiOWkv42dpnTkrg7z)\n\n### 1.5 方法区\n方法区和堆一样，是各个线程共享的内存区域。\n1. `JDK 1.7`及以前，`Java`类信息、常量、静态变量都存储在方法区里，又常被称为`Perm（永久代）`，当本质上两者并不等价，仅仅是因为HotSpot虚拟机设计团队用永久代来实现方法区而已，这样HotSpot虚拟机的垃圾收集器就可以像管理`Java`堆一样管理这部分内存了。`Java`虚拟机规范把方法区描述为堆的一个逻辑区域，但是它有一个别名叫`Non-Heap（非堆）`。类的元数据和静态变量在类加载的时候分配到`Perm`，当类被卸载的时候垃圾收集器从`Perm`处理掉。\n\n总的来说，就是虽然这东西叫永久代，可是并不代表这里面的东西就是永久存在的。\n\n2. `JDK 1.8`对`JVM`架构的改造将类元数据放到了本地内存当中（元空间），另外，将常量池和静态变量放到`Java`堆里。`HotSpot VM`将会为类的元数据明确分配和释放本地内存。在这种架构下，类元信息就突破了原来`-XX:MaxPermSize`的闲置，所以`PermSize`的配置也是无效的，现在可以使用更多的本地内存。这样就从一定程度上解决了原来在运行时生成大量类时造成经常`Full GC`问题，如运行时使用反射、代理等。\n\n### 1.6 运行时常量池\n运行时常量池是方法区的一部分。`Class`文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池信息（用于存放编译期生成的各种字面量和符号引用）\n既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时就会抛出OOM异常。\n`JDK 1.7`及以后版本的`JVM`已经将运行时常量池从方法区中移了出来，在`Java堆(Heap)`中开辟了一块区域存放运行时常量池。同时在`JDK 1.8`中移除了整个永久代，取而代之的是一个叫元空间的区域。\n\n## 2、 对象的创建\n### 2.1 对象创建过程流程图\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/bVrfbNr6F3Aj6HecB59clCkL)\n**①类加载检查：** 虚拟机遇到一条`new`指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。\n**②分配内存：** 在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从`Java堆`中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择那种分配方式由 `Java 堆`是否规整决定，而`Java堆`是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。\n\n::: hljs-center\n\n--------------分配内存的两种方式----start--------------\n\n:::\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/lQcIFWR2GyciU26tddeVbPAV)\n\n选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是\"标记-清除\"，还是\"标记-整理\"（也称作\"标记-压缩\"），值得注意的是，复制算法内存也是规整的\n\n\n::: hljs-center\n\n--------------分配内存的两种方式----end--------------\n\n:::\n\n**③初始化零值：** 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。\n\n**④设置对象头：** 初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希吗、对象的GC分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。\n\n**⑤执行 init 方法：** 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始， <init> 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 <init> 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。\n\n## 2、String类和常量池\n### 2.1 String对象的两种创建方式\n```java\nString str1=\"abc\";\nString str2=new String(\"abc\");\n①System.out.println(str1==str2); //false\n```\n根据上述①处可知，这两种创建方法得到的并不是同一个对象。第一种方法实在常量池中拿对象，第二种方法是直接在堆内存空间中创建一个新的对象。\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/AwBjx5ESK6TjkRlaad1skKN5)\n\n> 只要使用new方法，便需要创建新的对象。\n\n### 2.2 String类型的常量池比较特殊。它的主要使用方法有两种：\n- 直接使用双引号声明出来额String对象会直接存储在常量池中。\n- 如果不是用双引号声明的String对象，可以使用String提供的intern方法。它的作用是：如果运行时常量池中已经包含一个等与此String对象内容的字符串，则返回常量池中该字符串的引用；如果没有，则在常量池中创建于此String内容相同的字符串，并返回常量池中创建的字符串的引用。\n\n```java\n        String s1=new String(\"hello\");\n        String s2=s1.intern();\n        String s3=\"hello\";\n        System.out.println(s2); //hello\n        System.out.println(s1 == s2); //false\n        System.out.println(s3 == s2); //true\n```\n\n### 2.3 String字符串拼接\n```java\n        String s1 = \"str\";\n        String s2 = \"ing\";\n        String s3 = \"str\" + \"ing\";  //常量池中的对象\n        String s4 = s1 + s2;  //在堆上创建新的对象\n        String s5 = \"string\";  //常量池中的对象\n        System.out.println(s3 == s4);  //false\n        System.out.println(s3 == s5);  //true\n        System.out.println(s4 == s5);  //false\n```\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/wfS4FgXsEoWDpf1RWDen2c4R)\n\n>尽量避免多个字符串拼接，因为这样会重新创建对象，每次生成对象都会对系统性能产生影响，特别当内存中无引用对象多了以后， JVM 的 GC 就会开始工作，那速度是一定会相当慢的。。如果需要改变字符串的花，可以使用 StringBuilder 或者 StringBuffer。\n\n## 3、垃圾回收机制\n### 3.1 堆空间的基本结构\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/HTAJnDrpVKxoFRXwlTnSxa1j)\n上图所示的` eden `区、`s0(\"From\") `区、`s1(\"To\") `区都属于新生代，`tentired `区属于老年代。大部分情况，对象都会首先在 `Eden `区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入` s1(\"To\")`，并且对象的年龄还会加 1(`Eden `区->`Survivor `区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数` -XX:MaxTenuringThreshold `来设置。经过这次GC后，`Eden`区和`From`区已经被清空。这个时候，`From`和`To`会交换他们的角色，也就是新的`To`就是上次GC前的`From`，新的`From`就是上次GC前的`To`。不管怎样，都会保证名为`To`的`Survivor`区域是空的。`Minor GC`会一直重复这样的过程，直到`To`区被填满，`To`区被填满之后，会将所有对象移动到老年代中。\n\n### 3.2 如何判断对象已经死亡\n堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/xyUK6aaR4wRbELEeDwIK2Y8b)\n\n#### 3.2.1 引用计数法\n给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。\n**这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。** 所谓对象之间的相互引用问题，如下面代码所示：除了对象 objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为 0，于是引用计数算法无法通知 GC 回收器回收他们。\n```java\npublic class ReferenceCountingGc {\n    Object instance = null;\n    public static void main(String[] args) {\n        ReferenceCountingGc objA = new ReferenceCountingGc();\n        ReferenceCountingGc objB = new ReferenceCountingGc();\n        objA.instance = objB;\n        objB.instance = objA;\n        objA = null;\n        objB = null;\n\n    }\n}\n```\n\n#### 3.2.2 可达性分析算法\n这个算法的基本思想就是通过一系列的称为 `GC Roots` 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 `GC Roots` 没有任何引用链相连的话，则证明此对象是不可用的。\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/dKUY5kHdfhUBip2PEeUHPGm6)\n\n### 3.3 再谈引用\n引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱）\n- 强引用：如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。\n- 软引用：如果一个对象只具有软引用，那就类似于可有可无的生活用品。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。\n- 弱引用：如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。\n- 虚引用：\"虚引用\"顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。**虚引用主要用来跟踪对象被垃圾回收的活动。**\n**虚引用与软引用和弱引用的一个区别在于：** 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。\n\n### 3.4 不可达对象并非\"非死不可\"\n即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize 方法。当对象没有覆盖 finalize 方法，或 finalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。\n被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。\n\n### 3.5 如何判断一个常量是废弃常量\n运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？\n假如在常量池中存在字符串 \"abc\"，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 \"abc\" 就是废弃常量，如果这时发生内存回收的话而且有必要的话，\"abc\" 就会被系统清理出常量池。\n\n### 3.6 如何判断一个类是无用的类\n方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？\n\n判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是 “无用的类” ：\n\n- 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。\n- 加载该类的 ClassLoader 已经被回收。\n- 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。\n\n虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。\n\n## 4、垃圾收集算法\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/1EtwjpH4u0NjJ0QwdAuCGPye)\n\n### 4.1 标志-清除算法\n该算法分为“标记”和“清除”阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题：\n\n- 效率问题\n- 空间问题（标志清除后会产生大量不连续的空间）\n\n标记-清除算法其实就是有两个过程，第一个过程就是标记，第二个过程就是进行清除，所谓的标记，就是标记出所需要回收的对象\n\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/3daLgKLT3tLlnouWGeyDMapq)\n\n我们发现，这样的话，我们的内存区域会出现越来越多的不连续的空间，那么，这就导致一个问题，当我们在分配一个大对象的时候，这块空间不连续，我们在进行寻址在找的过程中就非常麻烦，影响性能，另外，如果说，实在找不到了，虚拟机会自动再进行触发一次垃圾回收，那么，这个过程也是非常耗性能的。\n\n### 4.2 复制算法\n为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/WJqPJSFtSjZcCmPK8p6RCR0e)\n\n### 4.3 标志-整理算法\n根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/qcBdrA9TfaUWLnHFuQe81amH)\n\n### 4.4 分代收集算法\n当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。\n>**比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。**\n\n**延伸面试问题：** HotSpot 为什么要分为新生代和老年代？\n\n### 5、 垃圾收集器\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/uFJ1mBbXrutSNaFRP5Ozlt0W)\n\n**如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。**\n\n虽然我们对各个收集器进行比较，但并非要挑选出一个最好的收集器。因为直到现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，**我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。**\n\n#### 5.1 Serial收集器\nSerial（串行）收集器收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ \"Stop The World\" ），直到它收集结束。\n在Serial收集器中，新生代采用复制算法，老年代采用标记-整理算法。（十分明显的分代收集算法，具体看4.4中分代收集算法的描述）\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/DVYnEqJpeUTZkgJjkQl3TjNL)\n\n虚拟机的设计者们当然知道 Stop The World 带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。\n\n但是 Serial 收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial 收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial 收集器对于运行在 Client 模式下的虚拟机来说是个不错的选择。\n\n#### 5.2 Serial Old 收集器\nSerial 收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。\n\n#### 5.3 ParNew收集器\n**ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。**\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/jI0vzvEsyfGBomUuERawpFrI)\n\n它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器，后面会介绍到）配合工作。\n**并行和并发概念补充：**\n- 并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。\n- 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。\n\n\n#### 5.4 Parallel Scavenge 收集器\nParallel Scavenge 收集器也是使用复制算法的多线程收集器，它看上去几乎和ParNew都一样。 那么它有什么特别之处呢？\n```\n-XX:+UseParallelGC \n\n    使用 Parallel 收集器+ 老年代串行\n\n-XX:+UseParallelOldGC\n\n    使用 Parallel 收集器+ 老年代并行\n```\n\nParallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，手工优化存在困难的话可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。\n新生代采用复制算法，老年代采用标记-整理算法。\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/CAOP2VDo5piEbnaYFj5vM4Re)\n\n#### 5.5 Parallel Old 收集器\nParallel Scavenge 收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。\n\n#### 5.6 CMS 收集器\nCMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。\nCMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。\n从名字中的Mark Sweep这两个词可以看出，CMS 收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：\n- 初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；（从root对象开始标记存活的对象）\n- 并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。\n- 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短。（并发标记阶段遗漏的对象（在并发标记阶段结束后对象状态的更新导致）。）\n- 并发清除： 开启用户线程，同时 GC 线程开始对为标记的区域做清扫。\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/sYkaXCxhvYkKAtF7JxTLQVo1)\n\n从它的名字就可以看出它是一款优秀的垃圾收集器，**主要优点：并发收集、低停顿。** 但是它有下面三个明显的缺点：\n\n- 对 CPU 资源敏感；\n- 无法处理浮动垃圾；（并发清理阶段用户线程还在运行，这段时间就可能产生新的垃圾，新的垃圾在此次GC无法清除，只能等到下次清理。这些垃圾有个专业名词：浮动垃圾。）\n- 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。\n\n#### 5.7 G1收集器\n\nG1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.\n\n被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备一下特点：\n\n- 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。\n- 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。\n- 空间整合：与 CMS 的“标记--清理”算法不同，G1 从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。\n- 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。\n\nG1 收集器的运作大致分为以下几个步骤：\n- 初始标记\n- 并发标记\n- 最终标记\n- 筛选回收\n\nG1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 GF 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。\n\n\n### 6、调优常用参数\n\n```\n-XX:MetaspaceSize=128M -XX:MaxMetaspaceSize=256M -Xms256m -Xmx256m\n```\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/2YiTOeuf3FJuVTYhZkr5IDT9)\n\n> 图中永久代在现在应改为元空间，对应的设置参数为Metaspace，使用PermSize将不起作用\n\n## 参考\n[可能是把Java内存区域讲的最清楚的一篇文章](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247484884&amp;idx=1&amp;sn=0d9b841ce0fc300c78ade2a87ffbfb46&source=41#wechat_redirect)\n');
INSERT INTO `blog_content` VALUES (55, '- cd <路径>：cd命令后面跟一个路径，用于切换当前用户所在的路径，其中路径可以是绝对路径也可以是相对路径\n- ls <参数> <路径>：ls是list的缩写。最常用的参数是`-l`，也就是`ls -l`命令，作用为用于显示所有文件及文件夹的详细信息\n- cat <文件>：concatenate的缩写，表示读取文件内容及拼接文件\n- rm <文件>或rm -r <文件夹>：rm是remove的缩写，-r表示删除目录，也可以用于删除文件，-f表示强制删除，不需要确认\n- mkdir 文件夹：make directory的缩写\n- cp <文件> <目标文件>或cp -r <文件夹> <目标文件夹>，cp是copy的缩写\n- kill PID码：结束PID码指定的进程，kill -9 PID码表示强制结束。\n- pwd：查看当前路径\n- ps：用于查看当前运行的进程状态，如果需要动态连续结果使用top。常用参数：\n	- -A 显示所有进程\n	- -a 显示同一终端下所有进程\n	- c 显示进程真实名称\n	- e 显示环境变量\n	- f 显示进程间关系\n	- r 显示当前终端运行的进程\n	- -aux 显示所有包含其它使用的进程');
INSERT INTO `blog_content` VALUES (56, '## 一、单例模式\n### 1.1 饿汉模式\n```Java\n//饿汉式单例类.在类初始化时，已经自行实例化   \npublic class Singleton1 {  \n    private Singleton1() {}  \n    private static final Singleton1 single = new Singleton1();  \n    //静态工厂方法   \n    public static Singleton1 getInstance() {  \n        return single;  \n    }  \n}\n```\n\n饿汉式在类创建的同时就实例化一个静态对象出来，不管之后会不会使用这个单例，都会占据一定的内存，但是相应的，在第一次调用时速度也会更快，因为其资源已经初始化完成，\n\n### 1.2 懒汉模式\n先看一个基础版本\n```Java\n//懒汉式单例类.在第一次调用的时候实例化自己   \npublic class Singleton {  \n    private Singleton() {}  \n    private volatile static Singleton single=null;  \n    //静态工厂方法   \n    public static Singleton getInstance() {  \n         if (single == null) {    \n             single = new Singleton();  \n         }    \n        return single;  \n    }  \n} \n```\n如果对线程安全有了解，那么就会知道，这个懒汉方法实际上是不好的，它在并发的环境下是有可能被多次实例化的。于是乎有了下面三种方法，都是对getInstance这个方法改造，保证了懒汉式单例的线程安全。\n\n#### 1.2.1 将`getInstance()`方法改为同步方法（不推荐，效率太低了）\n```Java\npublic static synchronized Singleton getInstance() {  \n         if (single == null) {    \n             single = new Singleton();  \n         }    \n        return single;  \n} \n```\n\n#### 1.2.2 双重校验方法（Double Check Lock）\n```Java\npublic static Singleton getInstance() {  \n    if (singleton == null) {    \n        synchronized (Singleton.class) {    \n           if (singleton == null) {    \n              singleton = new Singleton();   \n           }    \n        }    \n    }    \n    return singleton;   \n} \n```\n由于jvm存在乱序执行功能，DCL也会出现线程不安全的情况。\n\n`INSTANCE  = new SingleTon(); `这个步骤，其实在jvm里面的执行分为三步：\n- 在堆内存开辟内存空间。\n- 在堆内存中实例化SingleTon里面的各个参数。\n- 把对象指向堆内存空间。\n\n\n由于jvm存在乱序执行功能，所以可能在2还没执行时就先执行了3，如果此时再被切换到线程B上，由于执行了3，INSTANCE 已经非空了，会被直接拿出来用，这样的话，就会出现异常。这个就是著名的DCL失效问题。\n不过在JDK1.5之后，官方也发现了这个问题，故而具体化了volatile，即在JDK1.6及以后，只要定义为private volatile static SingleTon  INSTANCE = null;就可解决DCL失效问题。volatile确保INSTANCE每次均在主内存中读取，这样虽然会牺牲一点效率，但也无伤大雅。\n\n\n\n\n#### 1.2.3 静态内部类（推荐）\n```Java\npublic class Singleton {    \n    private static class LazyHolder {    \n       private static final Singleton INSTANCE = new Singleton();    \n    }    \n    private Singleton (){}    \n    public static final Singleton getInstance() {    \n       return LazyHolder.INSTANCE;    \n    }    \n} \n```\n这种比上面1、2都好一些，既实现了线程安全，又避免了同步带来的性能影响。\n[深入理解单例模式：静态内部类单例原理](https://blog.csdn.net/mnb65482/article/details/80458571)\n\n#### 1.2.4 枚举方法\n```java\npublic class EnumSingleton {\n\n    enum SerEnumSingleton {\n        INSTANCE;\n        private String content;\n\n        public String getContent() {\n            return content;\n        }\n\n        /**\n         * 内容测试\n         * @param content content\n         */\n        public void setContent(String content) {\n            this.content = content;\n        }\n\n        SerEnumSingleton() { }\n    }\n\n    public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException {\n        SerEnumSingleton serEnumSingleton = SerEnumSingleton.INSTANCE;\n        serEnumSingleton.setContent(\"singleton1\");\n        Class<SerEnumSingleton> serEnumSingletonClass = SerEnumSingleton.class;\n        Constructor<SerEnumSingleton> constructor=serEnumSingletonClass.getDeclaredConstructor(String.class,int.class);\n        constructor.setAccessible(true);\n        SerEnumSingleton serEnumSingleton1=constructor.newInstance(\"test\",123);\n        System.out.println(serEnumSingleton==serEnumSingleton1);\n    }\n}\n```\n\n[为什么要用枚举实现单例模式（避免反射、序列化问题）](https://www.cnblogs.com/chiclee/p/9097772.html)\n\n## 二、工厂模式\n\n### 2.1 简单工厂\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/hMpGLQL18CmtKWIPDuAxxnqa)\n是通过专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。\n简单工厂模式就是通过一个\"全能类\"，根据外界传递的信息来决定创建哪个具体类的对象。\n```java\npublic class SimpleFactory {\n    public static IProduct getFactory(String name) throws IllegalAccessException {\n        if (name.equals(\"A\")){\n            return new AProduct();\n        }else if (name.equals(\"B\")){\n            return new BProduct();\n        }else{\n            throw new IllegalAccessException();\n        }\n    }\n}\n```\n\n### 2.2 工厂方法模式\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/tDR7T6fhZ5fOuBWDYzlIZ6kp)\n对简单工厂模式进行了抽象化，符合“开闭原则”，实现了可扩展。\n工厂方法(Factory Method)模式的意义是定义一个创建产品对象的工厂接口，将实际创建工作推迟到子类当中。核心工厂类不再负责产品的创建，这样核心类成为一个抽象工厂角色，仅负责具体工厂子类必须实现的接口，这样进一步抽象化的好处是使得工厂方法模式可以使系统在不修改具体工厂角色的情况下引进新的产品。\n```java\npublic interface MyPhone {\n    String phoneName();\n}\n\npublic class IPhone implements MyPhone{\n    @Override\n    public String phoneName() {\n        return \"IPhone\";\n    }\n}\n\npublic class OnePlus implements MyPhone{\n    @Override\n    public String phoneName() {\n        return \"OnePlus\";\n    }\n}\n\npublic class FactoryMethods {\n    public static void main(String[] args) {\n        MyPhone iphone =new IPhone();\n        MyPhone onePlus=new OnePlus();\n        System.out.println(iphone.phoneName());\n        System.out.println(onePlus.phoneName());\n    }\n}\n```\n\n### 2.3 抽象工厂\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/1csnvnvVlK288sobKlH0ZlGv)\n抽象工厂模式（Abstract Factory Pattern）是围绕一个超级工厂创建其他工厂。该超级工厂又称为其他工厂的工厂。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。\n\n在抽象工厂模式中，接口是负责创建一个相关对象的工厂，不需要显式指定它们的类。每个生成的工厂都能按照工厂模式提供对象。\n\n## 三、代理模式\n### 3.1 静态代理\n静态代理是由程序员创建或特定工具自动生成源代码，在对其编译。在程序员运行之前，代理类.class文件就已经被创建了。\n```java\npublic interface BuyHouse {\n    void buyHouse();\n}\n\n\npublic class BuyHouseImpl implements BuyHouse {\n    @Override\n    public void buyHouse() {\n        System.out.println(\"我要买房\");\n    }\n}\n\n\npublic class BuyHouseProxy implements BuyHouse {\n    private BuyHouse buyHouse;\n\n    public BuyHouseProxy(final BuyHouse buyHouse) {\n        this.buyHouse = buyHouse;\n    }\n\n    @Override\n    public void buyHouse() {\n        System.out.println(\"买房前准备\");\n        buyHouse.buyHouse();\n        System.out.println(\"买完了\");\n    }\n}\n\n\npublic class ProxyTest {\n    public static void main(String[] args) {\n        BuyHouse buyHouse = new BuyHouseImpl();\n        BuyHouseProxy buyHouseProxy = new BuyHouseProxy(buyHouse);\n        buyHouseProxy.buyHouse();\n    }\n}\n```\n\n### 3.2 JDK代理\n在动态代理中我们不再需要再手动的创建代理类，我们只需要编写一个动态处理器就可以了。真正的代理对象由JDK再运行时为我们动态的来创建。JDK实现动态代理需要实现类通过接口定义业务方法。\n```java\npublic class ProxyMethod implements InvocationHandler {\n    private Object object;\n    public ProxyMethod(final Object o){\n        this.object=o;\n    }\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        System.out.println(\"买房准备\");\n        Object o=method.invoke(object,args);\n        System.out.println(\"买完了\");\n        return null;\n    }\n}\n\npublic class ProxyTest {\n    public static void main(String[] args) {\n        BuyHouse buyHouse = new BuyHouseImpl();\n        BuyHouse proxyBuyHouse = (BuyHouse) Proxy.newProxyInstance(BuyHouse.class.getClassLoader(),\n                new Class[]{BuyHouse.class}, new ProxyMethod(buyHouse));\n        proxyBuyHouse.buyHouse();\n    }\n}\n\n```\n注意Proxy.newProxyInstance()方法接受三个参数：\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/TiwxuCF60cFc8JN38NK7meIx)\n- ClassLoader loader:指定当前目标对象使用的类加载器,获取加载器的方法是固定的\n- Class<?>[] interfaces:指定目标对象实现的接口的类型,使用泛型方式确认类型\n- InvocationHandler:指定动态处理器，执行目标对象的方法时,会触发事件处理器的方法\n\n\n### 3.3 CGLIB代理\n对于没有接口的类，如何实现动态代理呢，这就需要CGLib了。CGLib采用了非常底层的字节码技术，其原理是通过字节码技术为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。但因为采用的是继承，所以不能对final修饰的类进行代理。JDK动态代理与CGLib动态代理均是实现Spring AOP的基础。\nCGLIB创建的动态代理对象比JDK创建的动态代理对象的性能更高，但是CGLIB创建代理对象时所花费的时间却比JDK多得多。所以对于单例的对象，因为无需频繁创建对象，用CGLIB合适，反之使用JDK方式要更为合适一些。同时由于CGLib由于是采用动态创建子类的方法，对于final修饰的方法无法进行代理。\n\n> 由于cglib是第三方实现的，需要自己先引入cglib包或者直接引入spring包\n\n```java\npublic class CglibProxy implements MethodInterceptor {\n\n    private Object object;\n\n    public Object getInstance(Object o){\n        this.object=o;\n        Enhancer enhancer=new Enhancer();\n        enhancer.setSuperclass(this.object.getClass());\n        enhancer.setCallback(this);\n        return enhancer.create();\n    }\n\n    @Override\n    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {\n        System.out.println(\"买房前准备\");\n        Object result = methodProxy.invokeSuper(o, objects);\n        System.out.println(\"买房后装修\");\n        return result;\n    }\n}\n\npublic class CglibTest {\n    public static void main(String[] args) {\n        BuyHouse buyHouse = new BuyHouseImpl();\n        CglibProxy cglibProxy = new CglibProxy();\n        BuyHouseImpl buyHouse1 = (BuyHouseImpl) cglibProxy.getInstance(buyHouse);\n        buyHouse1.buyHouse();\n    }\n}\n```\n这里需要注意的是`intercept`中要使用`methodProxy.invokeSuper(o,objects)`方法。使用`invoke`将会发生死循环。（具体原因待补充）\n\n## 四、适配器模式\n适配器模式(Adapter Pattern)：将一个接口转换成客户希望的另一个接口，使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。\n在适配器模式中，我们通过增加一个新的适配器类来解决接口不兼容的问题，使得原本没有任何关系的类可以协同工作。\n根据适配器类与适配者类的关系不同，适配器模式可分为对象适配器和类适配器两种，在对象适配器模式中，适配器与适配者之间是关联关系；在类适配器模式中，适配器与适配者之间是继承（或实现）关系。\n- 类适配器\n首先有一个已存在的将被适配的类,定义一个目标接口,怎么才可以在目标接口中的 request() 调用 Adaptee 的 adapteeRequest() 方法呢？通过一个适配器类，实现 Target 接口，同时继承了 Adaptee 类，然后在实现的 request() 方法中调用父类的 adapteeRequest() 即可实现\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/YpGMLnrDXbKhEC4xuW1MYbcb)\n\n```java\npublic interface Target {\n    void request();\n}\n\npublic class ConcreteTarget implements Target {\n    @Override\n    public void request() {\n        System.out.println(\"concreteTarget目标方法\");\n    }\n}\n\n\npublic class Adaptee {\n    public void adapteeRequest() {\n        System.out.println(\"被适配者的方法\");\n    }\n}\n\npublic class Adapter extends Adaptee implements Target {\n\n    @Override\n    public void request() {\n        super.adapteeRequest();\n    }\n}\n\npublic class Test {\n    public static void main(String[] args) {\n        Target target = new ConcreteTarget();\n        target.request();\n\n        Target adapterTarget = new Adapter();\n        adapterTarget.request();\n    }\n}\n```\n\n- 对象适配器\n对象适配器与类适配器不同之处在于，类适配器通过继承来完成适配，对象适配器则是通过关联来完成，这里稍微修改一下 Adapter 类即可将转变为对象适配器。\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/scUyDpbIOMjQ01EwnOaV41UJ)\n\n```java\npublic class Adapter implements Target {\n    // 适配者是对象适配器的一个属性\n    private Adaptee adaptee = new Adaptee();\n\n    @Override\n    public void request() {\n        adaptee.adapteeRequest();\n    }\n}\n```\n\n注意这里的 Adapter 是将 Adaptee 作为一个成员属性，而不是继承它\n\n');
INSERT INTO `blog_content` VALUES (57, '# 计算机网络\n### [TCP 常见面试题](https://zhuanlan.zhihu.com/p/87310327)\n### [TCP连接拥塞控制四种方法总结（详细简单，稳的一批）](https://blog.csdn.net/qq_26896213/article/details/84594060?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)\n### [Http中200、302、304、404和500等响应状态码所表示的意义？](https://blog.csdn.net/qq_44066201/article/details/100518914)\n\n# Java\n### [java中的各种锁详细介绍](https://www.cnblogs.com/jyroy/p/11365935.html)\n### [拦截器（Interceptor）和过滤器（Filter）的执行顺序和区别](https://blog.csdn.net/zxd1435513775/article/details/80556034)\n### [深入理解CyclicBarrier原理](https://blog.csdn.net/qq_39241239/article/details/87030142)\n### [设计模式 | 适配器模式及典型应用](https://blog.csdn.net/wwwdc1012/article/details/82780560)\n### [学习、探究Java设计模式——装饰者模式](https://blog.csdn.net/a553181867/article/details/52108423)\n### [java双亲委派模型](https://www.jianshu.com/p/9df9d318e838)\n### [B树、B-树、B+树、B*树之间的关系](https://blog.csdn.net/u013411246/article/details/81088914)\n### [面试题：B（B-）树，B+树，B树和B+树的区别，B树和B+树的优点](https://blog.csdn.net/weixin_42228338/article/details/97684517)\n### [JAVA不使用中间变量，实现两个数的交换](https://blog.csdn.net/qq1608731824/article/details/81449508)\n### [Java数据结构和算法（十一）——红黑树](https://www.cnblogs.com/ysocean/p/8004211.html)\n\n# Redis\n### [图解Redis之数据结构篇——跳跃表](https://www.cnblogs.com/hunternet/p/11248192.html)\n\n# MySQL\n### [数据库三大范式最简单的解释](https://blog.csdn.net/andywuchuanlong/article/details/25913235?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)\n### [MySql存储引擎和索引原理](https://blog.csdn.net/xc123_java/article/details/89350332)\n### [MySQL索引原理](https://www.cnblogs.com/iwenwen/p/11052766.html)\n### [聚簇索引和非聚簇索引(通俗易懂 言简意赅)](https://www.cnblogs.com/jiawen010/p/11805241.html)\n\n# Spring \n### [spring执行流程](https://blog.csdn.net/xuebaobao130526/article/details/80831412)(这是SpringMVC)\n');
INSERT INTO `blog_content` VALUES (58, '本文章对应代码地址：[github-NIO](https://github.com/yhuihu/Java-Study/tree/master/NIO)\n## 一、了解IO与NIO区别\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/Noa9o99Wg7E2Wi7sFglL6Ybj)\n\n## 二、初见Buffer缓冲区\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/iWflUQfv3EcWt3y9L4jCw9o6)\n\n### 2.1 非直接缓冲区 ：`allocate()`方法创建`Buffer`\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/ur332TjhRyK6A8xp2WoPO17W)\n\n### 2.2 直接缓冲区 ：`allocateDirect()`方法创建`Buffer`\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/LzPVD34BXDJm7P5XlkD1eLVx)\n\n### 2.3 对`Buffer`的操作：\n`Buffer`有许多类型，在基本数据类型当中，除了`boolean`，其他都有对应的`Buffer`，如：`ByteBuffer`、`CharBuffer`、`ShortBuffer`、`LongBuffer`、`IntBuffer`、`DoubleBuffer`、`FloatBuffer`，以下通过`ByteBuffer`代码进行展示。首先我们打开源码可以知道他们都继承了`Buffer`类。\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/CfZT3EvmQF6nEmHuPyxDM0cA)\n`Buffer`类四大核心属性：\n- `mark`：标记，当我们使用`reset()`方法时，`position`将回到该位置\n- `position`：个人理解为游标，用于记录当前操作到什么位置\n- `limit`：限制大小，在写`Buffer`时对应总大小（即`allocate`的大小）。在读时对应当前`Buffer`的数据长度（比如往`Buffer`中写入3个字节，那么`limit`为3）\n- `capcity`：总大小\n\n`Buffer`最核心的两个方法为：`put()`和\'get()\'，分别对应存和取\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/vQ8aC4VwzW4Di2XB9UQGmZUz)\n\n> 注意：进入读模式时需要调用`flip()`方法\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/UvBgZ8s1eJJ8GVmdtDQFN8oi)\n\n```java\npublic class BufferTest {\n    public static void main(String[] args) {\n        //        直接缓冲区\n        ByteBuffer buffer = ByteBuffer.allocateDirect(1024);\n        System.out.println(\"-----------allocateDirect----------\");\n        System.out.println(\"position:\" + buffer.position());\n        System.out.println(\"limit:\" + buffer.limit());\n        System.out.println(\"capacity:\" + buffer.capacity());\n\n        System.out.println(\"-----------put----------\");\n        buffer.put(\"abcdefg\".getBytes());\n        System.out.println(\"position:\" + buffer.position());\n        System.out.println(\"limit:\" + buffer.limit());\n        System.out.println(\"capacity:\" + buffer.capacity());\n\n        System.out.println(\"-----------flip----------\");\n        buffer.flip();\n        System.out.println(\"position:\" + buffer.position());\n        System.out.println(\"limit:\" + buffer.limit());\n        System.out.println(\"capacity:\" + buffer.capacity());\n\n        System.out.println(\"-----------第一次get----------\");\n        byte[] bt = new byte[buffer.limit()];\n        //        offset表示第几个开始，length表示选多少个\n        buffer.get(bt, 0, 2);\n        System.out.println(\"取出的数据为：\" + new String(bt));\n        System.out.println(\"position:\" + buffer.position());\n        System.out.println(\"limit:\" + buffer.limit());\n        System.out.println(\"capacity:\" + buffer.capacity());\n\n        System.out.println(\"-----------第二次get----------\");\n        buffer.mark();\n        byte[] bt1 = new byte[buffer.limit()];\n        //        offset表示第几个开始，length表示选多少个\n        buffer.get(bt1, 2, 2);\n        System.out.println(\"取出的数据为：\" + new String(bt1));\n        System.out.println(\"position:\" + buffer.position());\n        System.out.println(\"limit:\" + buffer.limit());\n        System.out.println(\"capacity:\" + buffer.capacity());\n\n        System.out.println(\"-----------reset----------\");\n        buffer.reset();\n        System.out.println(\"position:\" + buffer.position());\n        System.out.println(\"limit:\" + buffer.limit());\n        System.out.println(\"capacity:\" + buffer.capacity());\n\n        System.out.println(\"-----------rewind----------\");\n        buffer.rewind();\n        System.out.println(\"position:\" + buffer.position());\n        System.out.println(\"limit:\" + buffer.limit());\n        System.out.println(\"capacity:\" + buffer.capacity());\n\n        System.out.println(\"-----------remind----------\");\n        if (buffer.hasRemaining()) {\n//            显示可操作数量\n            System.out.println(buffer.remaining());\n        }\n\n        System.out.println(\"-----------clear----------\");\n//        注意：数据还存在，只是位置回到了最开始的位置，数据处于被遗忘状态\n        buffer.clear();\n        System.out.println(\"position:\" + buffer.position());\n        System.out.println(\"limit:\" + buffer.limit());\n        System.out.println(\"capacity:\" + buffer.capacity());\n        System.out.println(\"data:\" + (char) (buffer.get()));\n    }\n}\n```\n运行结果：\n```txt\n-----------allocateDirect----------\nposition:0\nlimit:1024\ncapacity:1024\n-----------put----------\nposition:7\nlimit:1024\ncapacity:1024\n-----------flip----------\nposition:0\nlimit:7\ncapacity:1024\n-----------第一次get----------\n取出的数据为：ab     \nposition:2\nlimit:7\ncapacity:1024\n-----------第二次get----------\n取出的数据为：  cd   \nposition:4\nlimit:7\ncapacity:1024\n-----------reset----------\nposition:2\nlimit:7\ncapacity:1024\n-----------rewind----------\nposition:0\nlimit:7\ncapacity:1024\n-----------remind----------\n7\n-----------clear----------\nposition:0\nlimit:1024\ncapacity:1024\ndata:a\nPicked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8\n\nProcess finished with exit code 0\n```\n\n## 三、通道（Channel）\n### 3.1 没有通道前，使用DMA总线\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/TIBrXf9zo8wilQQ6V91XIx8p)\n当有大量I/O请求时，cpu利用率低，因为需要请求cpu获取资源。\n\n### 3.2 使用通道后\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/q9z0GhNy552dpEqovZIwiXP4)\n通道是一个完全独立的处理器，专门用于I/O操作，有自己的命令，附属于CPU。就算有大量请求，也不需要向cpu请求。\n\n### 3.3 通道的使用\n通道用于源节点与目标节点的连接。在`Java NIO`中负责缓冲区中数据的传输。`Channel`本身不存储数据，因此需要配合缓冲区进行传输。\n#### 3.3.1通道主要的实现类：\n- `FileChannel`：文件操作通道\n- `SocketChannel`：TCP\n- `ServerSocketChannel`：TCP\n- `DatagramChannel`：UDP\n\n#### 3.3.2获取通道的方式：\n1. `Java`针对支持通道的类提供了`getChannel()`方法\n	1. 本地`IO`：\n		1. `FileInputStream/FileOutputStream`\n		2. `RandomAccessFile`\n	2. 网络`IO`：\n		1. `Socket`\n		2. `ServerSocket`\n		3. `DatagramSocket`\n2. 在`JDK 1.7`中的`NIO.2`针对各个通道提供了静态方法`open()`\n3. 在`JDK 1.7`中的`NIO.2`的`Files`工具类的`newByteChannel`\n\n#### 3.3.3 代码实现通道文件复制\n```java\npublic class ChannelTest {\n\n    //利用通道完成文件复制（非直接缓冲区）\n    @Test\n    public void test1() throws IOException {\n        long start = System.currentTimeMillis();\n        FileInputStream fileInputStream = new FileInputStream(new File(\"D:\\\\资源\\\\1.mp4\"));\n        FileOutputStream fileOutputStream = new FileOutputStream(new File(\"D:\\\\资源\\\\2.mp4\"));\n        FileChannel channel = fileInputStream.getChannel();\n        FileChannel channel1 = fileOutputStream.getChannel();\n        ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n        while (channel.read(byteBuffer) != -1) {\n            byteBuffer.flip();\n            channel1.write(byteBuffer);\n            byteBuffer.clear();\n        }\n        long end = System.currentTimeMillis();\n        System.out.println(end - start);\n        channel.close();\n        channel1.close();\n        fileInputStream.close();\n        fileOutputStream.close();\n    }\n\n    @Test\n    public void test2() throws IOException {\n        long start = System.currentTimeMillis();\n        FileChannel inputChannel = FileChannel.open(Paths.get(\"D:\\\\资源\\\\1.mp4\"), StandardOpenOption.READ);\n        FileChannel outputChannel = FileChannel.open(Paths.get(\"D:\\\\资源\\\\2.mp4\"), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE);\n//        内存映射文件\n        MappedByteBuffer map = inputChannel.map(FileChannel.MapMode.READ_ONLY, 0, inputChannel.size());\n        MappedByteBuffer map1 = outputChannel.map(FileChannel.MapMode.READ_WRITE, 0, inputChannel.size());\n        byte[] bytes=new byte[map.limit()];\n        map.get(bytes);\n        map1.put(bytes);\n        long end = System.currentTimeMillis();\n        System.out.println(end - start);\n        inputChannel.close();\n        outputChannel.close();\n    }\n\n    //通道间直接传输（直接缓冲区）\n    @Test\n    public void test3() throws IOException {\n        long start = System.currentTimeMillis();\n        FileChannel inputChannel = FileChannel.open(Paths.get(\"D:\\\\资源\\\\1.mp4\"), StandardOpenOption.READ);\n        FileChannel outputChannel = FileChannel.open(Paths.get(\"D:\\\\资源\\\\2.mp4\"), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE);\n        inputChannel.transferTo(0, inputChannel.size(), outputChannel);\n//        outputChannel.transferFrom(inputChannel,0,inputChannel.size());\n        inputChannel.close();\n        outputChannel.close();\n        long end = System.currentTimeMillis();\n        System.out.println(end - start);\n    }\n\n//    分散读取，聚集写入\n    @Test\n    public void test4() throws IOException {\n        RandomAccessFile randomAccessFile=new RandomAccessFile(\"C:\\\\Users\\\\Admin\\\\Desktop\\\\新建文本文档.txt\",\"rw\");\n        FileChannel fileChannel=randomAccessFile.getChannel();\n        ByteBuffer buffer1=ByteBuffer.allocate(100);\n        ByteBuffer buffer2=ByteBuffer.allocate(1024);\n        ByteBuffer[] byteBuffers={buffer1,buffer2};\n        fileChannel.read(byteBuffers);\n        for (ByteBuffer byteBuffer : byteBuffers) {\n            byteBuffer.flip();\n        }\n        System.out.println(new String(byteBuffers[0].array(),0,byteBuffers[0].limit()));\n        System.out.println(new String(byteBuffers[1].array(),0,byteBuffers[1].limit()));\n        RandomAccessFile randomAccessFile1=new RandomAccessFile(\"2.txt\",\"rw\");\n        FileChannel fileChannel1=randomAccessFile1.getChannel();\n        fileChannel1.write(byteBuffers);\n        fileChannel1.close();\n        fileChannel.close();\n    }\n}\n```\n\n## 四、网络通信\n\n### 4.1 三大核心\n- 通道（`Channel`）:负责连接\n- 缓冲区（`Buffer`）：负责数据的存取\n- 选择器（`Selector`）：是`SelectableChannel`的多路复用。用于监控`SelectableChannel`的IO状况\n\n### 4.2 代码使用\n阻塞版本：\n```java\npublic class Client {\n    public static void main(java.lang.String[] args) throws IOException {\n        // 1.建立连接\n        SocketChannel socketChannel = SocketChannel.open(new InetSocketAddress(\"127.0.0.1\", 8888));\n        // 2.获取文件\n        FileChannel inputChannel = FileChannel.open(Paths.get(\"D:\\\\资源\\\\资料\\\\个人\\\\杨辉虎1.jpg\"), StandardOpenOption.READ);\n        // 3.创建缓冲区\n        ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n        // 4.读取数据\n        while (inputChannel.read(byteBuffer) != -1) {\n            byteBuffer.flip();\n            socketChannel.write(byteBuffer);\n            byteBuffer.clear();\n        }\n\n        // 5.告诉服务端自己发送完成了，不然会一直阻塞，无法进入下一步\n        socketChannel.shutdownOutput();\n\n        int length = 0;\n        while ((length = socketChannel.read(byteBuffer)) != -1) {\n            byteBuffer.flip();\n            System.out.println(new java.lang.String(byteBuffer.array(), 0, length));\n            byteBuffer.clear();\n        }\n        inputChannel.close();\n        socketChannel.close();\n    }\n}public class Server {\n    public static void main(String[] args) throws IOException {\n        // 1.获取通道\n        ServerSocketChannel serverSocketChannel=ServerSocketChannel.open();\n        // 2.文件通道\n        FileChannel outChannel = FileChannel.open(Paths.get(\"D:\\\\资源\\\\2.mp4\"), StandardOpenOption.READ,StandardOpenOption.WRITE,StandardOpenOption.CREATE);\n        // 3.绑定连接\n        serverSocketChannel.bind(new InetSocketAddress(8888));\n        // 4.获取客户端连接的通道\n        SocketChannel accept = serverSocketChannel.accept();\n        // 5.分配缓冲区\n        ByteBuffer byteBuffer=ByteBuffer.allocate(1024);\n        // 6.接收数据\n        while (accept.read(byteBuffer)!=-1){\n            byteBuffer.flip();\n            outChannel.write(byteBuffer);\n            byteBuffer.clear();\n        }\n        outChannel.close();\n        accept.close();\n        serverSocketChannel.close();\n    }\n}\n```\n\n非阻塞版本先引入几个内容：\n- `Selector`：选择器\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/ajEGNFEhBJBBaRRMji7nnmoC)\n- `SelectionKey`: 表示`SelectableChannel`和`Selector`之间的注册关系。每次向选择器注册通道时就会选择一个事件（选择键）。选择键包含两个表示未整数值的操作集。操作集的每一位都表示该键的通道锁支持的一类可选择操作。\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/1iKt7i7qqq6QtPxAHdCe1bHj)\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/UWTo16PKwRC47koTsEDu9itn)\n\n```java\npublic class Server {\n    public static void main(String[] args) throws IOException {\n        //1.获取通道\n        ServerSocketChannel ssChannel = ServerSocketChannel.open();\n        //2.切换非阻塞式模式\n        ssChannel.configureBlocking(false);\n        //3.绑定连接\n        ssChannel.bind(new InetSocketAddress(9898));\n        //4.获取选择器\n        Selector selector = Selector.open();\n        //5.将通道注册到选择器上，并且指定“监听接收事件”\n        ssChannel.register(selector, SelectionKey.OP_ACCEPT);\n        //6.轮询式的获取选择器上已经“准备就绪”的事件\n        while (selector.select() > 0) {\n            //7.获取当前选择器中所有注册的“选择键（已就绪的监听事件）”\n            Iterator<SelectionKey> it = selector.selectedKeys().iterator();\n            while (it.hasNext()) {\n                //8.获取准备“就绪”的事件\n                SelectionKey sk = it.next();\n                //9.判断具体是什么时间准备就绪\n                if (sk.isAcceptable()) {\n                    //10.若“接收就绪”，获取客户端连接\n                    SocketChannel sChannel = ssChannel.accept();\n                    //11.切换非阻塞模式\n                    sChannel.configureBlocking(false);\n                    //12.将该通道注册到选择器上\n                    sChannel.register(selector, SelectionKey.OP_READ);\n                } else if (sk.isReadable()) {\n                    //13.获取当前选择器上“读就绪”状态的通道\n                    SocketChannel sChannel = (SocketChannel) sk.channel();\n                    //14.读取数据\n                    ByteBuffer buf = ByteBuffer.allocate(1024);\n                    int len = 0;\n                    while ((len = sChannel.read(buf)) > 0) {\n                        buf.flip();\n                        System.out.println(new String(buf.array(), 0, len));\n                        buf.clear();\n                    }\n                }\n                //15.取消选择键SelectionKey\n                it.remove();\n            }\n        }\n    }\n}\n\npublic class Client {\n    public static void main(String[] args) throws IOException {\n        //1.获取通道\n        SocketChannel sChannel = SocketChannel.open(new InetSocketAddress(\"127.0.0.1\", 9898));\n        //2.切换非阻塞模式\n        sChannel.configureBlocking(false);\n        //3.分配指定大小的缓冲区\n        ByteBuffer buf = ByteBuffer.allocate(1024);\n        //4.发送数据给服务端\n        Scanner scan = new Scanner(System.in);\n        while (scan.hasNext()) {\n            String str = scan.next();\n            buf.put((new Date().toString() + \"\\n\" + str).getBytes());\n            buf.flip();\n            sChannel.write(buf);\n            buf.clear();\n        }\n        //5.关闭通道\n        sChannel.close();\n    }\n}\n\n```\n\nUDP方式：\n```java\npublic class Server {\n    public static void main(String[] args) throws IOException {\n        DatagramChannel dc= DatagramChannel.open();\n        dc.configureBlocking(false);\n        dc.bind(new InetSocketAddress(9898));\n        Selector selector= Selector.open();\n        dc.register(selector, SelectionKey.OP_READ);\n        while(selector.select()>0){\n            Iterator<SelectionKey> it=selector.selectedKeys().iterator();\n            while(it.hasNext()){\n                SelectionKey sk=it.next();\n                if(sk.isReadable()){\n                    ByteBuffer buf= ByteBuffer.allocate(1024);\n                    dc.receive(buf)\n                    ;\n                    buf.flip();\n                    System.out.println(new String(buf.array(),0,buf.limit()));\n                    buf.clear();\n                }\n            }\n            it.remove();\n        }\n    }\n}\n\npublic class Client {\n    public static void main(String[] args) throws IOException {\n        DatagramChannel dc= DatagramChannel.open();\n        dc.configureBlocking(false);\n        ByteBuffer buf= ByteBuffer.allocate(1024);\n        Scanner scan=new Scanner(System.in);\n        while(scan.hasNext()){\n            String str=scan.next();\n            buf.put((new Date().toString()+\"\\n\"+str).getBytes());\n            buf.flip();\n            dc.send(buf, new InetSocketAddress(\"127.0.0.1\", 9898));\n            buf.clear();\n        }\n        dc.close();\n    }\n}\n```');
INSERT INTO `blog_content` VALUES (59, '内容参考尚硅谷`Netty`教程\n## 有了NIO，为什么还有Netty\n1. `NIO`中`epoll`空轮询问题\n[NIO的epoll空轮询bug](https://www.cnblogs.com/JAYIT/p/8241634.html)\n\n2. `NIO`的类库和`API`繁杂，使用麻烦：需要掌握`Selector`、`ServerSocketChannel`、`SocketChannel`、`ByteBuffer`等。具体可以参考`NIO`的文章\n3. 开发难度和工作量大，例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常流的处理等，在`NIO`中，这些问题都需要我们自行解决\n4. 需要熟悉多线程，因为`NIO`编程涉及到`Reactor`模式，必须对多线程和网络编程十分熟悉，才能编写出高质量代码\n\n## 认识Netty\n官网：`https://netty.io/`\n以下是官网的描述：\n`Netty is an asynchronous event-driven network application framework\nfor rapid development of maintainable high performance protocol servers & clients.`\n`Netty`是一个异步基于事件驱动的网络应用框架，用来快速开发高性能的服务端和客户端\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/WVDB9Lnc9Sv6Uszb3qgbU8XN)\n\n- `Core`：`Netty`的核心，零拷贝、交互API库、可扩展的事件模型\n- `Protocol Support`：`Netty`支持的协议\n- `Transport Services`：支持的传输服务\n\n官方文档：`https://netty.io/wiki/user-guide-for-4.x.html`\n\n## `Netty`的优点\n\n## `Netty`的线程模型\n根据`Reactor`的数量和处理资源线程的数量不同，有3种典型的实现：\n- 单`Reactor`单线程\n- 单`Reactor`多线程\n- 主从`Reactor`多线程\n`Netty`线程模型主要基于主从`Reactor`线程模型做了一定的改进，其中主从`Reactor`多线程模型有多个`Reactor`\n\n1. 传统阻塞I/O服务模型\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/w5RiIShKNsONxt88getU7sYY)\n\n2. `Reactor`模式（还有反应器模式，分发者模式，通知者模式叫法）\n针对传统阻塞I/O服务模型的两个缺点，提供了解决方案：\n- 基于I/O复用模型：多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。\n- 基于线程池复用线程资源：不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/oyDWAQGT2jzZYiEBzfWBzHxV)\n\nI/O复用结合线程池，就是`Reactor`模式基本思想\n- `Reactor`模式，通过一个或多个输入同时传递给服务处理器的模式（基于事件驱动）\n- 服务器端程序处理传入的多个请求，并将它们同步分派到相应的处理线程，因此`Reactor`模式也叫`Dispatcher`模式\n- `Reactor`模式使用IO复用监听事件，收到事件后，分发给某个线程（进程），这点就是网络服务器高并发处理的关键\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/UD5Fomqe1CHKXACk6VEuhy65)\n\n3. `Reactor`模式中的核心\n- `Reactor`:`Reactor`在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对IO事件做出反应。它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人；\n- `Handlers`:处理程序执行I/O事件要完成的实际时间，类似于客户想要与之交谈的公司中的实际官员。`Reactor`通过调度适当的处理程序来响应I/O事件，处理程序执行非阻塞操作。\n\n## `Reactor`模式分类\n- 单`Reactor`单线程（NIO就是这样的）\n线程数量少了，可是太少了，read的时候还是会出现\"排队\"\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/pX5mHZo3oejJM0CWBnTi7xpD)\n\n说明：\n1. `Select` 是前面 I/O复用模型介绍的标准网络编程API，可以实现应用程序通过一个阻塞对象监听多路连接请求\n2. `Reactor` 对象通过 `Select` 监控客户端请求事件，收到事件后通过 `Dispatch` 进行分发\n3. 如果是建立连接请求事件，则由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理\n4. 如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应\n5. Handler 会完成 Read→业务处理→Send 的完整业务流程\n\n结合实例：服务器端用一个线程通过多路复用搞定所有的 IO 操作（包括连接，读、写等），编码简单，清晰明了，但是如果客户端连接数量较多，将无法支撑，前面的 NIO 案例就属于这种模型。\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/stJ4rry7RU6oKaTDbtfN8XV1)\n\n- 单`Reactor`多线程\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/jD1t1OZfhEJMID95l3YQUlA4)\n\n说明：\n1. Reactor 对象通过select 监控客户端请求事件, 收到事件后，通过dispatch进行分发\n2. 如果建立连接请求, 则右Acceptor 通过accept 处理连接请求, 然后创建一个Handler对象处理完成连接后的各种事件\n3. 如果不是连接请求，则由reactor分发调用连接对应的handler 来处理\n4. handler 只负责响应事件，不做具体的业务处理, 通过read 读取数据后，会分发给后面的worker线程池的某个线程处理业务\n5. worker 线程池会分配独立线程完成真正的业务，并将结果返回给handler\n6. handler收到响应后，通过send 将结果返回给client\n\n- 主从`Reactor`多线程\n\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/9zhJyTlSNJd6wCvufEIwaafn)\n\n说明：\n1. `Reactor`主线程`MainReactor`对象通过`select`监听连接事件，收到事件后，通过`Acceptor`处理连接事件\n2. 当`Acceptor`处理连接事件后，`MainReactor`将连接分配给`SubReactor`\n3. `SubReactor`将链接加入到连接队列进行监听，并创建`handler`进行各种事件处理\n4. 当有新事件发生时，`SubReactor`就会调用对应的`handler`处理\n5. `handler`通过`read`读取数据，分发给后面的`worker`线程处理\n6. `worker`线程池分配独立的`worker`线程进行业务处理，并返回结果\n7. `handler`收到响应的结果后，再通过`send`将结果返回给`client`\n8. `Reactor`主线程可以对应多个`Reactor`子线程，即`MainReactor`可以关联多个`SubReactor`\n\n## `Netty`模型\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/K5mTKNtHGrOylzz3g7eLH9g6)\n\n说明：\n1. `Netty`抽象出两组线程池，分别为`BossGroup`和`WorkerGroup`。`BossGroup`负责接收客户端的连接。`WorkerGroup`负责网络的读写\n2. `BossGroup`和`WorkerGroup`类型都是`NioEventLoopGroup`\n3. `NioEventLoopGroup`相当于一个事件循环组，这个组中含有多个事件循环，每一个事件循环是`NioEventLoop`\n4. `NioEventLoop`表示一个不断循环的执行处理任务的线程，每个`NioEventLoop`都有一个`selector`，用于监听绑定在其上的`socket`网络通讯\n5. `NioEventLoopGroup`可以有多个线程，即可以含有多个贵`NioEventLoop`\n6. 每个`BossNioEventLoop`循环执行三个步骤：\n	1. 轮询`accept`事件\n	2. 处理`accept`事件，与`client`建立连接，生成`NioSocketChannel`，并将其注册到某个`WorkerGroup`的`NioEventLoop`上的`selector`\n	3. 处理任务队列的任务，即`runAllTasks`\n7. 每个`WorkerNioEventLoop`循环执行三个步骤:\n	1. 轮询`read,write`事件\n	2. 处理`I/O`事件，即`read,write`事件，在对应`NioSocketChannel`处理\n	3. 处理任务队列的任务，即`runAllTasks`\n8. 每个`Worker NioEventLoop`处理业务时，会使用`pipeline`（管道），`pipeline`中包含了`channel`,即通过`pipeline`可以获取到对应通道，管道中维护了很多处理器\n\n');
INSERT INTO `blog_content` VALUES (60, '## 使用Netty开启TCP服务\n\n[github](https://github.com/yhuihu/Java-Study/tree/master/netty)\n\n### Netty服务端\n```java\npublic class NettyServer {\n    public static void main(String[] args) throws InterruptedException {\n        //创建BossGroup和workerGroup\n        //1.创建两个线程组bossGroup和workerGroup\n        //2bossGroup只是处理连接请求，真正和客户端进行业务处理的，是workerGroup\n        EventLoopGroup bossGroup = new NioEventLoopGroup();\n        EventLoopGroup workerGroup = new NioEventLoopGroup();\n        //创建服务器端的启动对象，配置参数\n        try {\n            ServerBootstrap serverBootstrap = new ServerBootstrap();\n            //使用链式编程来进行设置\n            serverBootstrap.group(bossGroup, workerGroup)//设置两个线程组\n                    .channel(NioServerSocketChannel.class)//使用NioServerSocketChannel作为服务器的通道实现\n                    .option(ChannelOption.SO_BACKLOG, 128)//设置线程队列得到连接的个数\n                    .childOption(ChannelOption.SO_KEEPALIVE, true)//设置保持活动连接状态\n                    .childHandler(new ChannelInitializer<SocketChannel>() {//创建一个通道测试对象（匿名对象）\n                        //给pipeline设置处理器\n                        @Override\n                        protected void initChannel(SocketChannel ch) throws Exception {\n                            //给我们的workerGroup的EventLoop对应的管道设置处理器\n                            ch.pipeline().addLast(new NettyServerHandler());\n                        }\n                    });\n            System.out.println(\"..服务器 is ready\");\n            //绑定一个端口并且同步，生成了一个ChannelFuture对象\n            //启动服务器\n            ChannelFuture sync = serverBootstrap.bind(6668).sync();\n            //对关闭通道进行监听 当有关闭通道消息事件时才会关闭\n            sync.channel().closeFuture().sync();\n        } finally {\n            bossGroup.shutdownGracefully();\n            workerGroup.shutdownGracefully();\n        }\n    }\n}\n\npublic class NettyServerHandler extends ChannelInboundHandlerAdapter {\n    /**\n     * 读取实际数据（这里我们可以读取客户端发送的消息）\n     * 1.ChannelHandlerContext cts:上下文对象，含有与管道pipeline，通道channel，地址\n     * 2.Object msg:就是客户端发送的数据 默认Object\n     */\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n        System.out.println(\"服务器读取线程：\"+Thread.currentThread().getName());\n        System.out.println(\"server ctx=\" + ctx);\n        //将msg转成ByteBuf，这是netty提供的，也nio的ByteBuffer不同\n        ByteBuf byteBuf = (ByteBuf) msg;\n        System.out.println(\"客户端发送的消息是：\" + byteBuf.toString(CharsetUtil.UTF_8));\n        System.out.println(\"客户端地址：\" + ctx.channel().remoteAddress());\n    }\n\n    /**\n     * 数据读取完毕\n     *\n     * @param ctx 上下文对象\n     * @throws Exception e\n     */\n    @Override\n    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {\n        //write方法+flush方法，将数据写入缓存并刷新，一般讲，我们对这个发送的数据进行编码\n        ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello,客户端\", CharsetUtil.UTF_8));\n    }\n\n    /**\n     * 发生异常，关闭通道\n     *\n     * @param ctx   上下文\n     * @param cause\n     * @throws Exception\n     */\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        ctx.close();\n    }\n}\n```\n\n### Netty客户端\n```java\npublic class NettyClient {\n    public static void main(String[] args) throws InterruptedException {\n        //客户端需要一个事件循环组\n        EventLoopGroup eventExecutors = new NioEventLoopGroup();\n        //创建客户端启动对象\n        try {\n            Bootstrap bootstrap = new Bootstrap();\n            bootstrap.group(eventExecutors)//设置线程组\n                    .channel(NioSocketChannel.class)//设置客户端通道的实现类（反射）\n                    .handler(new ChannelInitializer<SocketChannel>() {\n                        @Override\n                        protected void initChannel(SocketChannel ch) throws Exception {\n                            ch.pipeline().addLast(new NettyClientHandler());\n                        }\n                    });\n            System.out.println(\"客户端 ok..\");\n            //启动客户端去连接服务端\n            //关于channelFuture要分析，涉及到netty的异步模型\n            ChannelFuture sync = bootstrap.connect(\"127.0.0.1\", 6668).sync();\n            //给关闭通道进行监听\n            sync.channel().closeFuture().sync();\n        } finally {\n            eventExecutors.shutdownGracefully();\n        }\n    }\n}\n\npublic class NettyClientHandler extends ChannelInboundHandlerAdapter {\n    /**\n     * 当通道就绪就会触发该方法\n     *\n     * @param ctx ctx\n     * @throws Exception e\n     */\n    @Override\n    public void channelActive(ChannelHandlerContext ctx) throws Exception {\n        System.out.println(\"client:\" + ctx);\n        ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello,server\", CharsetUtil.UTF_8));\n    }\n\n    /**\n     * 读取事件触发\n     *\n     * @param ctx ctx\n     * @param msg msg\n     * @throws Exception e\n     */\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n        ByteBuf byteBuf = (ByteBuf) msg;\n        System.out.println(\"接收到服务器消息：\" + byteBuf.toString(CharsetUtil.UTF_8));\n        System.out.println(\"服务器地址:\" + ctx.channel().remoteAddress());\n    }\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        cause.printStackTrace();\n        ctx.close();\n    }\n}\n```\n\n');
INSERT INTO `blog_content` VALUES (61, '## Netty任务队列\n- 用户程序自定义的普通任务\n```java\n	ctx.channel().eventLoop().execute(() -> {\n            try {\n                Thread.sleep(20 * 1000);\n                ctx.writeAndFlush(Unpooled.copiedBuffer(\"处理结束2\", CharsetUtil.UTF_8));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n```\n\n- 用户自定义定时任务\n```java\n        //schedule和execute是在两个不同队列的\n        ctx.channel().eventLoop().schedule(() -> {\n            try {\n                Thread.sleep(10 * 1000);\n                ctx.writeAndFlush(Unpooled.copiedBuffer(\"处理结束1\", CharsetUtil.UTF_8));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        },5, TimeUnit.SECONDS);\n```\n\n- 非当前Reactor线程调用Channel的各种方法\n例如在推送系统的业务线程里面，根据用户的标识，找到对应的 Channel 引用，然后调用 Write 类方法向该用户推送消息，就会进入到这种场景。最终的 Write 会提交到任务队列中后被异步消费。（这里给个思路，将用户与Channel对应关系方法一个map中，需要发送消息时根据用户取出来。如果是群聊系统的话两个map，有优化方法时再补充）\n\n## 注意事项\n1. 普通任务与定时任务是在两个不同的队列当中的\n![image.png](https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/rhXc8CCyy25OSLKLQieL92ZI)\n\n2. 如果多个任务在同一个队列，那么会出现排队的效果，例如：`ctx.channel().eventLoop().execute(new Runable())`这个方法执行两次，第一个任务耗时5s，第二个任务耗时10s，那么结果将是，第一个任务在5s返回，第二个任务在15s返回，因为队列遵循先进先出。');
INSERT INTO `blog_content` VALUES (62, '```java\npublic class ChatServer {\n    private int port;\n\n    ChatServer(int port) {\n        this.port = port;\n    }\n\n    public void start() throws InterruptedException {\n        EventLoopGroup boss = new NioEventLoopGroup();\n        EventLoopGroup worker = new NioEventLoopGroup();\n        ServerBootstrap serverBootstrap = new ServerBootstrap();\n        serverBootstrap.group(boss, worker);\n        serverBootstrap.channel(NioServerSocketChannel.class);\n        serverBootstrap.handler(new LoggingHandler(LogLevel.INFO));\n        serverBootstrap.childHandler(new ChannelInitializer<SocketChannel>() {\n            @Override\n            protected void initChannel(SocketChannel ch) throws Exception {\n                ChannelPipeline pipeline = ch.pipeline();\n                //http加解码\n                pipeline.addLast(new HttpServerCodec());\n                //请求长度限制\n                pipeline.addLast(new HttpObjectAggregator(8972));\n                //websocket连接端点\n                pipeline.addLast(new WebSocketServerProtocolHandler(\"/websocket\"));\n                pipeline.addLast(new ChatServerHandler());\n            }\n        });\n        ChannelFuture sync = serverBootstrap.bind(8080).sync();\n        sync.channel().closeFuture().sync();\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        ChatServer chatServer = new ChatServer(8080);\n        chatServer.start();\n    }\n}\n```\n\n```java\npublic class ChatServerHandler extends SimpleChannelInboundHandler<TextWebSocketFrame> {\n    @Override\n    protected void channelRead0(ChannelHandlerContext ctx, TextWebSocketFrame msg) throws Exception {\n        Channel channel = ctx.channel();\n        System.out.println(\"接收到来自[\" + channel.remoteAddress() + \"]的消息：\" + msg.text());\n        ctx.writeAndFlush(new TextWebSocketFrame(\"服务器时间\" + LocalDateTime.now() + \" \" + msg.text()));\n    }\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        System.out.println(\"发生异常：\" + cause.getMessage());\n    }\n\n    @Override\n    public void handlerAdded(ChannelHandlerContext ctx) throws Exception {\n        System.out.println(ctx.channel().remoteAddress() + \"上线了\");\n    }\n\n    @Override\n    public void handlerRemoved(ChannelHandlerContext ctx) throws Exception {\n        System.out.println(ctx.channel().remoteAddress() + \"离开了\");\n    }\n}\n```\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>websocket</title>\n</head>\n<script>\n  var socket = null;\n  if (!window.WebSocket) {\n    alert(\"当前浏览器不支持\");\n  } else {\n    socket = new WebSocket(\"ws://localhost:8080/websocket\");\n    socket.onopen = function () {\n      var elementById = document.getElementById(\"responseText\");\n      elementById.value = \"连接开启了。\"\n    }\n    //相当于连接关闭(感知到连接关闭)\n    socket.onclose = function (ev) {\n      var rt = document.getElementById(\"responseText\");\n      rt.value = rt.value + \"\\n\" + \"连接关闭了..\"\n    }\n    socket.onmessage = function (ev) {\n      var rt = document.getElementById(\"responseText\");\n      rt.value = rt.value + \"\\n\" + ev.data;\n    }\n  }\n\n  //发送消息到服务器\n  function send() {\n    if (!window.socket) { //先判断socket是否创建好\n      return;\n    }\n    if (socket.readyState === WebSocket.OPEN) {\n      //通过socket 发送消息\n      socket.send(document.getElementById(\"textValue\").value)\n    } else {\n      alert(\"连接没有开启\");\n    }\n  }\n</script>\n<body>\n<div>\n    <label>\n        <input type=\"text\" id=\"textValue\">\n    </label>\n    <input type=\"button\" value=\"发送消息\" onclick=\"send()\">\n</div>\n<div>\n    <label>\n        <textarea style=\"width: 300px;height: 300px\" id=\"responseText\"></textarea>\n    </label>\n    <input type=\"button\" value=\"清空消息\" onclick=\"document.getElementById(\'responseText\').value=\'\'\">\n</div>\n</body>\n</html>\n\n```');
INSERT INTO `blog_content` VALUES (63, '项目部署上线后github第三方登录离奇的慢，并且多次出现`Connection refused (Connection refused)`的错误，因此找到了一种办法是通过修改hosts解决。\nWindows下在`C:/Windows/system32/drivers/etc/hosts`\nUbuntu等linux系一般在`/etc/hosts`\n```yml\n # Github\n151.101.44.249 github.global.ssl.fastly.net\n192.30.253.113 github.com\n103.245.222.133 assets-cdn.github.com\n23.235.47.133 assets-cdn.github.com\n203.208.39.104 assets-cdn.github.com\n204.232.175.78 documentcloud.github.com\n204.232.175.94 gist.github.com\n107.21.116.220 help.github.com\n207.97.227.252 nodeload.github.com\n199.27.76.130 raw.github.com\n107.22.3.110 status.github.com\n204.232.175.78 training.github.com\n207.97.227.243 www.github.com\n185.31.16.184 github.global.ssl.fastly.net\n151.101.0.0/22 avatars0.githubusercontent.com\n151.101.0.0/22 avatars1.githubusercontent.com\n151.101.0.0/22 avatars2.githubusercontent.com\n151.101.0.0/22 avatars3.githubusercontent.com\n199.232.28.133 cloud.githubusercontent.com\n```\n刷新hosts\nWindows：`ipconfig /flushdns`\nUbuntu：`sudo systemctl restart nscd`');

-- ----------------------------
-- Table structure for carousel
-- ----------------------------
DROP TABLE IF EXISTS `carousel`;
CREATE TABLE `carousel`  (
                             `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键',
                             `image` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '图片',
                             `image_order` int(0) NOT NULL COMMENT '顺序',
                             `url` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '链接',
                             PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 4 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of carousel
-- ----------------------------
INSERT INTO `carousel` VALUES (1, 'https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/pYA3VyEiRqk5u83Pi9QNKyks', 1, '');
INSERT INTO `carousel` VALUES (3, 'https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/TZD9h01g8i414gSc6mMApPy4', 3, '');
INSERT INTO `carousel` VALUES (4, 'https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/KHzm6Fhn4lIydTbZ7IZB7D4X', 1, '');

-- ----------------------------
-- Table structure for comment
-- ----------------------------
DROP TABLE IF EXISTS `comment`;
CREATE TABLE `comment`  (
                            `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键',
                            `blog_id` int(0) UNSIGNED NOT NULL COMMENT '对应的博客',
                            `content` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '评论内容',
                            `comment_date` datetime(0) NOT NULL COMMENT '评论日期',
                            `reader_id` int(0) UNSIGNED NOT NULL COMMENT '读者/评论者',
                            `reply_comment_id` int(0) UNSIGNED NULL DEFAULT NULL COMMENT '回复的评论，空表示评论博客',
                            PRIMARY KEY (`id`) USING BTREE,
                            INDEX `comment_ibfk_1`(`blog_id`) USING BTREE,
                            INDEX `reader_id`(`reader_id`) USING BTREE,
                            INDEX `reply_comment_id`(`reply_comment_id`) USING BTREE,
                            CONSTRAINT `comment_ibfk_1` FOREIGN KEY (`blog_id`) REFERENCES `blog` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
                            CONSTRAINT `comment_ibfk_2` FOREIGN KEY (`reader_id`) REFERENCES `reader` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
                            CONSTRAINT `comment_ibfk_3` FOREIGN KEY (`reply_comment_id`) REFERENCES `comment` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE = InnoDB AUTO_INCREMENT = 139 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of comment
-- ----------------------------
INSERT INTO `comment` VALUES (108, 35, 'github第三方登录成功', '2019-08-26 19:19:07', 138, NULL);
INSERT INTO `comment` VALUES (109, 37, '多线程爬虫太狠了', '2019-08-27 19:20:53', 138, NULL);
INSERT INTO `comment` VALUES (111, 37, '本文章demo已经上传github\nhttps://github.com/yhuihu/Java_Spilder', '2019-08-28 10:06:07', 138, NULL);
INSERT INTO `comment` VALUES (112, 37, '牛批', '2019-08-28 17:11:40', 139, NULL);
INSERT INTO `comment` VALUES (139, 62, '<img src=1 onerror=alert(1)>', '2020-07-15 21:29:07', 139, NULL);

-- ----------------------------
-- Table structure for flyway_schema_history
-- ----------------------------
DROP TABLE IF EXISTS `flyway_schema_history`;
CREATE TABLE `flyway_schema_history`  (
                                          `installed_rank` int(0) NOT NULL,
                                          `version` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
                                          `description` varchar(200) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
                                          `type` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
                                          `script` varchar(1000) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
                                          `checksum` int(0) NULL DEFAULT NULL,
                                          `installed_by` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
                                          `installed_on` timestamp(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0),
                                          `execution_time` int(0) NOT NULL,
                                          `success` tinyint(1) NOT NULL,
                                          PRIMARY KEY (`installed_rank`) USING BTREE,
                                          INDEX `flyway_schema_history_s_idx`(`success`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of flyway_schema_history
-- ----------------------------
INSERT INTO `flyway_schema_history` VALUES (1, '1', 'init', 'SQL', 'V1__init.sql', 2120726760, 'blog', '2020-07-23 14:17:16', 1203, 1);

-- ----------------------------
-- Table structure for link
-- ----------------------------
DROP TABLE IF EXISTS `link`;
CREATE TABLE `link`  (
                         `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键',
                         `link_name` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '链接名称',
                         `link_url` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '链接地址',
                         `link_order` int(0) NOT NULL COMMENT '链接次序（小的在前）',
                         PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 5 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of link
-- ----------------------------
INSERT INTO `link` VALUES (1, 'iconfont', 'http://www.iconfont.cn/', 4);
INSERT INTO `link` VALUES (2, 'github', 'https://github.com/yhuihu/', 6);
INSERT INTO `link` VALUES (5, '百度', 'http://www.baidu.com', 10);

-- ----------------------------
-- Table structure for project
-- ----------------------------
DROP TABLE IF EXISTS `project`;
CREATE TABLE `project`  (
                            `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键',
                            `name` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '名称',
                            `url` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '项目地址',
                            `image` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '项目图片',
                            `project_order` int(0) UNSIGNED NOT NULL COMMENT '项目顺序',
                            PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of project
-- ----------------------------
INSERT INTO `project` VALUES (1, '客房预订系统', 'https://github.com/yhuihu/HotelsBook', 'https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/x4PJYPybcXTz9ikarRBSLrHA', 1);
INSERT INTO `project` VALUES (2, '个人博客系统', 'https://github.com/yhuihu/yhhu_blog_front', 'https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/8drzCCJGbrVu8wS0QWjW3Aco', 2);
INSERT INTO `project` VALUES (3, 'Java爬虫', 'https://github.com/yhuihu/Java_Spilder', 'https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/oOjL0WcQ10OMenyGofEBqT6P', 3);

-- ----------------------------
-- Table structure for reader
-- ----------------------------
DROP TABLE IF EXISTS `reader`;
CREATE TABLE `reader`  (
                           `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键',
                           `username` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '登录用的账户',
                           `password` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '登录用的密码',
                           `name` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '名字',
                           `ip` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT 'ip地址',
                           `avatar` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '头像',
                           `email` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '邮箱',
                           `inform` int(0) NULL DEFAULT 0 COMMENT '收到回复时是否接收邮件',
                           `uuid` int(0) NULL DEFAULT NULL,
                           PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 140 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of reader
-- ----------------------------
INSERT INTO `reader` VALUES (138, NULL, NULL, 'SuperTig', '127.0.0.1', 'https://avatars3.githubusercontent.com/u/35516186?v=4', NULL, 0, 35516186);
INSERT INTO `reader` VALUES (139, NULL, NULL, '努力学习天天向上', '127.0.0.1', 'https://avatars2.githubusercontent.com/u/43103543?v=4', NULL, 0, 43103543);
INSERT INTO `reader` VALUES (140, NULL, NULL, 'Arthur-_-', '223.74.111.32', 'https://avatars3.githubusercontent.com/u/66620545?v=4', NULL, 0, 66620545);

-- ----------------------------
-- Table structure for send_comment
-- ----------------------------
DROP TABLE IF EXISTS `send_comment`;
CREATE TABLE `send_comment`  (
                                 `id` int(0) NOT NULL AUTO_INCREMENT,
                                 `email` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
                                 `title` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
                                 `comment_id` int(0) UNSIGNED NOT NULL,
                                 `blog_id` int(0) UNSIGNED NOT NULL,
                                 `content` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
                                 `reader_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
                                 PRIMARY KEY (`id`) USING BTREE,
                                 INDEX `comment_id`(`comment_id`) USING BTREE,
                                 INDEX `blog_id`(`blog_id`) USING BTREE,
                                 CONSTRAINT `send_comment_ibfk_1` FOREIGN KEY (`comment_id`) REFERENCES `comment` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT,
                                 CONSTRAINT `send_comment_ibfk_2` FOREIGN KEY (`blog_id`) REFERENCES `blog` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Table structure for tag_name
-- ----------------------------
DROP TABLE IF EXISTS `tag_name`;
CREATE TABLE `tag_name`  (
                             `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键',
                             `name` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '名称',
                             PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 16 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of tag_name
-- ----------------------------
INSERT INTO `tag_name` VALUES (1, 'Java');
INSERT INTO `tag_name` VALUES (2, 'Spring');
INSERT INTO `tag_name` VALUES (4, 'JS');
INSERT INTO `tag_name` VALUES (5, 'HMTL');
INSERT INTO `tag_name` VALUES (6, 'Vue');
INSERT INTO `tag_name` VALUES (7, '数据库');
INSERT INTO `tag_name` VALUES (8, 'Linux');
INSERT INTO `tag_name` VALUES (9, '数据结构');
INSERT INTO `tag_name` VALUES (10, '算法');
INSERT INTO `tag_name` VALUES (11, '项目');
INSERT INTO `tag_name` VALUES (12, '笔记');
INSERT INTO `tag_name` VALUES (13, '其他');
INSERT INTO `tag_name` VALUES (14, 'CSS');
INSERT INTO `tag_name` VALUES (15, '微服务');
INSERT INTO `tag_name` VALUES (16, '中间件');

-- ----------------------------
-- Table structure for type_name
-- ----------------------------
DROP TABLE IF EXISTS `type_name`;
CREATE TABLE `type_name`  (
                              `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键',
                              `name` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT '名称',
                              PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of type_name
-- ----------------------------
INSERT INTO `type_name` VALUES (1, '原创');
INSERT INTO `type_name` VALUES (2, '转载');
INSERT INTO `type_name` VALUES (3, '翻译');

-- ----------------------------
-- Table structure for user
-- ----------------------------
DROP TABLE IF EXISTS `user`;
CREATE TABLE `user`  (
                         `id` int(0) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键',
                         `nickname` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '名字',
                         `profile` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '简介',
                         `avatar` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '头像',
                         `password` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '密码',
                         `username` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '用户名',
                         `email` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '邮箱',
                         PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of user
-- ----------------------------
INSERT INTO `user` VALUES (1, 'yhhu', '😄普通大学生，技术爱好者😄', 'https://yhhu.oss-cn-shenzhen.aliyuncs.com/blog/ft1Uo1DThKrCsVGosrEVxuGK', 'fT28i22g7aee7ref0ff0950720e00ba0e901b0f404c0780f', 'Tiger', '1357958736@qq.com');

SET FOREIGN_KEY_CHECKS = 1;
